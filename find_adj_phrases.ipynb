{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import nltkb\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NN phrases with atleast one JJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\"papers_2017_balanced.pickle\", \"papers_2018_balanced.pickle\", \"papers_2019_balanced.pickle\", \"papers_2020_balanced.pickle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'papers_2017_balanced.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f2310fe692e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0myearwise_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'papers_2017_balanced.pickle'"
     ]
    }
   ],
   "source": [
    "yearwise_data = []\n",
    "\n",
    "for ind_file in data_files:\n",
    "    with open(\"ICLR data/\"+ind_file, \"rb\") as f:\n",
    "        yearwise_data.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spacy.attrs)\n",
    "dir(POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "quick ADJ amod\n",
      "brown ADJ amod\n",
      "fox NOUN compound\n",
      "jumps NOUN ROOT\n",
      "over ADP prep\n",
      "the DET det\n",
      "lazy ADJ amod\n",
      "dog NOUN pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(tok.text, tok.pos_, tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps\n",
      "the lazy dog\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.noun_chunks:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = None\n",
    "with open(\"ICLR data/papers_2020_balanced.pickle\", \"rb\") as f:\n",
    "    review_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H1gNOeHKPS',\n",
       " 'S1xtORNFwH',\n",
       " 'SJx9ngStPH',\n",
       " 'BklOXeBFDS',\n",
       " 'ByeGzlrKwH',\n",
       " 'rJeGJaEtPH',\n",
       " 'SJldu6EtDS',\n",
       " 'BJe-unNYPr',\n",
       " 'BkgF4kSFPB',\n",
       " 'SJeUm1HtDH']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(review_data.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The authors propose the Neural Multiplication Unit (NMU), which can learn to '\n",
      " 'solve a family of arithmetic operations using -, + and * atomic operations '\n",
      " 'over real numbers from examples. They show that a combination of careful '\n",
      " 'initialization, regularization and structural choices allows their model to '\n",
      " 'learn more reliably and efficiently than the previously published Neural '\n",
      " 'Arithmetic Logic Unit.\\n'\n",
      " '\\n'\n",
      " 'The NALU consists of two additive sub-units in the real and log-space '\n",
      " 'respectively, which allows it to handle both additions/subtractions and '\n",
      " 'multiplications/divisions, and combines them with a gating mechanism. The '\n",
      " 'NMU on the other hand simply learns a product of affine transformations of '\n",
      " 'the input. This choice prevents the model from learning divisions, which the '\n",
      " 'authors argue made learning unstable for the NALU case, but allows for an a '\n",
      " 'priori better initialization and dispenses with the gating which is '\n",
      " 'empirically hard to learn. The departures from the NALU architecture are '\n",
      " 'well justified and lead to significant improvements for the considered '\n",
      " 'applications, especially as far as extrapolation to inputs outside of the '\n",
      " 'training domain.\\n'\n",
      " '\\n'\n",
      " 'The paper is mostly well written (one notable exception: the form of the '\n",
      " 'loss function is not given explicitly anywhere in the paper) and well '\n",
      " 'executed, but the scope of the work is somewhat limited, and the authors '\n",
      " 'fail to properly motivate the application or put it in a wider context.\\n'\n",
      " '\\n'\n",
      " 'First, divisions being difficult to handle does not constitute a sufficient '\n",
      " 'justification for choosing to exclude them: the authors should at the very '\n",
      " 'least propose a plausible way forward for future work. More generally, the '\n",
      " 'proposed unit needs to be exposed to at least 10K examples to learn a single '\n",
      " 'expression with fewer than 10 inputs (and the success rate already drops to '\n",
      " 'under 65% for 10 inputs). What would be the use case for such a unit? Even '\n",
      " 'the NMU is only proposed as a step on the way to a more modular, '\n",
      " 'general-purpose, or efficient architecture, its value is difficult to gauge '\n",
      " 'without some idea of what that would look like.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(review_data[\"H1gNOeHKPS\"][\"OFF_REVIEW\"][0][\"content\"][\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(review_data[\"H1gNOeHKPS\"][\"OFF_REVIEW\"][0][\"content\"][\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors ['DT', 'NNS']\n",
      "the Neural Multiplication Unit ['DT', 'NNP', 'NNP', 'NNP']\n",
      "NMU ['NNP']\n",
      "a family ['DT', 'NN']\n",
      "arithmetic operations ['JJ', 'NNS']\n",
      "and * atomic operations ['CC', 'NFP', 'JJ', 'NNS']\n",
      "real numbers ['JJ', 'NNS']\n",
      "examples ['NNS']\n",
      "They ['PRP']\n",
      "a combination ['DT', 'NN']\n",
      "careful initialization ['JJ', 'NN']\n",
      "regularization ['NN']\n",
      "structural choices ['JJ', 'NNS']\n",
      "their model ['PRP$', 'NN']\n",
      "the previously published Neural Arithmetic Logic Unit ['DT', 'RB', 'VBN', 'NNP', 'NNP', 'NNP', 'NNP']\n",
      "The NALU ['DT', 'NNP']\n",
      "two additive sub-units ['CD', 'JJ', 'NN', 'NNS', 'NNS']\n",
      "the real and log-space ['DT', 'JJ', 'CC', 'NN', 'HYPH', 'NN']\n",
      "it ['PRP']\n",
      "both additions/subtractions ['DT', 'NNS', 'SYM', 'NNS']\n",
      "multiplications ['NNS']\n",
      "/divisions ['SYM', 'NNS']\n",
      "them ['PRP']\n",
      "a gating mechanism ['DT', 'VBG', 'NN']\n",
      "The NMU ['DT', 'NNP']\n",
      "the other hand ['DT', 'JJ', 'NN']\n",
      "a product ['DT', 'NN']\n",
      "affine transformations ['JJ', 'NNS']\n",
      "the input ['DT', 'NN']\n",
      "This choice ['DT', 'NN']\n",
      "the model ['DT', 'NN']\n",
      "learning divisions ['NN', 'NNS']\n",
      "the authors ['DT', 'NNS']\n",
      "the NALU case ['DT', 'NNP', 'NN']\n",
      "an a priori better initialization ['DT', 'FW', 'FW', 'JJR', 'NN']\n",
      "dispenses ['NNS']\n",
      "the gating ['DT', 'NN']\n",
      "The departures ['DT', 'NNS']\n",
      "the NALU architecture ['DT', 'NNP', 'NN']\n",
      "significant improvements ['JJ', 'NNS']\n",
      "the considered applications ['DT', 'VBN', 'NNS']\n",
      "extrapolation ['NN']\n",
      "the training domain ['DT', 'NN', 'NN']\n",
      "The paper ['DT', 'NN']\n",
      "one notable exception ['CD', 'JJ', 'NN']\n",
      "the form ['DT', 'NN']\n",
      "the loss function ['DT', 'NN', 'NN']\n",
      "the paper ['DT', 'NN']\n",
      "the scope ['DT', 'NN']\n",
      "the work ['DT', 'NN']\n",
      "the authors ['DT', 'NNS']\n",
      "the application ['DT', 'NN']\n",
      "it ['PRP']\n",
      "a wider context ['DT', 'JJR', 'NN']\n",
      "divisions ['NNS']\n",
      "a sufficient justification ['DT', 'JJ', 'NN']\n",
      "them ['PRP']\n",
      "the authors ['DT', 'NNS']\n",
      "future work ['JJ', 'NN']\n",
      "the proposed unit ['DT', 'VBN', 'NN']\n",
      "at least 10K examples ['RB', 'RBS', 'CD', 'NN', 'NNS']\n",
      "a single expression ['DT', 'JJ', 'NN']\n",
      "fewer than 10 inputs ['JJR', 'IN', 'CD', 'NNS']\n",
      "the success rate ['DT', 'NN', 'NN']\n",
      "under 65% ['IN', 'CD', 'NN']\n",
      "10 inputs ['CD', 'NNS']\n",
      "What ['WP']\n",
      "the use case ['DT', 'NN', 'NN']\n",
      "such a unit ['PDT', 'DT', 'NN']\n",
      "Even the NMU ['RB', 'DT', 'NNP']\n",
      "a step ['DT', 'NN']\n",
      "the way ['DT', 'NN']\n",
      "a more modular, general-purpose, or efficient architecture ['DT', 'RBR', 'JJ', ',', 'JJ', 'HYPH', 'NN', ',', 'CC', 'JJ', 'NN']\n",
      "its value ['PRP$', 'NN']\n",
      "some idea ['DT', 'NN']\n",
      "what ['WP']\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.noun_chunks:\n",
    "    print(tok, [t.tag_ for t in tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of IN arithmetic operations\n",
      "* NFP atomic operations\n",
      "over IN real numbers\n",
      "of IN careful initialization\n",
      "and CC structural choices\n",
      "two CD additive sub\n",
      "the DT other hand\n",
      "of IN affine transformations\n",
      "priori FW better initialization\n",
      "to IN significant improvements\n",
      "one CD notable exception\n",
      "a DT wider context\n",
      "a DT sufficient justification\n",
      "a DT plausible way\n",
      "for IN future work\n",
      "a DT single expression\n",
      "or CC efficient architecture\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc)):\n",
    "    if doc[i].pos_ == \"ADJ\" and doc[i+1].tag_.startswith(\"NN\"):\n",
    "        print(doc[i-1], doc[i-1].tag_, doc[i], doc[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "authors\n",
      "propose\n",
      "the\n",
      "Neural\n",
      "Multiplication\n",
      "Unit\n",
      "(\n",
      "NMU\n",
      ")\n",
      ",\n",
      "which\n",
      "can\n",
      "learn\n",
      "to\n",
      "solve\n",
      "a\n",
      "family\n",
      "of\n",
      "arithmetic\n",
      "operations\n",
      "using\n",
      "-\n",
      ",\n",
      "+\n",
      "and\n",
      "*\n",
      "atomic\n",
      "operations\n",
      "over\n",
      "real\n",
      "numbers\n",
      "from\n",
      "examples\n",
      ".\n",
      "They\n",
      "show\n",
      "that\n",
      "a\n",
      "combination\n",
      "of\n",
      "careful\n",
      "initialization\n",
      ",\n",
      "regularization\n",
      "and\n",
      "structural\n",
      "choices\n",
      "allows\n",
      "their\n",
      "model\n",
      "to\n",
      "learn\n",
      "more\n",
      "reliably\n",
      "and\n",
      "efficiently\n",
      "than\n",
      "the\n",
      "previously\n",
      "published\n",
      "Neural\n",
      "Arithmetic\n",
      "Logic\n",
      "Unit\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "NALU\n",
      "consists\n",
      "of\n",
      "two\n",
      "additive\n",
      "sub\n",
      "-\n",
      "units\n",
      "in\n",
      "the\n",
      "real\n",
      "and\n",
      "log\n",
      "-\n",
      "space\n",
      "respectively\n",
      ",\n",
      "which\n",
      "allows\n",
      "it\n",
      "to\n",
      "handle\n",
      "both\n",
      "additions\n",
      "/\n",
      "subtractions\n",
      "and\n",
      "multiplications\n",
      "/\n",
      "divisions\n",
      ",\n",
      "and\n",
      "combines\n",
      "them\n",
      "with\n",
      "a\n",
      "gating\n",
      "mechanism\n",
      ".\n",
      "The\n",
      "NMU\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      "simply\n",
      "learns\n",
      "a\n",
      "product\n",
      "of\n",
      "affine\n",
      "transformations\n",
      "of\n",
      "the\n",
      "input\n",
      ".\n",
      "This\n",
      "choice\n",
      "prevents\n",
      "the\n",
      "model\n",
      "from\n",
      "learning\n",
      "divisions\n",
      ",\n",
      "which\n",
      "the\n",
      "authors\n",
      "argue\n",
      "made\n",
      "learning\n",
      "unstable\n",
      "for\n",
      "the\n",
      "NALU\n",
      "case\n",
      ",\n",
      "but\n",
      "allows\n",
      "for\n",
      "an\n",
      "a\n",
      "priori\n",
      "better\n",
      "initialization\n",
      "and\n",
      "dispenses\n",
      "with\n",
      "the\n",
      "gating\n",
      "which\n",
      "is\n",
      "empirically\n",
      "hard\n",
      "to\n",
      "learn\n",
      ".\n",
      "The\n",
      "departures\n",
      "from\n",
      "the\n",
      "NALU\n",
      "architecture\n",
      "are\n",
      "well\n",
      "justified\n",
      "and\n",
      "lead\n",
      "to\n",
      "significant\n",
      "improvements\n",
      "for\n",
      "the\n",
      "considered\n",
      "applications\n",
      ",\n",
      "especially\n",
      "as\n",
      "far\n",
      "as\n",
      "extrapolation\n",
      "to\n",
      "inputs\n",
      "outside\n",
      "of\n",
      "the\n",
      "training\n",
      "domain\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "paper\n",
      "is\n",
      "mostly\n",
      "well\n",
      "written\n",
      "(\n",
      "one\n",
      "notable\n",
      "exception\n",
      ":\n",
      "the\n",
      "form\n",
      "of\n",
      "the\n",
      "loss\n",
      "function\n",
      "is\n",
      "not\n",
      "given\n",
      "explicitly\n",
      "anywhere\n",
      "in\n",
      "the\n",
      "paper\n",
      ")\n",
      "and\n",
      "well\n",
      "executed\n",
      ",\n",
      "but\n",
      "the\n",
      "scope\n",
      "of\n",
      "the\n",
      "work\n",
      "is\n",
      "somewhat\n",
      "limited\n",
      ",\n",
      "and\n",
      "the\n",
      "authors\n",
      "fail\n",
      "to\n",
      "properly\n",
      "motivate\n",
      "the\n",
      "application\n",
      "or\n",
      "put\n",
      "it\n",
      "in\n",
      "a\n",
      "wider\n",
      "context\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "First\n",
      ",\n",
      "divisions\n",
      "being\n",
      "difficult\n",
      "to\n",
      "handle\n",
      "does\n",
      "not\n",
      "constitute\n",
      "a\n",
      "sufficient\n",
      "justification\n",
      "for\n",
      "choosing\n",
      "to\n",
      "exclude\n",
      "them\n",
      ":\n",
      "the\n",
      "authors\n",
      "should\n",
      "at\n",
      "the\n",
      "very\n",
      "least\n",
      "propose\n",
      "a\n",
      "plausible\n",
      "way\n",
      "forward\n",
      "for\n",
      "future\n",
      "work\n",
      ".\n",
      "More\n",
      "generally\n",
      ",\n",
      "the\n",
      "proposed\n",
      "unit\n",
      "needs\n",
      "to\n",
      "be\n",
      "exposed\n",
      "to\n",
      "at\n",
      "least\n",
      "10\n",
      "K\n",
      "examples\n",
      "to\n",
      "learn\n",
      "a\n",
      "single\n",
      "expression\n",
      "with\n",
      "fewer\n",
      "than\n",
      "10\n",
      "inputs\n",
      "(\n",
      "and\n",
      "the\n",
      "success\n",
      "rate\n",
      "already\n",
      "drops\n",
      "to\n",
      "under\n",
      "65\n",
      "%\n",
      "for\n",
      "10\n",
      "inputs\n",
      ")\n",
      ".\n",
      "What\n",
      "would\n",
      "be\n",
      "the\n",
      "use\n",
      "case\n",
      "for\n",
      "such\n",
      "a\n",
      "unit\n",
      "?\n",
      "Even\n",
      "the\n",
      "NMU\n",
      "is\n",
      "only\n",
      "proposed\n",
      "as\n",
      "a\n",
      "step\n",
      "on\n",
      "the\n",
      "way\n",
      "to\n",
      "a\n",
      "more\n",
      "modular\n",
      ",\n",
      "general\n",
      "-\n",
      "purpose\n",
      ",\n",
      "or\n",
      "efficient\n",
      "architecture\n",
      ",\n",
      "its\n",
      "value\n",
      "is\n",
      "difficult\n",
      "to\n",
      "gauge\n",
      "without\n",
      "some\n",
      "idea\n",
      "of\n",
      "what\n",
      "that\n",
      "would\n",
      "look\n",
      "like\n",
      ".\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_py_tokens', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_disk', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'is_nered', 'is_parsed', 'is_sentenced', 'is_tagged', 'lang', 'lang_', 'mem', 'merge', 'noun_chunks', 'noun_chunks_iterator', 'print_tree', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_extension', 'similarity', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_disk', 'to_json', 'to_utf8_array', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7425985699627899538                  90                   0\n",
      "                   1]\n"
     ]
    }
   ],
   "source": [
    "for t in nparr:\n",
    "    if t[1] == \"ADJ\"\n",
    "#     print((t.view()))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f8218eb39a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
