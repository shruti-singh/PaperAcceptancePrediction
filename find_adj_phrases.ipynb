{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NN phrases with atleast one JJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\"papers_2017_balanced.pickle\", \"papers_2018_balanced.pickle\", \"papers_2019_balanced.pickle\", \"papers_2020_balanced.pickle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearwise_data = []\n",
    "\n",
    "for ind_file in data_files:\n",
    "    with open(\"ICLR data/\"+ind_file, \"rb\") as f:\n",
    "        yearwise_data.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3446\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for data in yearwise_data:\n",
    "    total += len(data)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF_REVIEW not found for:  ry5wc1bCW\n",
      "10454\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "adjective_phrases_acc = {}\n",
    "adjective_phrases_reject = {}\n",
    "\n",
    "bad_count = good_count = 0\n",
    "\n",
    "for data in yearwise_data:\n",
    "    for k,v in data.items():\n",
    "        if \"decision\" in data[k][\"DECISIONS\"]:\n",
    "            if \"decision\" in data[k][\"DECISIONS\"][\"decision\"][\"content\"]:\n",
    "                dec = data[k][\"DECISIONS\"][\"decision\"][\"content\"][\"decision\"].lower()\n",
    "            else:\n",
    "                dec = data[k][\"DECISIONS\"][\"decision\"][\"content\"][\"recommendation\"].lower()\n",
    "        else:\n",
    "            dec = data[k][\"DECISIONS\"][\"content\"][\"decision\"].lower()\n",
    "        if \"OFF_REVIEW\" in data[k]:\n",
    "            for review in data[k][\"OFF_REVIEW\"]:\n",
    "                try:\n",
    "                    review_text = review[\"content\"][\"review\"]\n",
    "                    doc = nlp(review_text)\n",
    "                    for nchunk in doc.noun_chunks:\n",
    "                        nchunk_tags = [t.tag_ for t in nchunk]\n",
    "                        if \"JJ\" in nchunk_tags or \"JJR\" in nchunk_tags or \"JJS\" in nchunk_tags:\n",
    "                            cleaned_chunk = \" \".join([tok.lemma_.lower() for tok in nchunk])\n",
    "                            \n",
    "                            if \"accept\" in dec:\n",
    "                                if cleaned_chunk in adjective_phrases_acc:\n",
    "                                    adjective_phrases_acc[cleaned_chunk] += 1\n",
    "                                else:\n",
    "                                    adjective_phrases_acc[cleaned_chunk] = 1\n",
    "                            else:\n",
    "                                if cleaned_chunk in adjective_phrases_reject:\n",
    "                                    adjective_phrases_reject[cleaned_chunk] += 1\n",
    "                                else:\n",
    "                                    adjective_phrases_reject[cleaned_chunk] = 1\n",
    "                    good_count += 1\n",
    "                except Exception as ex:\n",
    "                    bad_count += 1\n",
    "        else:\n",
    "            print(\"OFF_REVIEW not found for: \", k)\n",
    "print(good_count)\n",
    "print(bad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjective_phrases_acc\n",
    "sorted_adj_phrases_acc = sorted(adjective_phrases_acc.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neural network', 505),\n",
       " ('the experimental result', 408),\n",
       " ('previous work', 327),\n",
       " ('minor comment', 283),\n",
       " ('more detail', 239),\n",
       " ('the main contribution', 227),\n",
       " ('experimental result', 210),\n",
       " ('adversarial example', 208),\n",
       " ('related work', 206),\n",
       " ('prior work', 205),\n",
       " ('deep neural network', 187),\n",
       " ('the main text', 186),\n",
       " ('deep learning', 179),\n",
       " ('the other hand', 166),\n",
       " ('future work', 165),\n",
       " ('other method', 163),\n",
       " ('the experimental section', 158),\n",
       " ('deep network', 158),\n",
       " ('a neural network', 152),\n",
       " ('the main idea', 142),\n",
       " ('-pron- main concern', 139),\n",
       " ('adversarial training', 137),\n",
       " ('the related work', 134),\n",
       " ('the empirical result', 130),\n",
       " ('adversarial attack', 125),\n",
       " ('detailed comment', 116),\n",
       " ('an important problem', 115),\n",
       " ('a good job', 114),\n",
       " ('the main paper', 112),\n",
       " ('other word', 108),\n",
       " ('the neural network', 106),\n",
       " ('well performance', 105),\n",
       " ('the related work section', 102),\n",
       " ('the theoretical result', 97),\n",
       " ('good result', 92),\n",
       " ('the experimental evaluation', 92),\n",
       " ('good performance', 92),\n",
       " ('the same time', 91),\n",
       " ('a large number', 90),\n",
       " ('more discussion', 88),\n",
       " ('generative model', 88),\n",
       " ('other comment', 87),\n",
       " ('the main result', 84),\n",
       " ('empirical result', 83),\n",
       " ('gradient descent', 82),\n",
       " ('a new method', 82),\n",
       " ('recent work', 79),\n",
       " ('a good paper', 79),\n",
       " ('the theoretical analysis', 77),\n",
       " ('the key idea', 77)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_adj_phrases_acc[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjective_phrases_reject\n",
    "sorted_adj_phrases_rej = sorted(adjective_phrases_reject.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neural network', 533),\n",
       " ('the experimental result', 432),\n",
       " ('previous work', 349),\n",
       " ('the main contribution', 257),\n",
       " ('minor comment', 252),\n",
       " ('experimental result', 237),\n",
       " ('more detail', 226),\n",
       " ('adversarial example', 219),\n",
       " ('prior work', 205),\n",
       " ('related work', 202),\n",
       " ('deep learning', 197),\n",
       " ('other method', 186),\n",
       " ('the other hand', 186),\n",
       " ('-pron- main concern', 179),\n",
       " ('the main idea', 169),\n",
       " ('a neural network', 163),\n",
       " ('deep neural network', 162),\n",
       " ('the experimental section', 161),\n",
       " ('detailed comment', 155),\n",
       " ('the empirical result', 143),\n",
       " ('deep network', 140),\n",
       " ('adversarial training', 136),\n",
       " ('the related work', 121),\n",
       " ('the main text', 120),\n",
       " ('other word', 120),\n",
       " ('well performance', 113),\n",
       " ('adversarial attack', 109),\n",
       " ('the neural network', 107),\n",
       " ('-pron- current form', 106),\n",
       " ('generative model', 106),\n",
       " ('the experimental evaluation', 100),\n",
       " ('the objective function', 97),\n",
       " ('the related work section', 93),\n",
       " ('an important problem', 92),\n",
       " ('the same time', 90),\n",
       " ('the current paper', 90),\n",
       " ('other comment', 90),\n",
       " ('mutual information', 87),\n",
       " ('more experiment', 82),\n",
       " ('active learning', 79)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_adj_phrases_rej[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3446\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t = 0\n",
    "\n",
    "for data in yearwise_data:\n",
    "    for k,v in data.items():\n",
    "        t += 1\n",
    "        try:\n",
    "            dec = data[k][\"DECISIONS\"][\"decision\"][\"content\"][\"decision\"]\n",
    "        except Exception as ex:\n",
    "            try:\n",
    "                if \"decision\" in data[k][\"DECISIONS\"]:\n",
    "                    dec = data[k][\"DECISIONS\"][\"decision\"][\"content\"][\"recommendation\"]\n",
    "                elif \"content\" in data[k][\"DECISIONS\"]:\n",
    "                    dec = data[k][\"DECISIONS\"][\"content\"][\"decision\"]\n",
    "            except Exception as e:\n",
    "                c+=1\n",
    "                print(data[k][\"DECISIONS\"].keys())\n",
    "                pprint(data[k][\"DECISIONS\"])\n",
    "                print(\"done\")\n",
    "                break\n",
    "print(c)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence': '4: The area chair is confident but not absolutely certain',\n",
       " 'metareview': 'The paper proposes a novel way to ensemble multi-class or multi-label models\\nbased on a Wasserstein barycenter approach. The approach is theoretically\\njustified and obtains good results. Reviewers were concerned with time\\ncomplexity, and authors provided a clear breakdown of the complexity.\\nOverall, all reviewers were positives in their scores, and I recommend accepting the paper.',\n",
       " 'recommendation': 'Accept (Poster)',\n",
       " 'title': 'meta-review'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(yearwise_data[2].keys())[0:5]\n",
    "yearwise_data[2][\"H1g4k309F7\"][\"DECISIONS\"][\"decision\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision': {'cdate': 1576798719989,\n",
       "  'content': {'comment': 'This paper extracts a list of conditions from the question, each of which should be satisfied by the candidate answer generated by an MRC model. All reviewers agree that this approach is interesting (verification and validation) and experiments are solid. One of the reviewers raised concerns are promptly answered by authors, raising the average score to accept. \\n',\n",
       "   'decision': 'Accept (Poster)',\n",
       "   'title': 'Paper Decision'},\n",
       "  'ddate': None,\n",
       "  'details': {'replyCount': 0},\n",
       "  'forum': 'ryxgsCVYPr',\n",
       "  'id': 'bmukdcHZsa',\n",
       "  'invitation': 'ICLR.cc/2020/Conference/Paper1307/-/Decision',\n",
       "  'nonreaders': [],\n",
       "  'number': 1,\n",
       "  'original': None,\n",
       "  'readers': ['everyone'],\n",
       "  'referent': None,\n",
       "  'replyto': 'ryxgsCVYPr',\n",
       "  'signatures': ['ICLR.cc/2020/Conference/Program_Chairs'],\n",
       "  'tcdate': 1576798719989,\n",
       "  'tmdate': 1576800916570,\n",
       "  'writers': ['ICLR.cc/2020/Conference/Program_Chairs']}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ryxgsCVYPr\"][\"DECISIONS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138328"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjective_phrases_yearwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_adj_phrases = sorted(adjective_phrases_yearwise.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neural network', 1038),\n",
       " ('the experimental result', 840),\n",
       " ('previous work', 676),\n",
       " ('minor comment', 535),\n",
       " ('the main contribution', 484),\n",
       " ('more detail', 465),\n",
       " ('experimental result', 447),\n",
       " ('adversarial example', 427),\n",
       " ('prior work', 410),\n",
       " ('related work', 408)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_adj_phrases[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yearwise_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0dd227de67a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myearwise_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ry5wc1bCW\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'yearwise_data' is not defined"
     ]
    }
   ],
   "source": [
    "yearwise_data[1][\"ry5wc1bCW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spacy.attrs)\n",
    "dir(POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "quick ADJ amod\n",
      "brown ADJ amod\n",
      "fox NOUN compound\n",
      "jumps NOUN ROOT\n",
      "over ADP prep\n",
      "the DET det\n",
      "lazy ADJ amod\n",
      "dog NOUN pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(tok.text, tok.pos_, tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps\n",
      "the lazy dog\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.noun_chunks:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = None\n",
    "with open(\"ICLR data/papers_2020_balanced.pickle\", \"rb\") as f:\n",
    "    review_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ryxgsCVYPr',\n",
       " 'rJe8pxSFwr',\n",
       " 'SJldu6EtDS',\n",
       " 'r1xGP6VYwH',\n",
       " 'H1x9004YPr',\n",
       " 'H1eH9hNtwr',\n",
       " 'BJxsrgStvr',\n",
       " 'SJlYqRNKDS',\n",
       " 'BklIxyHKDr',\n",
       " 'B1xm3RVtwB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(review_data.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The authors propose the Neural Multiplication Unit (NMU), which can learn to '\n",
      " 'solve a family of arithmetic operations using -, + and * atomic operations '\n",
      " 'over real numbers from examples. They show that a combination of careful '\n",
      " 'initialization, regularization and structural choices allows their model to '\n",
      " 'learn more reliably and efficiently than the previously published Neural '\n",
      " 'Arithmetic Logic Unit.\\n'\n",
      " '\\n'\n",
      " 'The NALU consists of two additive sub-units in the real and log-space '\n",
      " 'respectively, which allows it to handle both additions/subtractions and '\n",
      " 'multiplications/divisions, and combines them with a gating mechanism. The '\n",
      " 'NMU on the other hand simply learns a product of affine transformations of '\n",
      " 'the input. This choice prevents the model from learning divisions, which the '\n",
      " 'authors argue made learning unstable for the NALU case, but allows for an a '\n",
      " 'priori better initialization and dispenses with the gating which is '\n",
      " 'empirically hard to learn. The departures from the NALU architecture are '\n",
      " 'well justified and lead to significant improvements for the considered '\n",
      " 'applications, especially as far as extrapolation to inputs outside of the '\n",
      " 'training domain.\\n'\n",
      " '\\n'\n",
      " 'The paper is mostly well written (one notable exception: the form of the '\n",
      " 'loss function is not given explicitly anywhere in the paper) and well '\n",
      " 'executed, but the scope of the work is somewhat limited, and the authors '\n",
      " 'fail to properly motivate the application or put it in a wider context.\\n'\n",
      " '\\n'\n",
      " 'First, divisions being difficult to handle does not constitute a sufficient '\n",
      " 'justification for choosing to exclude them: the authors should at the very '\n",
      " 'least propose a plausible way forward for future work. More generally, the '\n",
      " 'proposed unit needs to be exposed to at least 10K examples to learn a single '\n",
      " 'expression with fewer than 10 inputs (and the success rate already drops to '\n",
      " 'under 65% for 10 inputs). What would be the use case for such a unit? Even '\n",
      " 'the NMU is only proposed as a step on the way to a more modular, '\n",
      " 'general-purpose, or efficient architecture, its value is difficult to gauge '\n",
      " 'without some idea of what that would look like.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(review_data[\"H1gNOeHKPS\"][\"OFF_REVIEW\"][0][\"content\"][\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(review_data[\"H1gNOeHKPS\"][\"OFF_REVIEW\"][0][\"content\"][\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the author\n",
      "the neural multiplication unit\n",
      "nmu\n",
      "a family\n",
      "arithmetic operation\n",
      "and * atomic operation\n",
      "real number\n",
      "example\n",
      "-pron-\n",
      "a combination\n",
      "careful initialization\n",
      "regularization\n",
      "structural choice\n",
      "-pron- model\n",
      "the previously publish neural arithmetic logic unit\n",
      "the nalu\n",
      "two additive sub - unit\n",
      "the real and log - space\n",
      "-pron-\n",
      "both addition / subtraction\n",
      "multiplication\n",
      "/ division\n",
      "-pron-\n",
      "a gate mechanism\n",
      "the nmu\n",
      "the other hand\n",
      "a product\n",
      "affine transformation\n",
      "the input\n",
      "this choice\n",
      "the model\n",
      "learning division\n",
      "the author\n",
      "the nalu case\n",
      "an a priori well initialization\n",
      "dispense\n",
      "the gating\n",
      "the departure\n",
      "the nalu architecture\n",
      "significant improvement\n",
      "the consider application\n",
      "extrapolation\n",
      "the training domain\n",
      "the paper\n",
      "one notable exception\n",
      "the form\n",
      "the loss function\n",
      "the paper\n",
      "the scope\n",
      "the work\n",
      "the author\n",
      "the application\n",
      "-pron-\n",
      "a wide context\n",
      "division\n",
      "a sufficient justification\n",
      "-pron-\n",
      "the author\n",
      "future work\n",
      "the propose unit\n",
      "at least 10 k example\n",
      "a single expression\n",
      "few than 10 input\n",
      "the success rate\n",
      "under 65 %\n",
      "10 input\n",
      "what\n",
      "the use case\n",
      "such a unit\n",
      "even the nmu\n",
      "a step\n",
      "the way\n",
      "a more modular , general - purpose , or efficient architecture\n",
      "-pron- value\n",
      "some idea\n",
      "what\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.noun_chunks:\n",
    "    print(tok.lemma_.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors ['DT', 'NNS']\n",
      "the Neural Multiplication Unit ['DT', 'NNP', 'NNP', 'NNP']\n",
      "NMU ['NNP']\n",
      "a family ['DT', 'NN']\n",
      "arithmetic operations ['JJ', 'NNS']\n",
      "and * atomic operations ['CC', 'NFP', 'JJ', 'NNS']\n",
      "real numbers ['JJ', 'NNS']\n",
      "examples ['NNS']\n",
      "They ['PRP']\n",
      "a combination ['DT', 'NN']\n",
      "careful initialization ['JJ', 'NN']\n",
      "regularization ['NN']\n",
      "structural choices ['JJ', 'NNS']\n",
      "their model ['PRP$', 'NN']\n",
      "the previously published Neural Arithmetic Logic Unit ['DT', 'RB', 'VBN', 'NNP', 'NNP', 'NNP', 'NNP']\n",
      "The NALU ['DT', 'NNP']\n",
      "two additive sub-units ['CD', 'JJ', 'NN', 'NNS', 'NNS']\n",
      "the real and log-space ['DT', 'JJ', 'CC', 'NN', 'HYPH', 'NN']\n",
      "it ['PRP']\n",
      "both additions/subtractions ['DT', 'NNS', 'SYM', 'NNS']\n",
      "multiplications ['NNS']\n",
      "/divisions ['SYM', 'NNS']\n",
      "them ['PRP']\n",
      "a gating mechanism ['DT', 'VBG', 'NN']\n",
      "The NMU ['DT', 'NNP']\n",
      "the other hand ['DT', 'JJ', 'NN']\n",
      "a product ['DT', 'NN']\n",
      "affine transformations ['JJ', 'NNS']\n",
      "the input ['DT', 'NN']\n",
      "This choice ['DT', 'NN']\n",
      "the model ['DT', 'NN']\n",
      "learning divisions ['NN', 'NNS']\n",
      "the authors ['DT', 'NNS']\n",
      "the NALU case ['DT', 'NNP', 'NN']\n",
      "an a priori better initialization ['DT', 'FW', 'FW', 'JJR', 'NN']\n",
      "dispenses ['NNS']\n",
      "the gating ['DT', 'NN']\n",
      "The departures ['DT', 'NNS']\n",
      "the NALU architecture ['DT', 'NNP', 'NN']\n",
      "significant improvements ['JJ', 'NNS']\n",
      "the considered applications ['DT', 'VBN', 'NNS']\n",
      "extrapolation ['NN']\n",
      "the training domain ['DT', 'NN', 'NN']\n",
      "The paper ['DT', 'NN']\n",
      "one notable exception ['CD', 'JJ', 'NN']\n",
      "the form ['DT', 'NN']\n",
      "the loss function ['DT', 'NN', 'NN']\n",
      "the paper ['DT', 'NN']\n",
      "the scope ['DT', 'NN']\n",
      "the work ['DT', 'NN']\n",
      "the authors ['DT', 'NNS']\n",
      "the application ['DT', 'NN']\n",
      "it ['PRP']\n",
      "a wider context ['DT', 'JJR', 'NN']\n",
      "divisions ['NNS']\n",
      "a sufficient justification ['DT', 'JJ', 'NN']\n",
      "them ['PRP']\n",
      "the authors ['DT', 'NNS']\n",
      "future work ['JJ', 'NN']\n",
      "the proposed unit ['DT', 'VBN', 'NN']\n",
      "at least 10K examples ['RB', 'RBS', 'CD', 'NN', 'NNS']\n",
      "a single expression ['DT', 'JJ', 'NN']\n",
      "fewer than 10 inputs ['JJR', 'IN', 'CD', 'NNS']\n",
      "the success rate ['DT', 'NN', 'NN']\n",
      "under 65% ['IN', 'CD', 'NN']\n",
      "10 inputs ['CD', 'NNS']\n",
      "What ['WP']\n",
      "the use case ['DT', 'NN', 'NN']\n",
      "such a unit ['PDT', 'DT', 'NN']\n",
      "Even the NMU ['RB', 'DT', 'NNP']\n",
      "a step ['DT', 'NN']\n",
      "the way ['DT', 'NN']\n",
      "a more modular, general-purpose, or efficient architecture ['DT', 'RBR', 'JJ', ',', 'JJ', 'HYPH', 'NN', ',', 'CC', 'JJ', 'NN']\n",
      "its value ['PRP$', 'NN']\n",
      "some idea ['DT', 'NN']\n",
      "what ['WP']\n"
     ]
    }
   ],
   "source": [
    "for tok in doc.noun_chunks:\n",
    "    print(tok, [t.tag_ for t in tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of IN arithmetic operations\n",
      "* NFP atomic operations\n",
      "over IN real numbers\n",
      "of IN careful initialization\n",
      "and CC structural choices\n",
      "two CD additive sub\n",
      "the DT other hand\n",
      "of IN affine transformations\n",
      "priori FW better initialization\n",
      "to IN significant improvements\n",
      "one CD notable exception\n",
      "a DT wider context\n",
      "a DT sufficient justification\n",
      "a DT plausible way\n",
      "for IN future work\n",
      "a DT single expression\n",
      "or CC efficient architecture\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc)):\n",
    "    if doc[i].pos_ == \"ADJ\" and doc[i+1].tag_.startswith(\"NN\"):\n",
    "        print(doc[i-1], doc[i-1].tag_, doc[i], doc[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "authors\n",
      "propose\n",
      "the\n",
      "Neural\n",
      "Multiplication\n",
      "Unit\n",
      "(\n",
      "NMU\n",
      ")\n",
      ",\n",
      "which\n",
      "can\n",
      "learn\n",
      "to\n",
      "solve\n",
      "a\n",
      "family\n",
      "of\n",
      "arithmetic\n",
      "operations\n",
      "using\n",
      "-\n",
      ",\n",
      "+\n",
      "and\n",
      "*\n",
      "atomic\n",
      "operations\n",
      "over\n",
      "real\n",
      "numbers\n",
      "from\n",
      "examples\n",
      ".\n",
      "They\n",
      "show\n",
      "that\n",
      "a\n",
      "combination\n",
      "of\n",
      "careful\n",
      "initialization\n",
      ",\n",
      "regularization\n",
      "and\n",
      "structural\n",
      "choices\n",
      "allows\n",
      "their\n",
      "model\n",
      "to\n",
      "learn\n",
      "more\n",
      "reliably\n",
      "and\n",
      "efficiently\n",
      "than\n",
      "the\n",
      "previously\n",
      "published\n",
      "Neural\n",
      "Arithmetic\n",
      "Logic\n",
      "Unit\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "NALU\n",
      "consists\n",
      "of\n",
      "two\n",
      "additive\n",
      "sub\n",
      "-\n",
      "units\n",
      "in\n",
      "the\n",
      "real\n",
      "and\n",
      "log\n",
      "-\n",
      "space\n",
      "respectively\n",
      ",\n",
      "which\n",
      "allows\n",
      "it\n",
      "to\n",
      "handle\n",
      "both\n",
      "additions\n",
      "/\n",
      "subtractions\n",
      "and\n",
      "multiplications\n",
      "/\n",
      "divisions\n",
      ",\n",
      "and\n",
      "combines\n",
      "them\n",
      "with\n",
      "a\n",
      "gating\n",
      "mechanism\n",
      ".\n",
      "The\n",
      "NMU\n",
      "on\n",
      "the\n",
      "other\n",
      "hand\n",
      "simply\n",
      "learns\n",
      "a\n",
      "product\n",
      "of\n",
      "affine\n",
      "transformations\n",
      "of\n",
      "the\n",
      "input\n",
      ".\n",
      "This\n",
      "choice\n",
      "prevents\n",
      "the\n",
      "model\n",
      "from\n",
      "learning\n",
      "divisions\n",
      ",\n",
      "which\n",
      "the\n",
      "authors\n",
      "argue\n",
      "made\n",
      "learning\n",
      "unstable\n",
      "for\n",
      "the\n",
      "NALU\n",
      "case\n",
      ",\n",
      "but\n",
      "allows\n",
      "for\n",
      "an\n",
      "a\n",
      "priori\n",
      "better\n",
      "initialization\n",
      "and\n",
      "dispenses\n",
      "with\n",
      "the\n",
      "gating\n",
      "which\n",
      "is\n",
      "empirically\n",
      "hard\n",
      "to\n",
      "learn\n",
      ".\n",
      "The\n",
      "departures\n",
      "from\n",
      "the\n",
      "NALU\n",
      "architecture\n",
      "are\n",
      "well\n",
      "justified\n",
      "and\n",
      "lead\n",
      "to\n",
      "significant\n",
      "improvements\n",
      "for\n",
      "the\n",
      "considered\n",
      "applications\n",
      ",\n",
      "especially\n",
      "as\n",
      "far\n",
      "as\n",
      "extrapolation\n",
      "to\n",
      "inputs\n",
      "outside\n",
      "of\n",
      "the\n",
      "training\n",
      "domain\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "paper\n",
      "is\n",
      "mostly\n",
      "well\n",
      "written\n",
      "(\n",
      "one\n",
      "notable\n",
      "exception\n",
      ":\n",
      "the\n",
      "form\n",
      "of\n",
      "the\n",
      "loss\n",
      "function\n",
      "is\n",
      "not\n",
      "given\n",
      "explicitly\n",
      "anywhere\n",
      "in\n",
      "the\n",
      "paper\n",
      ")\n",
      "and\n",
      "well\n",
      "executed\n",
      ",\n",
      "but\n",
      "the\n",
      "scope\n",
      "of\n",
      "the\n",
      "work\n",
      "is\n",
      "somewhat\n",
      "limited\n",
      ",\n",
      "and\n",
      "the\n",
      "authors\n",
      "fail\n",
      "to\n",
      "properly\n",
      "motivate\n",
      "the\n",
      "application\n",
      "or\n",
      "put\n",
      "it\n",
      "in\n",
      "a\n",
      "wider\n",
      "context\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "First\n",
      ",\n",
      "divisions\n",
      "being\n",
      "difficult\n",
      "to\n",
      "handle\n",
      "does\n",
      "not\n",
      "constitute\n",
      "a\n",
      "sufficient\n",
      "justification\n",
      "for\n",
      "choosing\n",
      "to\n",
      "exclude\n",
      "them\n",
      ":\n",
      "the\n",
      "authors\n",
      "should\n",
      "at\n",
      "the\n",
      "very\n",
      "least\n",
      "propose\n",
      "a\n",
      "plausible\n",
      "way\n",
      "forward\n",
      "for\n",
      "future\n",
      "work\n",
      ".\n",
      "More\n",
      "generally\n",
      ",\n",
      "the\n",
      "proposed\n",
      "unit\n",
      "needs\n",
      "to\n",
      "be\n",
      "exposed\n",
      "to\n",
      "at\n",
      "least\n",
      "10\n",
      "K\n",
      "examples\n",
      "to\n",
      "learn\n",
      "a\n",
      "single\n",
      "expression\n",
      "with\n",
      "fewer\n",
      "than\n",
      "10\n",
      "inputs\n",
      "(\n",
      "and\n",
      "the\n",
      "success\n",
      "rate\n",
      "already\n",
      "drops\n",
      "to\n",
      "under\n",
      "65\n",
      "%\n",
      "for\n",
      "10\n",
      "inputs\n",
      ")\n",
      ".\n",
      "What\n",
      "would\n",
      "be\n",
      "the\n",
      "use\n",
      "case\n",
      "for\n",
      "such\n",
      "a\n",
      "unit\n",
      "?\n",
      "Even\n",
      "the\n",
      "NMU\n",
      "is\n",
      "only\n",
      "proposed\n",
      "as\n",
      "a\n",
      "step\n",
      "on\n",
      "the\n",
      "way\n",
      "to\n",
      "a\n",
      "more\n",
      "modular\n",
      ",\n",
      "general\n",
      "-\n",
      "purpose\n",
      ",\n",
      "or\n",
      "efficient\n",
      "architecture\n",
      ",\n",
      "its\n",
      "value\n",
      "is\n",
      "difficult\n",
      "to\n",
      "gauge\n",
      "without\n",
      "some\n",
      "idea\n",
      "of\n",
      "what\n",
      "that\n",
      "would\n",
      "look\n",
      "like\n",
      ".\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_py_tokens', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_disk', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'is_nered', 'is_parsed', 'is_sentenced', 'is_tagged', 'lang', 'lang_', 'mem', 'merge', 'noun_chunks', 'noun_chunks_iterator', 'print_tree', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_extension', 'similarity', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_disk', 'to_json', 'to_utf8_array', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7425985699627899538                  90                   0\n",
      "                   1]\n"
     ]
    }
   ],
   "source": [
    "for t in nparr:\n",
    "    if t[1] == \"ADJ\"\n",
    "#     print((t.view()))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f8218eb39a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
