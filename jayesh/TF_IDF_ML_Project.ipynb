{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF - IDF ML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWZVC0RNmUXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pePQGrtode-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "papers_2017 = pd.read_pickle(\"/content/drive/My Drive/ICLR_master_data/papers_2017_balanced.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr2MjacTmYpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "wordnet=WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4YcBwuHmdR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Year 2017\n",
        "corpus = []\n",
        "for i in papers_2017.keys():\n",
        "    abstract_text = papers_2017[i]['content']['abstract']\n",
        "    review = re.sub('[^a-zA-Z]', ' ', abstract_text)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]  \n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qy4UXHbmmLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "average_tf_idf_2017 = np.average(X, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHCDLYrnrlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(average_tf_idf_2017)\n",
        "tf_idf_2017 = dict(zip(papers_2017.keys() , average_tf_idf_2017))\n",
        "tf_idf_2017"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h16jzLqln1IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle_out = open(\"tf_idf_2017.pickle\",\"wb\")\n",
        "pickle.dump(tf_idf_2017, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}