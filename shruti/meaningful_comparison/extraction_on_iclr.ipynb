{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text and Tables Extraction on ICLR Data\n",
    "\n",
    "This notebook presents how to use our pipeline to extract text and tables from arXiv papers with available LaTeX source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from axcell.helpers.paper_extractor import PaperExtractor\n",
    "from axcell.data.paper_collection import PaperCollection\n",
    "from axcell.models.structure import TableType, TableStructurePredictor, TableTypePredictor\n",
    "# from axcell.helpers.results_extractor import ResultsExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Directories\n",
    "\n",
    "We cache the artifacts produced by successful execution of the intermediate steps of extraction pipeline. The `root` argument of `PaperExtractor` is a path under which the following directory structue is created:\n",
    "\n",
    "```\n",
    "root\n",
    "├── sources                       # e-print archives\n",
    "├── unpacked_sources              # extracted latex sources (generated automatically)\n",
    "├── htmls                         # converted html files (generated automatically)\n",
    "└── papers                        # extracted text and tables (generated automatically)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/singh_shruti/workspace/axcell_ws/axcell/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the iclr_arxiv map.\n",
    "\n",
    "We parse papers in the reverse manner. For iclr papers where arxivId is present, we extract tables, and extract bibitem from the leaderboard table csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/features/iclr_arxiv_map.pkl\", \"rb\") as f:\n",
    "    iclr_arxiv_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResultsExtractor??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run extraction one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path('data')\n",
    "MODELS_PATH = Path('models')\n",
    "\n",
    "SOURCES_PATH = ROOT_PATH / 'sources'\n",
    "PAPERS_PATH = ROOT_PATH / 'papers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = PaperExtractor(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.loss.BCEWithLogitsLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.AWD_LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.EmbeddingDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.WeightDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'fastai.text.models.awd_lstm.RNNDropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/singh_shruti/anaconda3/envs/axcell/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "[PID 35299] Load model table-type-classifier.pth\n"
     ]
    }
   ],
   "source": [
    "models_path = Path(MODELS_PATH)\n",
    "ttp = TableTypePredictor(models_path, \"table-type-classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_labels = {TableType.SOTA: 'leaderboard', TableType.ABLATION: 'ablation', TableType.IRRELEVANT: 'irrelevant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  0\n"
     ]
    }
   ],
   "source": [
    "status_count = 0\n",
    "err_count = 0\n",
    "unextracted_papers = []\n",
    "\n",
    "\n",
    "leaderboard_table_refs = defaultdict(dict)\n",
    "leaderboard_refs = defaultdict(dict)\n",
    "\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    #if k.startswith(\"2017\"):\n",
    "    if True:\n",
    "        if v[\"found\"]:\n",
    "            \n",
    "            # Keep saving after 10 entries\n",
    "            if status_count % 20 == 0:\n",
    "                print(\"Status: \", status_count)\n",
    "                with open(\"leaderboard_table_refs.pkl\", \"wb\") as some_file:\n",
    "                    pickle.dump(leaderboard_table_refs, some_file)\n",
    "                with open(\"leaderboard_refs.pkl\", \"wb\") as some_file:\n",
    "                    pickle.dump(leaderboard_refs, some_file)\n",
    "                    \n",
    "            try:\n",
    "#                 print(k, v[\"arxivId\"])\n",
    "                path_split = v[\"arxivId\"].split(\".\")\n",
    "\n",
    "                # Extraction\n",
    "                extract(SOURCES_PATH / path_split[0] / v[\"arxivId\"])\n",
    "\n",
    "                pc = PaperCollection.from_files(PAPERS_PATH)\n",
    "                paper = pc.get_by_id(v[\"arxivId\"])\n",
    "                \n",
    "                if not paper:\n",
    "                    unextracted_papers.append((k, v[\"arxivId\"]))\n",
    "                    continue\n",
    "\n",
    "                #leaderboard_table_refs[k][\"tcount\"] = len(paper.tables)\n",
    "                \n",
    "                if len(paper.tables) > 0:\n",
    "                    \n",
    "                    # Add table type if absent\n",
    "                    if paper.tables[0].gold_tags == \"\":\n",
    "                        tables_types = ttp.predict(paper, paper.tables)\n",
    "                        for table, table_type in zip(paper.tables, tables_types):\n",
    "                            table.gold_tags = table_labels[table_type]\n",
    "#                         print(\"check is retained: \", paper.tables[0].gold_tags)\n",
    "#                         break\n",
    "                    \n",
    "                    #Count the different types of tables\n",
    "                    table_type_count = [0, 0, 0]\n",
    "                    for tt in paper.tables:\n",
    "                        if tt.gold_tags.lower().strip() == \"leaderboard\":\n",
    "                            table_type_count[0] = table_type_count[0] + 1\n",
    "                        elif tt.gold_tags.lower().strip() == \"ablation\":\n",
    "                            table_type_count[1] = table_type_count[1] + 1\n",
    "                        elif tt.gold_tags.lower().strip() == \"irrelevant\":\n",
    "                            table_type_count[2] = table_type_count[2] + 1\n",
    "                        else:\n",
    "                            print(\"Unknown table type: \", tt.gold_tags)\n",
    "                    \n",
    "                    # Save table stat in leaderboard_table_refs\n",
    "                    leaderboard_table_refs[k][\"tcount\"] = [len(paper.tables), table_type_count[0], table_type_count[1], table_type_count[2]]\n",
    "                else:\n",
    "                    leaderboard_table_refs[k][\"tcount\"] = [0, 0, 0, 0]\n",
    "                \n",
    "                if (leaderboard_table_refs[k][\"tcount\"][1]+leaderboard_table_refs[k][\"tcount\"][2]) > 0:\n",
    "                    leaderboard_refs[k][\"refs\"] = {}\n",
    "                \n",
    "                # If sota/leaderboard tables present, extract references from them\n",
    "                if leaderboard_table_refs[k][\"tcount\"][1] > 0:\n",
    "                    leaderboard_refs[k][\"refs\"][\"ldb\"] = []\n",
    "                    leaderboard_refs[k][\"count\"] = 0\n",
    "                    for iterid, table in enumerate(paper.tables):\n",
    "                        idx = iterid + 1\n",
    "                        if table.gold_tags == \"leaderboard\":\n",
    "                            \n",
    "                            table_dir_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"]\n",
    "                            table_files = glob.glob(table_dir_path+\"/*.csv\")\n",
    "                            table_files_stripped = [tfs.rsplit(\"/\", 1)[1] for tfs in table_files]\n",
    "                            \n",
    "                            candidate_name = \"table_\" + \"{:02d}\".format(idx) + \".csv\"\n",
    "#                             print(\"Check: \", candidate_name)\n",
    "#                             print(table_dir_path+\"/*.csv\")\n",
    "#                             print(\"check: \", table_files)\n",
    "                            if candidate_name in table_files_stripped:\n",
    "                                cannot_use_f = open(table_dir_path + \"/\" + candidate_name, \"r\")\n",
    "                                for line in cannot_use_f:\n",
    "                                    m = re.findall(\"<ref id=[0-9a-zA-Z'-]*>[0-9]*</ref>\", line)\n",
    "                                    for iim in m:\n",
    "                                        leaderboard_refs[k][\"refs\"][\"ldb\"].append(iim)\n",
    "                                        leaderboard_refs[k][\"count\"] += 1\n",
    "                            else:\n",
    "                                print(\"For {} cannot find leaderboard table file: {}\".format(k, candidate_name))\n",
    "                            \n",
    "                    leaderboard_refs[k][\"refs\"][\"ldb\"] = list(set(leaderboard_refs[k][\"refs\"][\"ldb\"]))\n",
    "                    \n",
    "                if leaderboard_table_refs[k][\"tcount\"][2] > 0:\n",
    "                    leaderboard_refs[k][\"refs\"][\"abl\"] = []\n",
    "                    for iterid, table in enumerate(paper.tables):\n",
    "                        idx = iterid + 1\n",
    "                        if table.gold_tags == \"ablation\":\n",
    "                            \n",
    "                            table_dir_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"]\n",
    "                            table_files = glob.glob(table_dir_path+\"/*.csv\")\n",
    "                            table_files_stripped = [tfs.rsplit(\"/\", 1)[1] for tfs in table_files]\n",
    "                            \n",
    "                            candidate_name = \"table_\" + \"{:02d}\".format(idx) + \".csv\"\n",
    "                            if candidate_name in table_files_stripped:\n",
    "                                cannot_use_f = open(table_dir_path + \"/\" + candidate_name, \"r\")\n",
    "                                for line in cannot_use_f:\n",
    "                                    m = re.findall(\"<ref id=[0-9a-zA-Z'-]*>[0-9]*</ref>\", line)\n",
    "                                    for iim in m:\n",
    "                                        leaderboard_refs[k][\"refs\"][\"abl\"].append(iim)\n",
    "                            else:\n",
    "                                print(\"For {} cannot find ablation table file: {}\".format(k, candidate_name))\n",
    "                            \n",
    "                    leaderboard_refs[k][\"refs\"][\"abl\"] = list(set(leaderboard_refs[k][\"refs\"][\"abl\"]))\n",
    "                            \n",
    "                    #table_csv_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"] + \"/\" + \n",
    "                \n",
    "                status_count += 1\n",
    "                #break\n",
    "            except Exception as ex:\n",
    "                print(k, v[\"arxivId\"])\n",
    "                print(\"Error: \", ex)\n",
    "                err_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"leaderboard_table_refs.pkl\", \"wb\") as some_file:\n",
    "    pickle.dump(leaderboard_table_refs, some_file)\n",
    "with open(\"leaderboard_refs.pkl\", \"wb\") as some_file:\n",
    "    pickle.dump(leaderboard_refs, some_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  0\n",
      "What si happening;  1606.00704v3 ['1606', '00704v3']\n",
      "Paper is:  None\n",
      "2017_B1ElR4cgg 1606.00704v3\n",
      "Error:  'NoneType' object has no attribute 'tables'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# status_count = 0\n",
    "# err_count = 0\n",
    "\n",
    "# leaderboard_table_refs = defaultdict(dict)\n",
    "# leaderboard_refs = defaultdict(dict)\n",
    "\n",
    "# for k, v in iclr_arxiv_map.items():\n",
    "#     if k == \"2017_B1ElR4cgg\":\n",
    "# #     if True:\n",
    "#         if v[\"found\"]:\n",
    "            \n",
    "#             # Keep saving after 10 entries\n",
    "#             if status_count % 20 == 0:\n",
    "#                 print(\"Status: \", status_count)\n",
    "#                 with open(\"leaderboard_table_refs.pkl\", \"wb\") as some_file:\n",
    "#                     pickle.dump(leaderboard_table_refs, some_file)\n",
    "#                 with open(\"leaderboard_refs.pkl\", \"wb\") as some_file:\n",
    "#                     pickle.dump(leaderboard_refs, some_file)\n",
    "                    \n",
    "#             try:\n",
    "# #                 print(k, v[\"arxivId\"])\n",
    "#                 path_split = v[\"arxivId\"].split(\".\")\n",
    "#                 print(\"What si happening; \",  v[\"arxivId\"], path_split)\n",
    "\n",
    "#                 # Extraction\n",
    "#                 extract(SOURCES_PATH / path_split[0] / v[\"arxivId\"])\n",
    "\n",
    "#                 pc = PaperCollection.from_files(PAPERS_PATH)\n",
    "#                 paper = pc.get_by_id(v[\"arxivId\"])\n",
    "                \n",
    "#                 print(\"Paper is: \", paper)\n",
    "#                 #leaderboard_table_refs[k][\"tcount\"] = len(paper.tables)\n",
    "                \n",
    "#                 if len(paper.tables) > 0:\n",
    "                    \n",
    "#                     # Add table type if absent\n",
    "#                     if paper.tables[0].gold_tags == \"\":\n",
    "#                         tables_types = ttp.predict(paper, paper.tables)\n",
    "#                         for table, table_type in zip(paper.tables, tables_types):\n",
    "#                             table.gold_tags = table_labels[table_type]\n",
    "# #                         print(\"check is retained: \", paper.tables[0].gold_tags)\n",
    "# #                         break\n",
    "                    \n",
    "#                     #Count the different types of tables\n",
    "#                     table_type_count = [0, 0, 0]\n",
    "#                     for tt in paper.tables:\n",
    "#                         if tt.gold_tags.lower().strip() == \"leaderboard\":\n",
    "#                             table_type_count[0] = table_type_count[0] + 1\n",
    "#                         elif tt.gold_tags.lower().strip() == \"ablation\":\n",
    "#                             table_type_count[1] = table_type_count[1] + 1\n",
    "#                         elif tt.gold_tags.lower().strip() == \"irrelevant\":\n",
    "#                             table_type_count[2] = table_type_count[2] + 1\n",
    "#                         else:\n",
    "#                             print(\"Unknown table type: \", tt.gold_tags)\n",
    "                    \n",
    "#                     # Save table stat in leaderboard_table_refs\n",
    "#                     leaderboard_table_refs[k][\"tcount\"] = [len(paper.tables), table_type_count[0], table_type_count[1], table_type_count[2]]\n",
    "#                 else:\n",
    "#                     leaderboard_table_refs[k][\"tcount\"] = [0, 0, 0, 0]\n",
    "                \n",
    "#                 if (leaderboard_table_refs[k][\"tcount\"][1]+leaderboard_table_refs[k][\"tcount\"][2]) > 0:\n",
    "#                     leaderboard_refs[k][\"refs\"] = {}\n",
    "                \n",
    "#                 # If sota/leaderboard tables present, extract references from them\n",
    "#                 if leaderboard_table_refs[k][\"tcount\"][1] > 0:\n",
    "#                     leaderboard_refs[k][\"refs\"][\"ldb\"] = []\n",
    "#                     leaderboard_refs[k][\"count\"] = 0\n",
    "#                     for iterid, table in enumerate(paper.tables):\n",
    "#                         idx = iterid + 1\n",
    "#                         if table.gold_tags == \"leaderboard\":\n",
    "                            \n",
    "#                             table_dir_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"]\n",
    "#                             table_files = glob.glob(table_dir_path+\"/*.csv\")\n",
    "#                             table_files_stripped = [tfs.rsplit(\"/\", 1)[1] for tfs in table_files]\n",
    "                            \n",
    "#                             candidate_name = \"table_\" + \"{:02d}\".format(idx) + \".csv\"\n",
    "# #                             print(\"Check: \", candidate_name)\n",
    "# #                             print(table_dir_path+\"/*.csv\")\n",
    "# #                             print(\"check: \", table_files)\n",
    "#                             if candidate_name in table_files_stripped:\n",
    "#                                 cannot_use_f = open(table_dir_path + \"/\" + candidate_name, \"r\")\n",
    "#                                 for line in cannot_use_f:\n",
    "#                                     m = re.findall(\"<ref id=[0-9a-zA-Z'-]*>[0-9]*</ref>\", line)\n",
    "#                                     for iim in m:\n",
    "#                                         leaderboard_refs[k][\"refs\"][\"ldb\"].append(iim)\n",
    "#                                         leaderboard_refs[k][\"count\"] += 1\n",
    "#                             else:\n",
    "#                                 print(\"For {} cannot find leaderboard table file: {}\".format(k, candidate_name))\n",
    "                            \n",
    "#                     leaderboard_refs[k][\"refs\"][\"ldb\"] = list(set(leaderboard_refs[k][\"refs\"][\"ldb\"]))\n",
    "                    \n",
    "#                 if leaderboard_table_refs[k][\"tcount\"][2] > 0:\n",
    "#                     leaderboard_refs[k][\"refs\"][\"abl\"] = []\n",
    "#                     for iterid, table in enumerate(paper.tables):\n",
    "#                         idx = iterid + 1\n",
    "#                         if table.gold_tags == \"ablation\":\n",
    "                            \n",
    "#                             table_dir_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"]\n",
    "#                             table_files = glob.glob(table_dir_path+\"/*.csv\")\n",
    "#                             table_files_stripped = [tfs.rsplit(\"/\", 1)[1] for tfs in table_files]\n",
    "                            \n",
    "#                             candidate_name = \"table_\" + \"{:02d}\".format(idx) + \".csv\"\n",
    "#                             if candidate_name in table_files_stripped:\n",
    "#                                 cannot_use_f = open(table_dir_path + \"/\" + candidate_name, \"r\")\n",
    "#                                 for line in cannot_use_f:\n",
    "#                                     m = re.findall(\"<ref id=[0-9a-zA-Z'-]*>[0-9]*</ref>\", line)\n",
    "#                                     for iim in m:\n",
    "#                                         leaderboard_refs[k][\"refs\"][\"abl\"].append(iim)\n",
    "#                             else:\n",
    "#                                 print(\"For {} cannot find ablation table file: {}\".format(k, candidate_name))\n",
    "                            \n",
    "#                     leaderboard_refs[k][\"refs\"][\"abl\"] = list(set(leaderboard_refs[k][\"refs\"][\"abl\"]))\n",
    "                            \n",
    "#                     #table_csv_path = \"/home/singh_shruti/workspace/axcell_ws/axcell/axcell/notebooks/data/papers/\" + path_split[0] + \"/\" + v[\"arxivId\"] + \"/\" + \n",
    "                \n",
    "#                 status_count += 1\n",
    "#                 break\n",
    "#             except Exception as ex:\n",
    "#                 print(k, v[\"arxivId\"])\n",
    "#                 print(\"Error: \", ex)\n",
    "#                 err_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2020_ryxz8CVYDH', '1910.09464v2')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, v[\"arxivId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606.00704v3\n"
     ]
    }
   ],
   "source": [
    "arxiv_re = re.compile(r\"^(?P<arxiv_id>\\d{4}\\.\\d+(v\\d+)?)(\\..*)?$\")\n",
    "p = SOURCES_PATH / path_split[0] / v[\"arxivId\"]\n",
    "m = arxiv_re.match(p.name)\n",
    "arxiv_id = m.group('arxiv_id')\n",
    "print(arxiv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1606.00704v3', '1606.00704v3', 'v3', None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0], m[1], m[2], m[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606.00704v3\n"
     ]
    }
   ],
   "source": [
    "subpath = p.relative_to(ROOT_PATH / 'sources').parent / arxiv_id\n",
    "print(subpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('1606/1606.00704v3')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.relative_to(ROOT_PATH / 'sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_path = ROOT_PATH / 'unpacked_sources' / subpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axcell.helpers import LatexConverter, Unpack\n",
    "up = Unpack()\n",
    "up(p, unpack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_path = ROOT_PATH / 'htmls' / subpath / 'index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "LatexConversionError",
     "evalue": "LaTeXML was unable to convert source code of this paper",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContainerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/axcell/lib/python3.7/site-packages/axcell/helpers/latex_converter.py\u001b[0m in \u001b[0;36mlatex2html\u001b[0;34m(self, source_dir, output_dir, use_named_volumes)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arxivvanity/engrafo:b3db888fefa118eacf4f13566204b68ce100b3a6\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolumes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mContainerError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/axcell/lib/python3.7/site-packages/docker/models/containers.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, image, command, stdout, stderr, remove, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m             raise ContainerError(\n\u001b[0;32m--> 832\u001b[0;31m                 \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexit_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m             )\n",
      "\u001b[0;31mContainerError\u001b[0m: Command '['/files/latex2html.sh', 'index.html']' in image 'arxivvanity/engrafo:b3db888fefa118eacf4f13566204b68ce100b3a6' returned non-zero exit status 117: b\"\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/TeX.pool.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/eTeX.pool.ltxml... 0.01 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/pdfTeX.pool.ltxml... 0.01 sec) 0.20 sec)\\n(Loading /app/latexml/engrafo.ltxml... 0.00 sec)\\n(Loading /usr/src/latexml/lib/LaTeXML/Package/hyperref.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/url.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/nameref.sty.ltxml... 0.00 sec) 0.05 sec)\\n\\nlatexmlc (LaTeXML version 0.8.4)\\ninvoked as [/usr/local/bin/latexmlc --format html5 --nodefaultresources --mathtex --svg --verbose --timestamp 0 --path /app/latexml/packages/ --preload /app/latexml/engrafo.ltxml --preload /usr/src/latexml/lib/LaTeXML/Package/hyperref.sty.ltxml --xsltparameter SIMPLIFY_HTML:true --css /app/dist/css/index.css --javascript /app/dist/javascript/index.js adversarially_learned_inference.tex --dest /files/output/index.html]\\nprocessing started Wed Jun 17 13:48:58 2020\\n\\n(Digesting TeX adversarially_learned_inference...\\n(Processing content /files/source/adversarially_learned_inference.tex...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml... 0.17 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/article.cls.ltxml... 0.01 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/inputenc.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/utf8.def.ltxml... 0.01 sec) 0.02 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/fontenc.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/t1enc.def.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/base/t1enc.def...[#25][#50][#75][#100]\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/t1.fontmap.ltxml... 0.00 sec)[#125][#150][#175][#200][#225][#250][#275] 0.08 sec) 1.06 sec) 1.07 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/hyperref.sty.ltxml...\\nWarning:perl:warn Subroutine hyperref_setoption redefined\\n\\tat hyperref.sty.ltxml; line 87\\n\\tat /usr/local/share/perl/5.28.1/LaTeXML/Package/hyperref.sty.ltxml line 87, <$IN> line 6\\n\\tIn Core::Gullet[@0x55bc456963d0] /usr/local/share/perl/5.28.1/LaTeXML/Package/hyperref.sty.ltxml; line 87\\n 0.05 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/booktabs.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amsfonts.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amsmath.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amsbsy.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amstext.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amsopn.sty.ltxml... 0.00 sec) 0.03 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/amsthm.sty.ltxml... 0.01 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/graphicx.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/graphics.sty.ltxml... 0.00 sec) 0.02 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/nicefrac.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/microtype.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/tikz.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/frontendlayer/tikz.sty...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/pgf.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.tex...[#25][#50][#75][#100][#125][#150] 0.02 sec) 0.09 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def...[#25][#50][#75][#100]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty...[#25][#50][#75][#100] 0.02 sec)[#125][#150][#175] 0.07 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/pgf.revision.tex... 0.00 sec)[#25][#50][#75] 0.02 sec) 0.41 sec)[#25]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/pgfkeys.code.tex.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000] 0.15 sec) 0.48 sec) 0.49 sec)[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg...[#25] 0.00 sec)Driver file for pgf: pgfsys-latexml.def\\n[#1725]\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/pgfsys-latexml.def.ltxml... 0.02 sec) 1.26 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200] 0.03 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.tex...[#25][#50] 0.01 sec) 1.31 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/keyval.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty...[#25][#50][#75] 0.01 sec) 0.01 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/xcolor.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/color.sty.ltxml... 0.02 sec) 0.10 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/pgfmath.code.tex.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250] 0.07 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975] 0.29 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800] 0.45 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonometric.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550] 1.34 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225] 0.05 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison.code.tex...[#25][#50][#75][#100][#125][#150][#175] 0.32 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325] 0.14 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code.tex...[#25][#50][#75][#100] 0.06 sec)[#250]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325] 0.16 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerarithmetics.code.tex...[#25][#50][#75][#100] 0.09 sec) 2.66 sec)[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525] 3.06 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700][#1725][#1750][#1775][#1800][#1825][#1850][#1875][#1900][#1925][#1950][#1975][#2000][#2025][#2050][#2075][#2100][#2125][#2150][#2175][#2200][#2225][#2250][#2275][#2300][#2325][#2350][#2375][#2400][#2425][#2450][#2475][#2500][#2525][#2550][#2575][#2600][#2625][#2650][#2675] 0.69 sec)[#25] 3.75 sec) 3.79 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275] 0.27 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475] 0.15 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650] 0.09 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750] 0.13 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275] 0.02 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformations.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800] 0.05 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex...[#25][#50][#75][#100][#125] 0.01 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.tex...[#25][#50][#75][#100] 0.00 sec)[#25]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550] 0.03 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250] 0.62 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575] 0.05 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525] 0.06 sec) 0.10 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200] 0.02 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300] 0.03 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275] 0.03 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorerdf.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225] 0.02 sec) 5.44 sec) 6.90 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300] 0.28 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550] 0.11 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65.sty...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700] 0.43 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18.sty...[#25] 0.02 sec) 8.19 sec) 8.19 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgffor.sty...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfkeys.sty... 0.00 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/pgf/math/pgfmath.sty... 0.01 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgffor.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750] 0.16 sec) 0.21 sec)\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/tikz.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/pgflibraryplothandlers.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100] 0.14 sec)[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmodulematrix.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650] 0.08 sec)[#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700][#1725][#1750][#1775][#1800][#1825][#1850][#1875][#1900][#1925][#1950][#1975][#2000][#2025][#2050][#2075][#2100][#2125][#2150][#2175][#2200][#2225][#2250][#2275][#2300][#2325][#2350][#2375][#2400][#2425][#2450][#2475][#2500][#2525][#2550][#2575][#2600][#2625][#2650][#2675][#2700][#2725][#2750][#2775][#2800][#2825][#2850][#2875][#2900][#2925][#2950][#2975][#3000][#3025][#3050][#3075][#3100][#3125][#3150][#3175][#3200][#3225][#3250][#3275][#3300][#3325][#3350][#3375][#3400][#3425][#3450][#3475][#3500][#3525][#3550][#3575][#3600][#3625][#3650][#3675][#3700][#3725][#3750][#3775][#3800][#3825][#3850][#3875][#3900][#3925][#3950][#3975][#4000][#4025][#4050][#4075][#4100][#4125][#4150][#4175][#4200][#4225][#4250][#4275][#4300][#4325][#4350][#4375][#4400][#4425][#4450][#4475][#4500][#4525][#4550][#4575][#4600][#4625][#4650][#4675][#4700][#4725][#4750][#4775][#4800][#4825][#4850][#4875][#4900][#4925][#4950][#4975][#5000][#5025][#5050][#5075][#5100][#5125][#5150][#5175][#5200][#5225][#5250][#5275][#5300][#5325][#5350][#5375][#5400][#5425][#5450][#5475][#5500]\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibrarytopaths.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375] 0.12 sec) 1.89 sec) 10.30 sec) 10.31 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/subcaption.sty.ltxml...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/caption.sty.ltxml... 0.01 sec) 0.03 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/algorithm.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/algorithms/algorithm.sty...\\nInfo:misdefined:UTF8 input isn't valid under encoding UTF8\\n\\tat algorithm.sty; line 11 col 0 - line 11 col 0\\n[#25]\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/float.sty.ltxml... 0.01 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/ifthen.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/base/ifthen.sty...[#25][#50][#75][#100][#125][#150] 0.01 sec) 0.01 sec)[#50][#75] 0.07 sec) 0.07 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/algpseudocode.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/algorithmicx/algpseudocode.sty...\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/algorithmicx.sty.ltxml...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/latex/algorithmicx/algorithmicx.sty...Document Style algorithmicx 1.2 - a greatly improved `algorithmic' style\\n[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775] 0.22 sec) 0.22 sec)Document Style - pseudocode environments for use with the `algorithmicx' style\\n[#25][#50][#75] 1.38 sec) 1.38 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/bm.sty.ltxml... 0.00 sec)\\nWarning:missing_file:iclr2017_conference Can't find binding for package iclr2017_conference\\n\\tat adversarially_learned_inference.tex; line 23 col 0 - line 23 col 15\\n\\tAnticipate undefined macros or environments\\n\\tsearch paths are /files/source, /app/latexml/packages/, /files/source\\n\\tIn Core::Definition::Constructor[\\\\usepac... /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml; line 764\\n\\nInfo:dependencies:dependencies Loading dependencies for /files/source/iclr2017_conference.sty: fancyhdr,natbib,eso-pic\\n\\tat adversarially_learned_inference.tex; line 23 col 0 - line 23 col 15\\n\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/fancyhdr.sty.ltxml... 0.00 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/natbib.sty.ltxml... 0.02 sec)\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/times.sty.ltxml... 0.00 sec)[#25]\\nTIKZ LIBRARY shapes\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.code.tex...\\nTIKZ LIBRARY shapes.geometric\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.geometric.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.geometric.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700][#1725][#1750][#1775][#1800][#1825][#1850][#1875][#1900][#1925][#1950][#1975][#2000][#2025][#2050][#2075][#2100][#2125][#2150][#2175][#2200][#2225][#2250][#2275][#2300][#2325][#2350][#2375][#2400][#2425][#2450][#2475][#2500][#2525][#2550][#2575][#2600][#2625][#2650][#2675][#2700][#2725][#2750][#2775][#2800][#2825][#2850][#2875][#2900][#2925][#2950][#2975][#3000][#3025][#3050][#3075][#3100][#3125][#3150][#3175][#3200][#3225][#3250][#3275][#3300][#3325][#3350][#3375][#3400][#3425][#3450][#3475][#3500][#3525][#3550][#3575][#3600][#3625][#3650][#3675][#3700][#3725][#3750][#3775][#3800][#3825][#3850][#3875][#3900][#3925][#3950][#3975][#4000][#4025][#4050][#4075][#4100][#4125][#4150][#4175][#4200][#4225][#4250][#4275][#4300][#4325][#4350][#4375][#4400] 1.42 sec) 1.46 sec)\\nTIKZ LIBRARY shapes.misc\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.misc.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.misc.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125] 0.41 sec) 0.44 sec)\\nTIKZ LIBRARY shapes.symbols\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.symbols.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.symbols.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975]\\nInfo:misdefined:UTF8 input isn't valid under encoding UTF8\\n\\tat pgflibraryshapes.symbols.code.tex; line 984 col 0 - line 984 col 0\\n[#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175]\\nInfo:misdefined:UTF8 input isn't valid under encoding UTF8\\n\\tat pgflibraryshapes.symbols.code.tex; line 1186 col 0 - line 1186 col 0\\n[#1200]\\nInfo:misdefined:UTF8 input isn't valid under encoding UTF8\\n\\tat pgflibraryshapes.symbols.code.tex; line 1224 col 0 - line 1224 col 0\\n[#1225][#1250]\\nInfo:misdefined:UTF8 input isn't valid under encoding UTF8\\n\\tat pgflibraryshapes.symbols.code.tex; line 1267 col 0 - line 1267 col 0\\n[#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700][#1725][#1750][#1775][#1800][#1825][#1850][#1875][#1900][#1925][#1950][#1975][#2000][#2025][#2050][#2075][#2100][#2125][#2150][#2175][#2200][#2225][#2250][#2275][#2300][#2325][#2350][#2375][#2400][#2425][#2450][#2475][#2500][#2525][#2550][#2575][#2600][#2625][#2650][#2675][#2700][#2725][#2750][#2775] 0.77 sec) 0.80 sec)\\nTIKZ LIBRARY shapes.arrows\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.arrows.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.arrows.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350][#1375][#1400][#1425][#1450][#1475][#1500][#1525][#1550][#1575][#1600][#1625][#1650][#1675][#1700][#1725][#1750][#1775][#1800][#1825][#1850][#1875][#1900][#1925][#1950][#1975][#2000][#2025][#2050][#2075][#2100][#2125][#2150][#2175][#2200][#2225][#2250][#2275][#2300][#2325][#2350] 0.47 sec) 0.50 sec)\\nTIKZ LIBRARY shapes.callouts\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.callouts.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.callouts.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950] 0.27 sec)[#25] 0.30 sec)\\nTIKZ LIBRARY shapes.multipart\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibraryshapes.multipart.code.tex...\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/libraries/shapes/pgflibraryshapes.multipart.code.tex...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800][#825][#850][#875][#900][#925][#950][#975][#1000][#1025][#1050][#1075][#1100][#1125][#1150][#1175][#1200][#1225][#1250][#1275][#1300][#1325][#1350] 0.85 sec)[#25] 0.90 sec) 4.43 sec)\\nTIKZ LIBRARY positioning\\n\\n(Processing definitions /usr/share/texlive/texmf-dist/tex/generic/pgf/frontendlayer/tikz/libraries/tikzlibrarypositioning.code.tex...[#25][#50][#75][#100] 0.06 sec)[#50]\\n(Loading /usr/local/share/perl/5.28.1/LaTeXML/Package/verbatim.sty.ltxml... 0.00 sec)ABD: EveryShipout initializing macros\\n[#75][#100][#125]\\nError:undefined:\\\\node The token T_CS[\\\\node] is not defined.\\n\\tat adversarially_learned_inference.tex; line 149 col 13 - line 149 col 13\\n\\tDefining it now as <ltx:ERROR/>\\n\\tIn Core::Stomach[@0x55bc4569d6e0] /files/source/adversarially_learned_inference.tex; from line 149 col 13 to line 149 col 13\\n[#150]\\nError:undefined:\\\\draw The token T_CS[\\\\draw] is not defined.\\n\\tat adversarially_learned_inference.tex; line 157 col 13 - line 157 col 13\\n\\tDefining it now as <ltx:ERROR/>\\n\\tIn Core::Stomach[@0x55bc4569d6e0] /files/source/adversarially_learned_inference.tex; from line 157 col 13 to line 157 col 13\\n\\nError:unexpected:_ Script _ can only appear in math mode\\n\\tat adversarially_learned_inference.tex; line 157 col 29 - line 157 col 29\\n\\tIn Core::Definition::Primitive[Subscript] /usr/local/share/perl/5.28.1/LaTeXML/Package/TeX.pool.ltxml; line 3791\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:_ Script _ can only appear in math mode\\n\\tat adversarially_learned_inference.tex; line 159 col 29 - line 159 col 29\\n\\tIn Core::Definition::Primitive[Subscript] /usr/local/share/perl/5.28.1/LaTeXML/Package/TeX.pool.ltxml; line 3791\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:\\\\endgroup Attempt to close non-boxing group\\n\\tat adversarially_learned_inference.tex; line 165 col 0 - line 165 col 17\\n\\tcurrent frame is mode-switch to text due to T_CS[\\\\begin{document}] adversarially_learned_inference.tex; line 53 col 0 - line 53 col 37\\n\\tIn Core::Stomach[@0x55bc4569d6e0] /files/source/adversarially_learned_inference.tex; from line 165 col 0 to line 165 col 17\\n\\t <= Core::Definition::Primitive[\\\\endgroup] <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:\\\\caption Use of \\\\caption outside any known float\\n\\tat adversarially_learned_inference.tex; line 166 col 12 - line 166 col 12\\n\\tIn Core::Definition::Constructor[\\\\@@gene... /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml; line 2980\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:\\\\end{figure} Can't close environment figure;\\n\\tat adversarially_learned_inference.tex; line 167 col 0 - line 167 col 12\\n\\tCurrent are:\\n\\tdocument adversarially_learned_inference.tex; line 53 col 0 - line 53 col 37\\n\\tIn Core::Definition::Constructor[\\\\end{fi... /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml; line 3000\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n[#175][#200][#225][#250][#275][#300][#325][#350][#375][#400][#425][#450][#475][#500][#525][#550][#575][#600][#625][#650][#675][#700][#725][#750][#775][#800]\\nInfo:expected:bibliography Couldn't find all bib files, using adversarially_learned_inference.bbl instead\\n\\tat adversarially_learned_inference.tex; line 812 col 0 - line 812 col 27\\n\\n(Processing content /files/source/adversarially_learned_inference.bbl...[#25][#50][#75][#100][#125][#150][#175][#200][#225][#250] 1.57 sec)[#825][#850][#875][#900][#925][#950][#975][#1000]\\nError:unexpected:_ Script _ can only appear in math mode\\n\\tat adversarially_learned_inference.tex; line 1021 col 29 - line 1021 col 29\\n\\tIn Core::Definition::Primitive[Subscript] /usr/local/share/perl/5.28.1/LaTeXML/Package/TeX.pool.ltxml; line 3791\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:_ Script _ can only appear in math mode\\n\\tat adversarially_learned_inference.tex; line 1022 col 29 - line 1022 col 29\\n\\tIn Core::Definition::Primitive[Subscript] /usr/local/share/perl/5.28.1/LaTeXML/Package/TeX.pool.ltxml; line 3791\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n[#1025]\\nError:unexpected:\\\\endgroup Attempt to close non-boxing group\\n\\tat adversarially_learned_inference.tex; line 1025 col 0 - line 1025 col 17\\n\\tcurrent frame is boxing group due to Initialization \\n\\tIn Core::Stomach[@0x55bc4569d6e0] /files/source/adversarially_learned_inference.tex; from line 1025 col 0 to line 1025 col 17\\n\\t <= Core::Definition::Primitive[\\\\endgroup] <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:\\\\caption Use of \\\\caption outside any known float\\n\\tat adversarially_learned_inference.tex; line 1026 col 12 - line 1026 col 12\\n\\tIn Core::Definition::Constructor[\\\\@@gene... /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml; line 2980\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nError:unexpected:\\\\end{figure} Can't close environment figure;\\n\\tat adversarially_learned_inference.tex; line 1028 col 0 - line 1028 col 12\\n\\tCurrent are:\\n\\tIn Core::Definition::Constructor[\\\\end{fi... /usr/local/share/perl/5.28.1/LaTeXML/Package/LaTeX.pool.ltxml; line 3000\\n\\t <= Core::Stomach[@0x55bc4569d6e0] <= ...\\n\\nFatal:unexpected:<endgroup> Attempt to pop last locked stack frame\\n\\tat adversarially_learned_inference.tex; line 1028 col 0 - line 1028 col 12\\n\\tStack Trace:\\n\\t\\tLaTeXML::Core::State=HASH(0x55bc4569d...->popFrame() @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Stomach.pm line 283\\n\\tCore::Stomach[@0x55bc4569d6e0]->popStackFrame(0) @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Stomach.pm line 321\\n\\tCore::Stomach[@0x55bc4569d6e0]->egroup() @ /usr/local/share/perl/5.28.1/LaTeXML/Package.pm line 1625\\n\\tLaTeXML::Package::__ANON__(Core::Stomach[@0x55bc4569d6e0],Whatsit[\\\\end{figure}]) @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Definition/Primitive.pm line 47\\n\\tCore::Definition::Constructor[\\\\end{fi...->executeAfterDigest(Core::Stomach[@0x55bc4569d6e0],Whatsit[\\\\end{figure}]) @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Definition/Constructor.pm line 113\\n\\tCore::Definition::Constructor[\\\\end{fi...->invoke(Core::Stomach[@0x55bc4569d6e0]) @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Stomach.pm line 174\\n\\tCore::Stomach[@0x55bc4569d6e0]->invokeToken(T_CS[\\\\end{figure}]) @ /usr/local/share/perl/5.28.1/LaTeXML/Core/Stomach.pm line 93\\n\\tCore::Stomach[@0x55bc4569d6e0]->digestNextBody() @ /usr/local/share/perl/5.28.1/LaTeXML/Core.pm line 166\\n\\tCore[@0x55bc456956b0]->finishDigestion() @ /usr/local/share/perl/5.28.1/LaTeXML/Core.pm line 155\\n\\tLaTeXML::Core::__ANON__(LaTeXML::Core::State=HASH(0x55bc4569d...) @ /usr/local/share/perl/5.28.1/LaTeXML/Core.pm line 245\\n\\tCore[@0x55bc456956b0]->withState(CODE(0x55bc45690368)) @ /usr/local/share/perl/5.28.1/LaTeXML/Core.pm line 157\\n\\tCore[@0x55bc456956b0]->digestFile('adversarially_learned_inference.tex','preamble',undef,'postamble',undef,'mode','TeX','noinitialize',1,...) @ /usr/local/share/perl/5.28.1/LaTeXML.pm line 227\\n\\teval {...} @ /usr/local/share/perl/5.28.1/LaTeXML.pm line 221\\n\\tLaTeXML=HASH(0x55bc456916e0)->convert('adversarially_learned_inference.tex') @ /usr/local/bin/latexmlc line 113\\n\\n2 warnings; 12 errors; 1 fatal error; 2 undefined macros[\\\\node, \\\\draw]; 1 missing file[iclr2017_conference.sty]\\n\\n\\nConversion complete: 2 warnings; 12 errors; 1 fatal error; 2 undefined macros[\\\\node, \\\\draw]; 1 missing file[iclr2017_conference.sty].\\nStatus:conversion:3\\n2 warnings; 12 errors; 1 fatal error; 2 undefined macros[\\\\node, \\\\draw]; 1 missing file[iclr2017_conference.sty]\\nError! Did not write file /files/output/index.html\\nEngrafo rendering failed: Error: latexmlc exited with status 1\\n    at ChildProcess.latexmlc.on.code (/app/src/converter/latexml.js:102:23)\\n    at emitTwo (events.js:126:13)\\n    at ChildProcess.emit (events.js:214:7)\\n    at maybeClose (internal/child_process.js:915:16)\\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:209:5)\\n\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLatexConversionError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1679db9745e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlatex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatexConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/axcell/lib/python3.7/site-packages/axcell/helpers/latex_converter.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self, source_dir)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatex2html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"index.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mContainerError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/axcell/lib/python3.7/site-packages/axcell/helpers/latex_converter.py\u001b[0m in \u001b[0;36mlatex2html\u001b[0;34m(self, source_dir, output_dir, use_named_volumes)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mContainerError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMAGIC_EXIT_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLatexConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LaTeXML was unable to convert source code of this paper\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Unable to find any suitable tex file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLatexConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to find any suitable tex file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLatexConversionError\u001b[0m: LaTeXML was unable to convert source code of this paper"
     ]
    }
   ],
   "source": [
    "latex = LatexConverter()\n",
    "html = latex.to_html(unpack_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "html_path.write_text(html, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processing-error'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(SOURCES_PATH / path_split[0] / v[\"arxivId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[\"arxivId\"] = \"1606.00704v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'2017_B1-Hhnslg': {'tcount': [6, 4, 2, 0]}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_table_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'2017_B1-Hhnslg': {'refs': [\"<ref id='bib-bib20'>20</ref>\",\n",
       "               \"<ref id='bib-bib36'>36</ref>\"],\n",
       "              'count': 70}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  name 'c' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(c)\n",
    "except Exception as ex:\n",
    "    print(\"Error: \", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/singh_shruti/workspace/axcell_ws/axcell/axcell/data',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/scripts',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/errors.py',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/pipeline_logger.py',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/__init__.py',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/helpers',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/config.py',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/mocks',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/loggers.py',\n",
       " '/home/singh_shruti/workspace/axcell_ws/axcell/axcell/models']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"/home/singh_shruti/workspace/axcell_ws/axcell/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/singh_shruti/workspace/axcell_ws/axcell/axcell/notebooks/data/papers/1703/1703.05175v2/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOTA\n",
      "SOTA\n",
      "SOTA\n",
      "ABLATION\n",
      "SOTA\n",
      "ABLATION\n"
     ]
    }
   ],
   "source": [
    "for x in tables_types:\n",
    "    print(x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__', '__doc__', '__module__', 'name', 'value']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tables_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOTA'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_types[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_types[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<enum 'TableType'>, 'An enumeration.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_types[0].__class__, tables_types[0].__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.tables[0].gold_tags == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leaderboard'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_labels[TableType.SOTA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "\"{:02d}\".format(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "t = \"ResNet-50,Encoding [<ref id='bib-bib36'>36</ref>],FPN [<ref id='bib-bib20'>20</ref>],37.87\"\n",
    "m = re.findall(\"<ref id=[0-9a-zA-Z'-]*>[0-9]*</ref>\", t)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<ref id='bib-bib36'>36</ref>\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case there's a single e-print archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tree {ROOT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = PaperExtractor(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract text and tables from a single paper just pass the path to the archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES_PATH = ROOT_PATH / 'sources'\n",
    "extract(SOURCES_PATH / '1903' / '1903.11816v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES_PATH = ROOT_PATH / 'sources'\n",
    "extract(SOURCES_PATH / '1611' / '1611.02200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 4 {ROOT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subdirectory structure under `sources` directory will be replicated in the other top-level directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 4 {ROOT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted data is stored in `papers` directory. We can read it using `PaperCollection` class. `PaperCollection` is a wrapper for `list` of papers with additional functions added for convenience. Due to large number of papers it is recommended to load the dataset in parallel (default uses number of processes equal to number of CPU cores) and store it in a pickle file. Set jobs=1 to disable multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axcell.data.paper_collection import PaperCollection\n",
    "\n",
    "PAPERS_PATH = ROOT_PATH / 'papers'\n",
    "pc = PaperCollection.from_files(PAPERS_PATH)\n",
    "# pc.to_pickle('mypapers.pkl')\n",
    "# pc = PaperCollection.from_pickle('mypapers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = pc.get_by_id('1903.11816v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.text.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[0]\n",
    "# print(paper.tables[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "paper.tables[0].__dict__[\"df\"][0][:].iloc[1]\n",
    "# , paper.tables[0].__dict__[\"df\"][1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[0].__dict__[\"df\"][0][:], paper.tables[0].__dict__[\"df\"][1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.value for i in paper.tables[1].__dict__[\"df\"][0][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[4].__dict__[\"df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As *FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation* (Wu et al., 2019) is present in our **SegmentedTables** dataset, we can use `PaperCollection` to import annotations (table segmentation and results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axcell.helpers.datasets import read_tables_annotations\n",
    "\n",
    "V1_URL = 'https://github.com/paperswithcode/axcell/releases/download/v1.0/'\n",
    "SEGMENTED_TABLES_URL = V1_URL + 'segmented-tables.json.xz'\n",
    "\n",
    "segmented_tables = read_tables_annotations(SEGMENTED_TABLES_URL)\n",
    "\n",
    "pc = PaperCollection.from_files(PAPERS_PATH, annotations=segmented_tables.to_dict('record'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = pc.get_by_id('1903.11816')\n",
    "paper.tables[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.cells_gold_tags_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.tables[4].sota_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Extraction\n",
    "\n",
    "For a single paper extraction can take from several seconds to a few minutes (the longest phase of converting LaTeX source into HTML is timed-out after 5 minutes), so to process multiple files we run extraction in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "# access extract from the global context to avoid serialization\n",
    "def extract_single(file): return extract(file)\n",
    "\n",
    "files = sorted([path for path in SOURCES_PATH.glob('**/*') if path.is_file()])\n",
    "\n",
    "statuses = Parallel(backend='multiprocessing', n_jobs=-1)(delayed(extract_single)(file) for file in files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:axcell] *",
   "language": "python",
   "name": "conda-env-axcell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
