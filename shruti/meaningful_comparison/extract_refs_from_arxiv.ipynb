{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data processing\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "# For file management/retrieval/download\n",
    "from urllib.request import urlretrieve\n",
    "import wget\n",
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "import  tarfile\n",
    "# pretty print\n",
    "from pprint import pprint\n",
    "# Error\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4897"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../../PaperAcceptancePrediction/shruti/features/iclr_arxiv_map.pkl\", \"rb\") as f:\n",
    "    iclr_arxiv_map = pickle.load(f)\n",
    "len(iclr_arxiv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files:  2506\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"/home/singh_shruti/workspace/ICLR_arxiv_dump/*\")\n",
    "print(\"Total files: \", len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2498"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_source_files = [f.rsplit(\"/\", 1)[1] for f in files]\n",
    "len(arxiv_source_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1802.04948v1\n",
      "1711.01970v1\n",
      "1806.04640v1\n",
      "1812.11240v2\n",
      "1805.09980v1\n",
      "1810.06544v1\n",
      "1805.09208v1\n",
      "1909.05352v2\n"
     ]
    }
   ],
   "source": [
    "# Find papers with arxiv_id but no source files\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    if v[\"found\"] and not v[\"arxivId\"] in arxiv_source_files:\n",
    "        #print(k)\n",
    "        print(v[\"arxivId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    if v[\"found\"]:\n",
    "        c += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2504"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "# Find papers with arxiv_id but no source files\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    if v[\"found\"] and v[\"arxivId\"] in arxiv_source_files:\n",
    "        c+= 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideally acc to 1-1 matching, count should be 2504, but is: 2494\n",
      "1802.04412v4 ['2018_Bk6qQGWRb', '2019_B1e7hs05Km']\n",
      "1806.03852v4 ['2018_ByJWeR1AW', '2020_H1eqOnNYDH']\n",
      "1706.01566v4 ['2018_HyBbjW-RW', '2019_SJf_XhCqKm']\n",
      "1810.05934v4 ['2018_S1Y7OOlRZ', '2019_S1MAriC5F7']\n",
      "1802.04948v3 ['2018_SJvu-GW0b', '2019_Ske7ToC5Km']\n",
      "1711.01970v2 ['2018_SyBBgXWAZ', '2019_BklCusRct7']\n",
      "1812.10607v1 ['2019_Bkeuz20cYm', '2020_ByedzkrKvH']\n",
      "1806.04640v2 ['2019_H1eRBoC9FX', '2020_S1et1lrtwr']\n",
      "1907.03179v1 ['2019_S14h9sCqYm', '2020_SygfNCEYDH']\n",
      "1805.09980v2 ['2019_SJz6MnC5YQ', '2020_r1e0G04Kvr']\n",
      "1810.06544v4 ['2019_SyehMhC9Y7', '2020_Skl4mRNYDr']\n",
      "1805.09208v2 ['2019_rklwwo05Ym', '2020_rJxwDTVFDB']\n"
     ]
    }
   ],
   "source": [
    "# find errs of incorrect matchings?\n",
    "rev_map = defaultdict(list)\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    if v[\"found\"]:\n",
    "        rev_map[v[\"arxivId\"]].append(k)\n",
    "\n",
    "print(\"Ideally acc to 1-1 matching, count should be 2504, but is:\", len(rev_map))\n",
    "        \n",
    "for k in rev_map:\n",
    "    if len(rev_map[k]) > 1:\n",
    "        print(k, rev_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2019_S14h9sCqYm', 'title': 'Weakly-supervised Knowledge Graph Alignment with Adversarial Learning', 'abstract': 'Aligning knowledge graphs from different sources or languages, which aims to align both the entity and relation, is critical to a variety of applications such as knowledge graph construction and question answering. Existing methods of knowledge graph alignment usually rely on a large number of aligned knowledge triplets to train effective models. However, these aligned triplets may not be available or are expensive to obtain for many domains. Therefore, in this paper we study how to design fully-unsupervised methods or weakly-supervised methods, i.e., to align knowledge graphs without or with only a few aligned triplets. We propose an unsupervised framework based on adversarial training, which is able to map the entities and relations in a source knowledge graph to those in a target knowledge graph. This framework can be further seamlessly integrated with existing supervised methods, where only a limited number of aligned triplets are utilized as guidance. Experiments on real-world datasets prove the effectiveness of our proposed approach in both the weakly-supervised and unsupervised settings.', 'authors': ['Meng Qu', 'Jian Tang', 'Yoshua Bengio'], 'label': 'Reject', 'found': True, 'arxivId': '1907.03179v1'}\n",
      "\n",
      "\n",
      "{'id': '2020_SygfNCEYDH', 'title': 'Weakly-supervised Knowledge Graph Alignment with Adversarial Learning', 'abstract': 'This paper studies aligning knowledge graphs from different sources or languages. Most existing methods train supervised methods for the alignment, which usually require a large number of aligned knowledge triplets. However, such a large number of aligned knowledge triplets may not be available or are expensive to obtain in many domains. Therefore, in this paper we propose to study aligning knowledge graphs in fully-unsupervised or weakly-supervised fashion, i.e., without or with only a few aligned triplets. We propose an unsupervised framework to align the entity and relation embddings of different knowledge graphs with an adversarial learning framework. Moreover, a regularization term which maximizes the mutual information between the embeddings of different knowledge graphs is used to mitigate the problem of mode collapse when learning the alignment functions. Such a framework can be further seamlessly integrated with existing supervised methods by utilizing a limited number of aligned triples as guidance. Experimental results on multiple datasets prove the effectiveness of our proposed approach in both the unsupervised and the weakly-supervised settings.', 'authors': ['Meng Qu', 'Jian Tang', 'Yoshua Bengio'], 'label': 'Reject', 'found': True, 'arxivId': '1907.03179v1'}\n"
     ]
    }
   ],
   "source": [
    "#inspecting the double matched papers:\n",
    "# 1812.10607v1 ['2019_Bkeuz20cYm', '2020_ByedzkrKvH']\n",
    "print(iclr_arxiv_map[\"2019_S14h9sCqYm\"])\n",
    "print(\"\\n\")\n",
    "print(iclr_arxiv_map[\"2020_SygfNCEYDH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now all duplicate papers resolved and downloaded all versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearwise_found = {k:defaultdict(int) for k in [2017, 2018, 2019, 2020]} \n",
    "\n",
    "for k in iclr_arxiv_map:\n",
    "    if iclr_arxiv_map[k][\"found\"]:\n",
    "        year = int(k.split(\"_\")[0])\n",
    "        yearwise_found[year][iclr_arxiv_map[k][\"label\"]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2017: defaultdict(<class 'int'>, {'Reject': 128, 'Accept': 170}),\n",
      " 2018: defaultdict(<class 'int'>, {'Accept': 287, 'Reject': 192}),\n",
      " 2019: defaultdict(<class 'int'>, {'Reject': 348, 'Accept': 406}),\n",
      " 2020: defaultdict(<class 'int'>, {'Accept': 385, 'Reject': 588})}\n"
     ]
    }
   ],
   "source": [
    "pprint(yearwise_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Year | Found:Rejected | Found:Accepted |\n",
    "| --- | --- | --- |\n",
    "| 2017 | 128/245 | 170/195 |\n",
    "| 2018 | 192/486 | 287/336 |\n",
    "| 2019 | 348/917 | 406/502 |\n",
    "| 2020 | 588/1526 | 385/687 |\n",
    "| **Total** | 1256/3174 | 1248/1720 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "not_count = 0\n",
    "err = 0\n",
    "\n",
    "not_count_list = []\n",
    "err_list = []\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        if not f.endswith(\"tmp\"):\n",
    "            tar = tarfile.open(f)\n",
    "            file_mems = tar.getmembers()\n",
    "            found = False\n",
    "\n",
    "            for t in file_mems:\n",
    "                if t.name.find(\".bib\") > -1:\n",
    "                    found = True\n",
    "                    #bib += 1\n",
    "                    break\n",
    "                if t.name.find(\".bbl\") > -1:\n",
    "                    found = True\n",
    "                    #bbl += 1\n",
    "                    break\n",
    "            if found:\n",
    "                count +=1\n",
    "            else:\n",
    "                not_count +=1\n",
    "                not_count_list.append(f)\n",
    "    except Exception as ex:\n",
    "        err += 1\n",
    "        err_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 2362, 131, 13)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib, bbl, count, not_count, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/singh_shruti/workspace/ICLR_arxiv_dump/1810.00953v4', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1906.05827v3', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1903.03107v2', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1804.10200v1', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1910.02109v1']\n",
      "['/home/singh_shruti/workspace/ICLR_arxiv_dump/1810.01588v1', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1610.06918v1', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1909.13111v1', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1804.02391v2', '/home/singh_shruti/workspace/ICLR_arxiv_dump/1611.02247v3']\n"
     ]
    }
   ],
   "source": [
    "print(err_list[0:5])\n",
    "print(not_count_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting bib files\n",
    "mul = 0\n",
    "err = 0\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        if not f.endswith(\"tmp\"):\n",
    "            tar = tarfile.open(f)\n",
    "            file_mems = tar.getmembers()\n",
    "            found = False\n",
    "            \n",
    "            count = 0\n",
    "            for t in file_mems:\n",
    "                if t.name.find(\".bib\") > -1:\n",
    "                    mul += 1\n",
    "                    break\n",
    "    except Exception as ex:\n",
    "        err += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 13)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = 0\n",
    "err = 0\n",
    "\n",
    "for f in files:\n",
    "    try:\n",
    "        if not f.endswith(\"tmp\"):\n",
    "            tar = tarfile.open(f)\n",
    "            file_mems = tar.getmembers()\n",
    "            found = False\n",
    "            \n",
    "            count = 0\n",
    "            for t in file_mems:\n",
    "                if t.name.find(\".bbl\") > -1:\n",
    "                    mul += 1\n",
    "                    break\n",
    "    except Exception as ex:\n",
    "        err += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2353, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the bib information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"/home/singh_shruti/workspace/ICLR_arxiv_dump/*\")\n",
    "arxiv_source_files = [f.rsplit(\"/\", 1)[1] for f in files]\n",
    "len(arxiv_source_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_HyAddcLge file could not be opened successfully\n",
      "2017_r1osyr_xg file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_rkeZRGbRW file could not be opened successfully\n",
      "2019_B1e0X3C9tQ 'f'\n",
      "2019_B1x9siCcYQ 'june'\n",
      "2019_BkedwoC5t7 file could not be opened successfully\n",
      "2019_BkgFqiAqFX 'february'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_HJMXTsCqYQ 'jacsat'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_HkxAisC9FQ file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: pami.\n",
      "Overwritting existing string for key: ijcv.\n",
      "Overwritting existing string for key: cvpr.\n",
      "Overwritting existing string for key: iccv.\n",
      "Overwritting existing string for key: eccv.\n",
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: bmvc.\n",
      "Overwritting existing string for key: jmlr.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_S1ey2sRcYQ 'july'\n",
      "2019_S1x2Fj0qKQ 'ijcai-95'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: jan.\n",
      "Overwritting existing string for key: feb.\n",
      "Overwritting existing string for key: mar.\n",
      "Overwritting existing string for key: apr.\n",
      "Overwritting existing string for key: may.\n",
      "Overwritting existing string for key: jun.\n",
      "Overwritting existing string for key: jul.\n",
      "Overwritting existing string for key: aug.\n",
      "Overwritting existing string for key: sep.\n",
      "Overwritting existing string for key: oct.\n",
      "Overwritting existing string for key: nov.\n",
      "Overwritting existing string for key: dec.\n",
      "Overwritting existing string for key: iccv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_SkeRTsAcYm file could not be opened successfully\n",
      "2019_SkghN205KQ 'mli'\n",
      "2019_SkxANsC9tQ file could not be opened successfully\n",
      "2019_SyezvsC5tX file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_BJeKh3VYDH 'sprg_ijcv'\n",
      "2020_BJexP6VKwH 'StringValue'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Overwritting existing string for key: jan.\n",
      "Overwritting existing string for key: feb.\n",
      "Overwritting existing string for key: mar.\n",
      "Overwritting existing string for key: apr.\n",
      "Overwritting existing string for key: may.\n",
      "Overwritting existing string for key: jun.\n",
      "Overwritting existing string for key: jul.\n",
      "Overwritting existing string for key: aug.\n",
      "Overwritting existing string for key: sep.\n",
      "Overwritting existing string for key: oct.\n",
      "Overwritting existing string for key: nov.\n",
      "Overwritting existing string for key: dec.\n",
      "Overwritting existing string for key: iccv.\n",
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: iccv.\n",
      "Overwritting existing string for key: cvpr.\n",
      "Overwritting existing string for key: bmvc.\n",
      "Overwritting existing string for key: civr.\n",
      "Overwritting existing string for key: visapp.\n",
      "Overwritting existing string for key: acmmm.\n",
      "Overwritting existing string for key: eccv.\n",
      "Overwritting existing string for key: www.\n",
      "Overwritting existing string for key: mir.\n",
      "Overwritting existing string for key: icassp.\n",
      "Overwritting existing string for key: cviu.\n",
      "Overwritting existing string for key: ijcv.\n",
      "Overwritting existing string for key: stoc.\n",
      "Overwritting existing string for key: sigmod.\n",
      "Overwritting existing string for key: aaai.\n",
      "Overwritting existing string for key: vldb.\n",
      "Overwritting existing string for key: wacv.\n",
      "Overwritting existing string for key: ieeetpami.\n",
      "Overwritting existing string for key: ieeetit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_Bke6vTVYwH 'eurasp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type url not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_BkgNqkHFPr 'february'\n",
      "2020_Byg9bxrtwS file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Overwritting existing string for key: apr.\n",
      "Overwritting existing string for key: aug.\n",
      "Overwritting existing string for key: dec.\n",
      "Overwritting existing string for key: feb.\n",
      "Overwritting existing string for key: jan.\n",
      "Overwritting existing string for key: jul.\n",
      "Overwritting existing string for key: jun.\n",
      "Overwritting existing string for key: mar.\n",
      "Overwritting existing string for key: may.\n",
      "Overwritting existing string for key: nov.\n",
      "Overwritting existing string for key: oct.\n",
      "Overwritting existing string for key: sep.\n",
      "Entry type paper not standard. Not considered.\n",
      "Entry type report not standard. Not considered.\n",
      "Entry type url not standard. Not considered.\n",
      "Entry type report not standard. Not considered.\n",
      "Entry type dataset not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_H1ekF2EYDH file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: aaai.\n",
      "Overwritting existing string for key: colt.\n",
      "Overwritting existing string for key: cvpr.\n",
      "Overwritting existing string for key: ecml.\n",
      "Overwritting existing string for key: ewcbr.\n",
      "Overwritting existing string for key: fg.\n",
      "Overwritting existing string for key: iccv.\n",
      "Overwritting existing string for key: icdm.\n",
      "Overwritting existing string for key: icml.\n",
      "Overwritting existing string for key: icpr.\n",
      "Overwritting existing string for key: icvp.\n",
      "Overwritting existing string for key: ijcai.\n",
      "Overwritting existing string for key: ijcv.\n",
      "Overwritting existing string for key: kdd.\n",
      "Overwritting existing string for key: mm.\n",
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: pami.\n",
      "Overwritting existing string for key: sigir.\n",
      "Overwritting existing string for key: tvcg.\n",
      "Overwritting existing string for key: uai.\n",
      "Overwritting existing string for key: pcm.\n",
      "Overwritting existing string for key: nips.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_HJezF3VYPB 'StringValue'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n",
      "Overwritting existing string for key: icalp.\n",
      "Overwritting existing string for key: iclrws.\n",
      "Overwritting existing string for key: amstrans.\n",
      "Overwritting existing string for key: bullams.\n",
      "Overwritting existing string for key: procams.\n",
      "Overwritting existing string for key: transams.\n",
      "Overwritting existing string for key: cacm.\n",
      "Overwritting existing string for key: acmmathsoft.\n",
      "Overwritting existing string for key: signum.\n",
      "Overwritting existing string for key: amerstatassoc.\n",
      "Overwritting existing string for key: applmathcomp.\n",
      "Overwritting existing string for key: amermathmonthly.\n",
      "Overwritting existing string for key: britstatpsych.\n",
      "Overwritting existing string for key: canmathbull.\n",
      "Overwritting existing string for key: compapplmath.\n",
      "Overwritting existing string for key: compphys.\n",
      "Overwritting existing string for key: compstruct.\n",
      "Overwritting existing string for key: compjour.\n",
      "Overwritting existing string for key: compsyssci.\n",
      "Overwritting existing string for key: contempmath.\n",
      "Overwritting existing string for key: giornalemath.\n",
      "Overwritting existing string for key: ieeetranscomp.\n",
      "Overwritting existing string for key: ieeetransac.\n",
      "Overwritting existing string for key: procieee.\n",
      "Overwritting existing string for key: ieeetransaeroelec.\n",
      "Overwritting existing string for key: imanumerana.\n",
      "Overwritting existing string for key: infproclet.\n",
      "Overwritting existing string for key: instmathapp.\n",
      "Overwritting existing string for key: intcontrol.\n",
      "Overwritting existing string for key: intnumereng.\n",
      "Overwritting existing string for key: intsuper.\n",
      "Overwritting existing string for key: jresnatburstand.\n",
      "Overwritting existing string for key: linalgapp.\n",
      "Overwritting existing string for key: mathanaappl.\n",
      "Overwritting existing string for key: mathannalen.\n",
      "Overwritting existing string for key: mathphys.\n",
      "Overwritting existing string for key: mathcomp.\n",
      "Overwritting existing string for key: mathscand.\n",
      "Overwritting existing string for key: tablesaidscomp.\n",
      "Overwritting existing string for key: numermath.\n",
      "Overwritting existing string for key: pacificmath.\n",
      "Overwritting existing string for key: pardistcomp.\n",
      "Overwritting existing string for key: parcomputing.\n",
      "Overwritting existing string for key: philmag.\n",
      "Overwritting existing string for key: procnas.\n",
      "Overwritting existing string for key: quartmath.\n",
      "Overwritting existing string for key: quartapplmath.\n",
      "Overwritting existing string for key: revueinststat.\n",
      "Overwritting existing string for key: jsiam.\n",
      "Overwritting existing string for key: jsiamb.\n",
      "Overwritting existing string for key: siamalgmeth.\n",
      "Overwritting existing string for key: siamappmath.\n",
      "Overwritting existing string for key: siamcomp.\n",
      "Overwritting existing string for key: siammatrix.\n",
      "Overwritting existing string for key: siamnumanal.\n",
      "Overwritting existing string for key: siamreview.\n",
      "Overwritting existing string for key: siamscistat.\n",
      "Overwritting existing string for key: softpracexp.\n",
      "Overwritting existing string for key: statscience.\n",
      "Overwritting existing string for key: ussrcompmathphys.\n",
      "Overwritting existing string for key: vlsicompsys.\n",
      "Overwritting existing string for key: zangewmathmech.\n",
      "Overwritting existing string for key: zangewmathphys.\n",
      "Entry type periodical not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_Hke3gyHYwH 'february'\n",
      "2020_HkgMxkHtPH file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type electronic not standard. Not considered.\n",
      "Entry type url not standard. Not considered.\n",
      "Entry type artile not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_Hye00pVtPS file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: amstrans.\n",
      "Overwritting existing string for key: bullams.\n",
      "Overwritting existing string for key: procams.\n",
      "Overwritting existing string for key: transams.\n",
      "Overwritting existing string for key: cacm.\n",
      "Overwritting existing string for key: acmmathsoft.\n",
      "Overwritting existing string for key: signum.\n",
      "Overwritting existing string for key: amerstatassoc.\n",
      "Overwritting existing string for key: applmathcomp.\n",
      "Overwritting existing string for key: amermathmonthly.\n",
      "Overwritting existing string for key: britstatpsych.\n",
      "Overwritting existing string for key: canmathbull.\n",
      "Overwritting existing string for key: compapplmath.\n",
      "Overwritting existing string for key: compphys.\n",
      "Overwritting existing string for key: compstruct.\n",
      "Overwritting existing string for key: compjour.\n",
      "Overwritting existing string for key: compsyssci.\n",
      "Overwritting existing string for key: contempmath.\n",
      "Overwritting existing string for key: giornalemath.\n",
      "Overwritting existing string for key: ieeetranscomp.\n",
      "Overwritting existing string for key: ieeetransac.\n",
      "Overwritting existing string for key: procieee.\n",
      "Overwritting existing string for key: ieeetransaeroelec.\n",
      "Overwritting existing string for key: imanumerana.\n",
      "Overwritting existing string for key: infproclet.\n",
      "Overwritting existing string for key: instmathapp.\n",
      "Overwritting existing string for key: intcontrol.\n",
      "Overwritting existing string for key: intnumereng.\n",
      "Overwritting existing string for key: intsuper.\n",
      "Overwritting existing string for key: jresnatburstand.\n",
      "Overwritting existing string for key: linalgapp.\n",
      "Overwritting existing string for key: mathanaappl.\n",
      "Overwritting existing string for key: mathannalen.\n",
      "Overwritting existing string for key: mathphys.\n",
      "Overwritting existing string for key: mathcomp.\n",
      "Overwritting existing string for key: mathscand.\n",
      "Overwritting existing string for key: tablesaidscomp.\n",
      "Overwritting existing string for key: numermath.\n",
      "Overwritting existing string for key: pacificmath.\n",
      "Overwritting existing string for key: pardistcomp.\n",
      "Overwritting existing string for key: parcomputing.\n",
      "Overwritting existing string for key: philmag.\n",
      "Overwritting existing string for key: procnas.\n",
      "Overwritting existing string for key: quartmath.\n",
      "Overwritting existing string for key: quartapplmath.\n",
      "Overwritting existing string for key: revueinststat.\n",
      "Overwritting existing string for key: jsiam.\n",
      "Overwritting existing string for key: jsiamb.\n",
      "Overwritting existing string for key: siamalgmeth.\n",
      "Overwritting existing string for key: siamappmath.\n",
      "Overwritting existing string for key: siamcomp.\n",
      "Overwritting existing string for key: siammatrix.\n",
      "Overwritting existing string for key: siamnumanal.\n",
      "Overwritting existing string for key: siamreview.\n",
      "Overwritting existing string for key: siamscistat.\n",
      "Overwritting existing string for key: softpracexp.\n",
      "Overwritting existing string for key: statscience.\n",
      "Overwritting existing string for key: ussrcompmathphys.\n",
      "Overwritting existing string for key: vlsicompsys.\n",
      "Overwritting existing string for key: zangewmathmech.\n",
      "Overwritting existing string for key: zangewmathphys.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_Hyx0slrFvH file could not be opened successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n",
      "Entry type unknown not standard. Not considered.\n",
      "Entry type unknown not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_S1glGANtDr 'december'\n",
      "2020_S1lEX04tPr 'icra'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type inproceeding not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_SJgMK64Ywr 'ijcai'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: jan.\n",
      "Overwritting existing string for key: feb.\n",
      "Overwritting existing string for key: mar.\n",
      "Overwritting existing string for key: apr.\n",
      "Overwritting existing string for key: may.\n",
      "Overwritting existing string for key: jun.\n",
      "Overwritting existing string for key: jul.\n",
      "Overwritting existing string for key: aug.\n",
      "Overwritting existing string for key: sep.\n",
      "Overwritting existing string for key: oct.\n",
      "Overwritting existing string for key: nov.\n",
      "Overwritting existing string for key: dec.\n",
      "Overwritting existing string for key: cvpr.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_SJxDDpEKvH 'december'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: aaai.\n",
      "Overwritting existing string for key: colt.\n",
      "Overwritting existing string for key: cvpr.\n",
      "Overwritting existing string for key: ecml.\n",
      "Overwritting existing string for key: ewcbr.\n",
      "Overwritting existing string for key: fg.\n",
      "Overwritting existing string for key: iccv.\n",
      "Overwritting existing string for key: icdm.\n",
      "Overwritting existing string for key: icml.\n",
      "Overwritting existing string for key: icpr.\n",
      "Overwritting existing string for key: icvp.\n",
      "Overwritting existing string for key: ijcai.\n",
      "Overwritting existing string for key: ijcv.\n",
      "Overwritting existing string for key: kdd.\n",
      "Overwritting existing string for key: mm.\n",
      "Overwritting existing string for key: nips.\n",
      "Overwritting existing string for key: pami.\n",
      "Overwritting existing string for key: sigir.\n",
      "Overwritting existing string for key: tvcg.\n",
      "Overwritting existing string for key: uai.\n",
      "Overwritting existing string for key: pcm.\n",
      "Overwritting existing string for key: nips.\n",
      "Entry type other not standard. Not considered.\n",
      "Entry type other not standard. Not considered.\n",
      "Entry type other not standard. Not considered.\n",
      "Entry type other not standard. Not considered.\n",
      "Entry type other not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_SkeJPertPS 'pami'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_Skg5r1BFvB 'february'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type electronic not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type standard not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type software not standard. Not considered.\n",
      "Entry type unknown not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_r1genAVKPB 'february'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type artical not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_r1xF7lSYDS 'eccv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type software not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_rJeBJJBYDB 'december'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwritting existing string for key: amstrans.\n",
      "Overwritting existing string for key: bullams.\n",
      "Overwritting existing string for key: procams.\n",
      "Overwritting existing string for key: transams.\n",
      "Overwritting existing string for key: cacm.\n",
      "Overwritting existing string for key: acmmathsoft.\n",
      "Overwritting existing string for key: signum.\n",
      "Overwritting existing string for key: amerstatassoc.\n",
      "Overwritting existing string for key: applmathcomp.\n",
      "Overwritting existing string for key: amermathmonthly.\n",
      "Overwritting existing string for key: britstatpsych.\n",
      "Overwritting existing string for key: canmathbull.\n",
      "Overwritting existing string for key: compapplmath.\n",
      "Overwritting existing string for key: compphys.\n",
      "Overwritting existing string for key: compstruct.\n",
      "Overwritting existing string for key: compjour.\n",
      "Overwritting existing string for key: compsyssci.\n",
      "Overwritting existing string for key: contempmath.\n",
      "Overwritting existing string for key: giornalemath.\n",
      "Overwritting existing string for key: ieeetranscomp.\n",
      "Overwritting existing string for key: ieeetransac.\n",
      "Overwritting existing string for key: procieee.\n",
      "Overwritting existing string for key: ieeetransaeroelec.\n",
      "Overwritting existing string for key: imanumerana.\n",
      "Overwritting existing string for key: infproclet.\n",
      "Overwritting existing string for key: instmathapp.\n",
      "Overwritting existing string for key: intcontrol.\n",
      "Overwritting existing string for key: intnumereng.\n",
      "Overwritting existing string for key: intsuper.\n",
      "Overwritting existing string for key: jresnatburstand.\n",
      "Overwritting existing string for key: linalgapp.\n",
      "Overwritting existing string for key: mathanaappl.\n",
      "Overwritting existing string for key: mathannalen.\n",
      "Overwritting existing string for key: mathphys.\n",
      "Overwritting existing string for key: mathcomp.\n",
      "Overwritting existing string for key: mathscand.\n",
      "Overwritting existing string for key: tablesaidscomp.\n",
      "Overwritting existing string for key: numermath.\n",
      "Overwritting existing string for key: pacificmath.\n",
      "Overwritting existing string for key: pardistcomp.\n",
      "Overwritting existing string for key: parcomputing.\n",
      "Overwritting existing string for key: philmag.\n",
      "Overwritting existing string for key: procnas.\n",
      "Overwritting existing string for key: quartmath.\n",
      "Overwritting existing string for key: quartapplmath.\n",
      "Overwritting existing string for key: revueinststat.\n",
      "Overwritting existing string for key: jsiam.\n",
      "Overwritting existing string for key: jsiamb.\n",
      "Overwritting existing string for key: siamalgmeth.\n",
      "Overwritting existing string for key: siamappmath.\n",
      "Overwritting existing string for key: siamcomp.\n",
      "Overwritting existing string for key: siammatrix.\n",
      "Overwritting existing string for key: siamnumanal.\n",
      "Overwritting existing string for key: siamreview.\n",
      "Overwritting existing string for key: siamscistat.\n",
      "Overwritting existing string for key: softpracexp.\n",
      "Overwritting existing string for key: statscience.\n",
      "Overwritting existing string for key: ussrcompmathphys.\n",
      "Overwritting existing string for key: vlsicompsys.\n",
      "Overwritting existing string for key: zangewmathmech.\n",
      "Overwritting existing string for key: zangewmathphys.\n",
      "Entry type online not standard. Not considered.\n",
      "Entry type thesis not standard. Not considered.\n",
      "Entry type thesis not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_rkeeoeHYvr 'scholarpedia'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type online not standard. Not considered.\n",
      "Entry type patent not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    }
   ],
   "source": [
    "bib1_dict = {}\n",
    "\n",
    "for k, v in iclr_arxiv_map.items():\n",
    "    if v[\"found\"] and v[\"arxivId\"] in arxiv_source_files:\n",
    "        try:\n",
    "            f = \"/home/singh_shruti/workspace/ICLR_arxiv_dump/\" + v[\"arxivId\"]\n",
    "            tar = tarfile.open(f)\n",
    "            file_mems = tar.getmembers()\n",
    "            \n",
    "            bib_files = []\n",
    "            \n",
    "            for t in file_mems:\n",
    "                if t.name.find(\".bib\") > -1:\n",
    "                    bib_files.append(t.name)\n",
    "            \n",
    "            if bib_files:\n",
    "                if len(bib_files) == 1:\n",
    "                    \n",
    "                    tar.extract(member=bib_files[0], path=\"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/\")\n",
    "                    \n",
    "                    new_loc = \"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/\" + bib_files[0]\n",
    "                    with open(new_loc) as bibtex_file:\n",
    "                        bib_database = bibtexparser.bparser.BibTexParser(common_strings=True).parse_file(bibtex_file)\n",
    "                        #bibtex_str = bibtex_file.read()\n",
    "                    #bib_database = bibtexparser.loads(bibtex_str)\n",
    "                    \n",
    "                    bib_entries = []\n",
    "                    for i, e in enumerate(bib_database.entries):\n",
    "                        e[\"seq\"] = i\n",
    "                        bib_entries.append(e)\n",
    "                    bib1_dict[k] = bib_entries\n",
    "#                 else:\n",
    "                    #read multiple\n",
    "        except Exception as ex:\n",
    "            print(k, ex)\n",
    "#             print(ex)\n",
    "#             if ex != \"file could not be opened successfully\":\n",
    "#                 print(repr(traceback.print_stack()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bib_dictionary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bib_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': '2016',\n",
       "  'journal': 'arXiv preprint arXiv:1607.02533',\n",
       "  'author': 'Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy',\n",
       "  'title': 'Adversarial examples in the physical world',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'kurakin2016adversarial',\n",
       "  'seq': 0},\n",
       " {'organization': 'IEEE',\n",
       "  'year': '2017',\n",
       "  'pages': '39--57',\n",
       "  'booktitle': '2017 IEEE Symposium on Security and Privacy (SP)',\n",
       "  'author': 'Carlini, Nicholas and Wagner, David',\n",
       "  'title': 'Towards evaluating the robustness of neural networks',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'carlini2017towards',\n",
       "  'seq': 1},\n",
       " {'organization': 'ACM',\n",
       "  'year': '2017',\n",
       "  'pages': '506--519',\n",
       "  'booktitle': 'Proceedings of the 2017 ACM on Asia conference on computer and communications security',\n",
       "  'author': 'Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram',\n",
       "  'title': 'Practical black-box attacks against machine learning',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'papernot2017practical',\n",
       "  'seq': 2},\n",
       " {'organization': 'ACM',\n",
       "  'year': '2018',\n",
       "  'pages': '2847--2856',\n",
       "  'booktitle': 'Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \\\\& Data Mining',\n",
       "  'author': 'Z{\\\\\"u}gner, Daniel and Akbarnejad, Amir and G{\\\\\"u}nnemann, Stephan',\n",
       "  'title': 'Adversarial attacks on neural networks for graph data',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'zugner2018adversarial1',\n",
       "  'seq': 3},\n",
       " {'url': 'https://openreview.net/forum?id=Bylnx209YX',\n",
       "  'year': '2019',\n",
       "  'booktitle': 'International Conference on Learning Representations',\n",
       "  'author': 'Daniel Zgner and Stephan Gnnemann',\n",
       "  'title': 'Adversarial Attacks on Graph Neural Networks via Meta Learning',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'zugner2018adversarial_2',\n",
       "  'seq': 4},\n",
       " {'year': '2018',\n",
       "  'pages': '1123--1132',\n",
       "  'booktitle': 'International Conference on Machine Learning',\n",
       "  'author': 'Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le',\n",
       "  'title': 'Adversarial Attack on Graph Structured Data',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'dai2018adversarial',\n",
       "  'seq': 5},\n",
       " {'year': '2016',\n",
       "  'journal': 'arXiv preprint arXiv:1609.02907',\n",
       "  'author': 'Kipf, Thomas N and Welling, Max',\n",
       "  'title': 'Semi-supervised classification with graph convolutional networks',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'kipf2016semi',\n",
       "  'seq': 6},\n",
       " {'publisher': 'Courier Corporation',\n",
       "  'year': '1997',\n",
       "  'author': 'Kullback, Solomon',\n",
       "  'title': 'Information theory and statistics',\n",
       "  'ENTRYTYPE': 'book',\n",
       "  'ID': 'kullback1997information',\n",
       "  'seq': 7},\n",
       " {'publisher': 'Citeseer',\n",
       "  'year': '1990',\n",
       "  'author': 'Stewart, Gilbert W',\n",
       "  'title': 'Matrix perturbation theory',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'stewart1990matrix',\n",
       "  'seq': 8},\n",
       " {'year': '1991',\n",
       "  'pages': '12',\n",
       "  'number': '871-898',\n",
       "  'volume': '2',\n",
       "  'journal': 'Graph theory, combinatorics, and applications',\n",
       "  'author': 'Mohar, Bojan and Alavi, Y and Chartrand, G and Oellermann, OR',\n",
       "  'title': 'The Laplacian spectrum of graphs',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'mohar1991laplacian',\n",
       "  'seq': 9},\n",
       " {'publisher': 'Institute of Mathematics, Academy of Sciences of the Czech Republic',\n",
       "  'year': '1973',\n",
       "  'pages': '298--305',\n",
       "  'number': '2',\n",
       "  'volume': '23',\n",
       "  'journal': 'Czechoslovak mathematical journal',\n",
       "  'author': 'Fiedler, Miroslav',\n",
       "  'title': 'Algebraic connectivity of graphs',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'fiedler1973algebraic',\n",
       "  'seq': 10},\n",
       " {'publisher': 'Springer',\n",
       "  'year': '2016',\n",
       "  'pages': '1395--1425',\n",
       "  'number': '5',\n",
       "  'volume': '30',\n",
       "  'journal': 'Data Mining and Knowledge Discovery',\n",
       "  'author': 'Chan, Hau and Akoglu, Leman',\n",
       "  'title': 'Optimizing network robustness by edge rewiring: a general framework',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'chan2016optimizing',\n",
       "  'seq': 11},\n",
       " {'publisher': 'Elsevier',\n",
       "  'year': '2013',\n",
       "  'pages': '5465--5479',\n",
       "  'number': '10',\n",
       "  'volume': '219',\n",
       "  'journal': 'Applied Mathematics and computation',\n",
       "  'author': 'Sydney, Ali and Scoglio, Caterina and Gruenbacher, Don',\n",
       "  'title': 'Optimizing algebraic connectivity by edge rewiring',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'sydney2013optimizing',\n",
       "  'seq': 12},\n",
       " {'publisher': 'Springer',\n",
       "  'year': '1991',\n",
       "  'pages': '101--109',\n",
       "  'number': '1',\n",
       "  'volume': '4',\n",
       "  'journal': 'Journal of Theoretical Probability',\n",
       "  'author': 'Tetali, Prasad',\n",
       "  'title': 'Random walks and the effective resistance of networks',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'tetali1991random',\n",
       "  'seq': 13},\n",
       " {'publisher': 'Elsevier',\n",
       "  'year': '2011',\n",
       "  'pages': '2491--2506',\n",
       "  'number': '10',\n",
       "  'volume': '435',\n",
       "  'journal': 'Linear algebra and its applications',\n",
       "  'author': 'Ellens, Wendy and Spieksma, FM and Van Mieghem, P and Jamakovic, A and Kooij, RE',\n",
       "  'title': 'Effective graph resistance',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'ellens2011effective',\n",
       "  'seq': 14},\n",
       " {'year': '2014',\n",
       "  'journal': 'arXiv preprint arXiv:1412.6572',\n",
       "  'author': 'Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian',\n",
       "  'title': 'Explaining and harnessing adversarial examples',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'goodfellow2014explaining',\n",
       "  'seq': 15},\n",
       " {'year': '2012',\n",
       "  'journal': 'arXiv preprint arXiv:1211.0053',\n",
       "  'author': 'Shuman, David I and Narang, Sunil K and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre',\n",
       "  'title': 'The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'shuman2012emerging',\n",
       "  'seq': 16},\n",
       " {'publisher': 'IEEE',\n",
       "  'year': '2014',\n",
       "  'pages': '3042--3054',\n",
       "  'number': '12',\n",
       "  'volume': '62',\n",
       "  'journal': 'IEEE Transactions on Signal Processing',\n",
       "  'author': 'Sandryhaila, Aliaksei and Moura, Jose MF',\n",
       "  'title': 'Discrete signal processing on graphs: Frequency analysis',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'sandryhaila2014discrete',\n",
       "  'seq': 17},\n",
       " {'year': '2013',\n",
       "  'journal': 'arXiv preprint arXiv:1312.6199',\n",
       "  'author': 'Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob',\n",
       "  'title': 'Intriguing properties of neural networks',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'szegedy2013intriguing',\n",
       "  'seq': 18},\n",
       " {'year': '2016',\n",
       "  'pages': '2574--2582',\n",
       "  'booktitle': 'Proceedings of the IEEE conference on computer vision and pattern recognition',\n",
       "  'author': 'Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal',\n",
       "  'title': 'Deepfool: a simple and accurate method to fool deep neural networks',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'moosavi2016deepfool',\n",
       "  'seq': 19},\n",
       " {'year': '2017',\n",
       "  'journal': 'arXiv preprint arXiv:1706.06083',\n",
       "  'author': 'Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian',\n",
       "  'title': 'Towards deep learning models resistant to adversarial attacks',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'madry2017towards',\n",
       "  'seq': 20},\n",
       " {'organization': 'ACM',\n",
       "  'year': '2017',\n",
       "  'pages': '15--26',\n",
       "  'booktitle': 'Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security',\n",
       "  'author': 'Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui',\n",
       "  'title': 'Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'chen2017zoo',\n",
       "  'seq': 21},\n",
       " {'year': '2018',\n",
       "  'journal': 'arXiv preprint arXiv:1807.04457',\n",
       "  'author': 'Cheng, Minhao and Le, Thong and Chen, Pin-Yu and Yi, Jinfeng and Zhang, Huan and Hsieh, Cho-Jui',\n",
       "  'title': 'Query-efficient hard-label black-box attack: An optimization-based approach',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'cheng2018query',\n",
       "  'seq': 22},\n",
       " {'year': '2018',\n",
       "  'journal': 'arXiv preprint arXiv:1804.08598',\n",
       "  'author': 'Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy',\n",
       "  'title': 'Black-box adversarial attacks with limited queries and information',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'ilyas2018black',\n",
       "  'seq': 23},\n",
       " {'year': '2018',\n",
       "  'journal': 'arXiv preprint arXiv:1810.10751',\n",
       "  'author': 'Wang, Xiaoyun and Eaton, Joe and Hsieh, Cho-Jui and Wu, Felix',\n",
       "  'title': 'Attack Graph Convolutional Networks by Adding Fake Nodes',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'wang2018attack',\n",
       "  'seq': 24},\n",
       " {'year': '2017',\n",
       "  'pages': '1024--1034',\n",
       "  'booktitle': 'Advances in Neural Information Processing Systems',\n",
       "  'author': 'Hamilton, Will and Ying, Zhitao and Leskovec, Jure',\n",
       "  'title': 'Inductive representation learning on large graphs',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'hamilton2017inductive',\n",
       "  'seq': 25},\n",
       " {'publisher': 'IEEE',\n",
       "  'year': '2008',\n",
       "  'pages': '61--80',\n",
       "  'number': '1',\n",
       "  'volume': '20',\n",
       "  'journal': 'IEEE Transactions on Neural Networks',\n",
       "  'author': 'Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele',\n",
       "  'title': 'The graph neural network model',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'scarselli2008graph',\n",
       "  'seq': 26},\n",
       " {'year': '2018',\n",
       "  'journal': 'arXiv preprint arXiv:1806.08804',\n",
       "  'author': 'Ying, Rex and You, Jiaxuan and Morris, Christopher and Ren, Xiang and Hamilton, William L and Leskovec, Jure',\n",
       "  'title': 'Hierarchical graph representation learning withdifferentiable pooling',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'ying2018hierarchical',\n",
       "  'seq': 27},\n",
       " {'year': '2018',\n",
       "  'booktitle': 'Thirty-Second AAAI Conference on Artificial Intelligence',\n",
       "  'author': 'Zhang, Muhan and Cui, Zhicheng and Neumann, Marion and Chen, Yixin',\n",
       "  'title': 'An end-to-end deep learning architecture for graph classification',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'zhang2018end',\n",
       "  'seq': 28},\n",
       " {'year': '2016',\n",
       "  'pages': '3844--3852',\n",
       "  'booktitle': 'Advances in neural information processing systems',\n",
       "  'author': 'Defferrard, Micha{\\\\\"e}l and Bresson, Xavier and Vandergheynst, Pierre',\n",
       "  'title': 'Convolutional neural networks on graphs with fast localized spectral filtering',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'defferrard2016convolutional',\n",
       "  'seq': 29},\n",
       " {'year': '2013',\n",
       "  'journal': 'arXiv preprint arXiv:1312.6203',\n",
       "  'author': 'Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann',\n",
       "  'title': 'Spectral networks and locally connected networks on graphs',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'bruna2013spectral',\n",
       "  'seq': 30},\n",
       " {'organization': 'IEEE',\n",
       "  'year': '2006',\n",
       "  'pages': '6605--6611',\n",
       "  'booktitle': 'Proceedings of the 45th IEEE Conference on Decision and Control',\n",
       "  'author': 'Ghosh, Arpita and Boyd, Stephen',\n",
       "  'title': 'Growing well-connected graphs',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'ghosh2006growing',\n",
       "  'seq': 31},\n",
       " {'journal': 'Proceedings of the National Academy of Sciences',\n",
       "  'eprint': 'https://www.pnas.org/content/116/10/4426.full.pdf',\n",
       "  'url': 'https://www.pnas.org/content/116/10/4426',\n",
       "  'issn': '0027-8424',\n",
       "  'abstract': 'The interactome network of protein{\\\\textendash}protein interactions captures the structure of molecular machinery that underlies organismal complexity. The resilience to network failures is a critical property of the interactome as the breakdown of interactions may lead to cell death or disease. By studying interactomes from 1,840 species across the tree of life, we find that evolution leads to more resilient interactomes, providing evidence for a longstanding hypothesis that interactomes evolve favoring robustness against network failures. We find that a highly resilient interactome has a beneficial impact on the organism{\\\\textquoteright}s survival in complex, variable, and competitive habitats. Our findings reveal how interactomes change through evolution and how these changes affect their response to environmental unpredictability.Phenotype robustness to environmental fluctuations is a common biological phenomenon. Although most phenotypes involve multiple proteins that interact with each other, the basic principles of how such interactome networks respond to environmental unpredictability and change during evolution are largely unknown. Here we study interactomes of 1,840 species across the tree of life involving a total of 8,762,166 protein{\\\\textendash}protein interactions. Our study focuses on the resilience of interactomes to network failures and finds that interactomes become more resilient during evolution, meaning that interactomes become more robust to network failures over time. In bacteria, we find that a more resilient interactome is in turn associated with the greater ability of the organism to survive in a more complex, variable, and competitive environment. We find that at the protein family level proteins exhibit a coordinated rewiring of interactions over time and that a resilient interactome arises through gradual change of the network topology. Our findings have implications for understanding molecular network structure in the context of both evolution and environment.',\n",
       "  'publisher': 'National Academy of Sciences',\n",
       "  'doi': '10.1073/pnas.1818013116',\n",
       "  'year': '2019',\n",
       "  'pages': '4426--4433',\n",
       "  'number': '10',\n",
       "  'volume': '116',\n",
       "  'title': 'Evolution of resilience in protein interactomes across the tree of life',\n",
       "  'author': 'Zitnik, Marinka and Sosi{\\\\v c}, Rok and Feldman, Marcus W. and Leskovec, Jure',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'Zitnik4426',\n",
       "  'seq': 32},\n",
       " {'url': 'http://graphkernels.cs.tu-dortmund.de',\n",
       "  'year': '2016',\n",
       "  'author': 'Kristian Kersting and Nils M. Kriege and Christopher Morris and Petra Mutzel and Marion Neumann',\n",
       "  'title': 'Benchmark Data Sets for Graph Kernels',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'KKMMN2016',\n",
       "  'seq': 33},\n",
       " {'organization': 'ACM',\n",
       "  'year': '2015',\n",
       "  'pages': '1365--1374',\n",
       "  'booktitle': 'Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining',\n",
       "  'author': 'Yanardag, Pinar and Vishwanathan, SVN',\n",
       "  'title': 'Deep graph kernels',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'yanardag2015deep',\n",
       "  'seq': 34},\n",
       " {'publisher': 'MIT press',\n",
       "  'year': '2018',\n",
       "  'author': 'Sutton, Richard S and Barto, Andrew G',\n",
       "  'title': 'Reinforcement learning: An introduction',\n",
       "  'ENTRYTYPE': 'book',\n",
       "  'ID': 'sutton2018reinforcement',\n",
       "  'seq': 35},\n",
       " {'year': '2000',\n",
       "  'pages': '1057--1063',\n",
       "  'booktitle': 'Advances in neural information processing systems',\n",
       "  'author': 'Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay',\n",
       "  'title': 'Policy gradient methods for reinforcement learning with function approximation',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'sutton2000policy',\n",
       "  'seq': 36}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_dict[\"2020_B1eXygBFPH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vinci_ML.bib']\n",
      "/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/vinci_ML.bib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# 2017_ryQbbFile\n",
    "\n",
    "\n",
    "bib_dict = {}\n",
    "\n",
    "# for v in iclr_arxiv_map[\"2017_ryQbbFile\"].items():\n",
    "k = \"2018_B1ydPgTpW\"\n",
    "v = iclr_arxiv_map[\"2018_B1ydPgTpW\"]\n",
    "\n",
    "for i in range(0, 1):\n",
    "    if v[\"found\"] and v[\"arxivId\"] in arxiv_source_files:\n",
    "        try:\n",
    "            f = \"/home/singh_shruti/workspace/ICLR_arxiv_dump/\" + v[\"arxivId\"]\n",
    "            tar = tarfile.open(f)\n",
    "            file_mems = tar.getmembers()\n",
    "            \n",
    "            bib_files = []\n",
    "            \n",
    "            for t in file_mems:\n",
    "                if t.name.find(\".bib\") > -1:\n",
    "                    bib_files.append(t.name)\n",
    "            \n",
    "            if bib_files:\n",
    "                print(bib_files)\n",
    "                if len(bib_files) == 1:\n",
    "                    \n",
    "                    tar.extract(member=bib_files[0], path=\"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/\")\n",
    "                    \n",
    "                    new_loc = \"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/\" + bib_files[0]\n",
    "                    print(new_loc)\n",
    "                    \n",
    "                    with open(new_loc) as bibtex_file:\n",
    "                        #bibtex_str = bibtex_file.read()\n",
    "                        bib_database = bibtexparser.bparser.BibTexParser(common_strings=True).parse_file(bibtex_file)\n",
    "                    print(\"Read file\")\n",
    "#                     bib_database = bibtexparser.loads(bibtex_str)\n",
    "#                     print(\"Loaded file\")\n",
    "                    \n",
    "                    print(len(bib_database.entries))\n",
    "                    bib_entries = []\n",
    "                    for i, e in enumerate(bib_database.entries):\n",
    "                        e[\"seq\"] = i\n",
    "                        bib_entries.append(e)\n",
    "                    bib_dict[k] = bib_entries\n",
    "#                 else:\n",
    "                    #read multiple\n",
    "        except Exception as ex:\n",
    "            print(k)\n",
    "            print(ex)\n",
    "#             if ex != \"file could not be opened successfully\":\n",
    "#                 print(repr(traceback.print_stack()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type unknown not standard. Not considered.\n",
      "Entry type online not standard. Not considered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file\n"
     ]
    }
   ],
   "source": [
    "# bp = BibTexParser(interpolate_strings=False)\n",
    "# bib_database = bp.parse(bibtex)\n",
    "\n",
    "with open(\"/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison/temp_ext_dir/vinci_ML.bib\") as bibtex_file:\n",
    "#     bibtex_str = bibtex_file.read()\n",
    "    bib_database = bibtexparser.bparser.BibTexParser(common_strings=True).parse_file(bibtex_file)\n",
    "print(\"Read file\")\n",
    "# bib_database = bibtexparser.loads(bibtex_str)\n",
    "\n",
    "# files_i_want = ['path/to/file1','path/to/file2']\n",
    "\n",
    "# tar = tarfile.open(\"bundle.tar\")\n",
    "# tar.extractall(members=[x for x in tar.getmembers() if x.name in files_i_want])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_missing_from_crossref_entry',\n",
       " '_entries_dict',\n",
       " '_make_entries_dict',\n",
       " '_not_updated_by_crossref',\n",
       " 'add_missing_from_crossref',\n",
       " 'comments',\n",
       " 'entries',\n",
       " 'entries_dict',\n",
       " 'entry_sort_key',\n",
       " 'expand_string',\n",
       " 'get_entry_dict',\n",
       " 'get_entry_list',\n",
       " 'load_common_strings',\n",
       " 'preambles',\n",
       " 'strings']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(bibtex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1812.04606v3     DownloadArxivForICLR.ipynb\r\n",
      "\u001b[0m\u001b[38;5;27maxcell_scripts\u001b[0m/  extract_refs_from_arxiv.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/singh_shruti/workspace/PaperAcceptancePrediction/shruti/meaningful_comparison'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir temp_ext_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls temp_ext_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir temp_ext_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r temp_ext_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167-@INPROCEEDINGS{cho-al-emnlp14,\r\n",
      "168-     author = {Cho, Kyunghyun and van Merri{\\\"{e}}nboer, Bart and G{\\\"{u}}l{\\c c}ehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},\r\n",
      "169:      month = oct,\r\n",
      "170-      title = {Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation},\r\n",
      "171-  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\r\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cat temp_ext_dir/vinci_ML.bib | grep -n2 oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
