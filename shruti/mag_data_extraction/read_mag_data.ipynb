{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MAG papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/singh_shruti/data/mag_aminer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_files = glob.glob(data_path + \"mag_papers_[0-9].zip\")\n",
    "author_files = glob.glob(data_path + \"mag_authors_[0-9].zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/home/singh_shruti/data/mag_aminer/mag_papers_2.zip',\n",
       "  '/home/singh_shruti/data/mag_aminer/mag_papers_1.zip',\n",
       "  '/home/singh_shruti/data/mag_aminer/mag_papers_0.zip'],\n",
       " ['/home/singh_shruti/data/mag_aminer/mag_authors_2.zip',\n",
       "  '/home/singh_shruti/data/mag_aminer/mag_authors_0.zip',\n",
       "  '/home/singh_shruti/data/mag_aminer/mag_authors_1.zip'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_files, author_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ElectronSpinResonanceInvestigationsofOxygenCenteredFreeRadicalsinBiologicalSystems'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"Electron Spin Resonance Investigations of Oxygen-Centered Free Radicals in Biological Systems\"\n",
    "title = ''.join(filter(str.isalpha, title))\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mag_papers_4.txt', 'mag_papers_5.txt', 'mag_papers_6.txt', 'mag_papers_7.txt']\n",
      "Read file mag_papers_4.txt in archive ['mag_papers_4.txt', 'mag_papers_5.txt', 'mag_papers_6.txt', 'mag_papers_7.txt']\n",
      "Length of file:  21477822\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_5.txt in archive ['mag_papers_4.txt', 'mag_papers_5.txt', 'mag_papers_6.txt', 'mag_papers_7.txt']\n",
      "Length of file:  22422047\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "22000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_6.txt in archive ['mag_papers_4.txt', 'mag_papers_5.txt', 'mag_papers_6.txt', 'mag_papers_7.txt']\n",
      "Length of file:  19595179\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_7.txt in archive ['mag_papers_4.txt', 'mag_papers_5.txt', 'mag_papers_6.txt', 'mag_papers_7.txt']\n",
      "Length of file:  21813021\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "['mag_papers_0.txt', 'mag_papers_1.txt', 'mag_papers_2.txt', 'mag_papers_3.txt']\n",
      "Read file mag_papers_0.txt in archive ['mag_papers_0.txt', 'mag_papers_1.txt', 'mag_papers_2.txt', 'mag_papers_3.txt']\n",
      "Length of file:  21406987\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_1.txt in archive ['mag_papers_0.txt', 'mag_papers_1.txt', 'mag_papers_2.txt', 'mag_papers_3.txt']\n",
      "Length of file:  18210051\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_2.txt in archive ['mag_papers_0.txt', 'mag_papers_1.txt', 'mag_papers_2.txt', 'mag_papers_3.txt']\n",
      "Length of file:  18063253\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_papers_3.txt in archive ['mag_papers_0.txt', 'mag_papers_1.txt', 'mag_papers_2.txt', 'mag_papers_3.txt']\n",
      "Length of file:  19066305\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "err for json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "mag_papers = {}\n",
    "\n",
    "for f in paper_files:\n",
    "    archive = zipfile.ZipFile(f, 'r')\n",
    "    zip_files = archive.namelist()\n",
    "    print(zip_files)\n",
    "    for fi in zip_files:\n",
    "        bytes_text = archive.read(fi)\n",
    "        print(\"Read file {} in archive {}\".format(fi, zip_files))\n",
    "        try:\n",
    "            str_list = bytes_text.decode('utf-8').split(\"\\n\")\n",
    "            print(\"Length of file: \", len(str_list))\n",
    "            idx = 0\n",
    "            \n",
    "            for l in str_list:\n",
    "                if idx % 1000000 == 0:\n",
    "                    print(idx)\n",
    "                idx += 1\n",
    "                try:\n",
    "                    paper_dict = json.loads(l)\n",
    "                    if \"year\" in paper_dict and paper_dict[\"year\"]:\n",
    "                        if paper_dict[\"year\"] in [2016, 2017, 2018]:\n",
    "                            if \"venue\" in paper_dict and paper_dict[\"venue\"] and \"id\" in paper_dict[\"venue\"]:\n",
    "                                if paper_dict[\"venue\"][\"id\"] == \"2584161585\":\n",
    "                                    if \"title\" in paper_dict:\n",
    "                                        title = paper_dict[\"title\"].lower()\n",
    "                                        title = ''.join(filter(str.isalpha, title))\n",
    "                                        mag_papers[title] = paper_dict\n",
    "                                else:\n",
    "                                    if \"title\" in paper_dict:\n",
    "                                        title = paper_dict[\"title\"].lower()\n",
    "                                        title = ''.join(filter(str.isalpha, title))\n",
    "                                        mag_papers[title] = paper_dict\n",
    "                            elif \"title\" in paper_dict:\n",
    "                                title = paper_dict[\"title\"].lower()\n",
    "                                title = ''.join(filter(str.isalpha, title))\n",
    "                                mag_papers[title] = paper_dict\n",
    "                    else:\n",
    "                        if \"venue\" in paper_dict and paper_dict[\"venue\"] and \"id\" in paper_dict[\"venue\"]:\n",
    "                            if paper_dict[\"venue\"][\"id\"] == \"2584161585\":\n",
    "                                if \"title\" in paper_dict:\n",
    "                                    title = paper_dict[\"title\"].lower()\n",
    "                                    title = ''.join(filter(str.isalpha, title))\n",
    "                                    mag_papers[title] = paper_dict\n",
    "                            else:\n",
    "                                if \"title\" in paper_dict:\n",
    "                                    title = paper_dict[\"title\"].lower()\n",
    "                                    title = ''.join(filter(str.isalpha, title))\n",
    "                                    mag_papers[title] = paper_dict\n",
    "                        elif \"title\" in paper_dict:\n",
    "                            title = paper_dict[\"title\"].lower()\n",
    "                            title = ''.join(filter(str.isalpha, title))\n",
    "                            mag_papers[title] = paper_dict\n",
    "                except Exception as ex:\n",
    "                    print(\"err for json loading\")\n",
    "                    print(ex)\n",
    "        except Exception as ex:\n",
    "            print(\"err for bytes decoding\")\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5732441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mag_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23873092"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mag_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('mag_papers.pickle', 'wb') as handle:\n",
    "    pickle.dump(mag_papers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['methodandterminalfordisplayingimageandvideoandrespondingnetworkrequest',\n",
       " 'blockhbhappensbeforebaseddynamicdataracedetectionmethodandsystem',\n",
       " 'carpullerhookassemblyvehicleframeandvehicle',\n",
       " 'daylilyoven',\n",
       " 'ultrasonicdeviceforinjectingskindrugs',\n",
       " 'canbeusedtothoughtlesslycylinderbodyofdefeatedmachineofoilgas',\n",
       " 'wirelessremotecontrolsendreceiverdevicebasedonsubghz',\n",
       " 'ledintegratorpanellamptakesprecautionsagainstearthquakes',\n",
       " 'hightemperatureresistantboatforreducingenvironment',\n",
       " 'hybridprotectionintelligentoperationandcontrolsystemforceramickiln']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mag_papers.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2828751091',\n",
       " 'title': 'Day lily oven',\n",
       " 'authors': [{'name': 'Zhang Qingping', 'id': '2818635959'},\n",
       "  {'name': 'Zhang Hui', 'id': '2435247520'},\n",
       "  {'name': 'Zhang Wei', 'id': '2292879635'},\n",
       "  {'name': 'Zhang Ye', 'id': '2860350827'},\n",
       "  {'name': 'Zhang Qianzhi', 'id': '2855981264'},\n",
       "  {'name': 'Liu Jianmei', 'id': '2837323458'}],\n",
       " 'year': 2017,\n",
       " 'n_citation': 0,\n",
       " 'page_start': '',\n",
       " 'page_end': '',\n",
       " 'doc_type': 'Patent',\n",
       " 'publisher': '',\n",
       " 'volume': '',\n",
       " 'issue': ''}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_papers[\"daylilyoven\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment iclr2017 data with MAG papers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdjectiveAnalysis.ipynb        get_pr_features.ipynb\r\n",
      "AllModels2017Baseline.ipynb    \u001b[0m\u001b[38;5;27mICLRData\u001b[0m/\r\n",
      "\u001b[38;5;27margminingdata\u001b[0m/                 \u001b[38;5;27mimages\u001b[0m/\r\n",
      "BaselineOnEntireICLR.ipynb     IndividualModelsAllData_17_20.ipynb\r\n",
      "Copy_of_get_conf_papers.ipynb  \u001b[38;5;27mmag_data_extraction\u001b[0m/\r\n",
      "EntireICLRFeaturePrep.ipynb    \u001b[38;5;27mnovelty\u001b[0m/\r\n",
      "\u001b[38;5;27mfeatures\u001b[0m/                      \u001b[38;5;27mOCR_workspace\u001b[0m/\r\n",
      "find_adj_phrases.ipynb         plotauthorstats.ipynb\r\n",
      "get_aspects.py                 reviewratings_iclr17_peeread.pkl\r\n",
      "get_data_ICLR.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>number</th>\n",
       "      <th>cdate</th>\n",
       "      <th>tcdate</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>ddate</th>\n",
       "      <th>content</th>\n",
       "      <th>forum</th>\n",
       "      <th>referent</th>\n",
       "      <th>...</th>\n",
       "      <th>details</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>label</th>\n",
       "      <th>ref_latest</th>\n",
       "      <th>ref_len</th>\n",
       "      <th>ref_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HJWHIKqgl</th>\n",
       "      <td>HJWHIKqgl</td>\n",
       "      <td>None</td>\n",
       "      <td>494</td>\n",
       "      <td>None</td>\n",
       "      <td>1478297149874</td>\n",
       "      <td>1559850667018</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Generative Models and Model Critici...</td>\n",
       "      <td>HJWHIKqgl</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'replyCount': 12}</td>\n",
       "      <td>Generative Models and Model Criticism via Opti...</td>\n",
       "      <td>[Dougal J. Sutherland, Hsiao-Yu Tung, Heiko St...</td>\n",
       "      <td>We propose a method to optimize the representa...</td>\n",
       "      <td>[Unsupervised Learning]</td>\n",
       "      <td>12</td>\n",
       "      <td>Accept</td>\n",
       "      <td>2019</td>\n",
       "      <td>34</td>\n",
       "      <td>[2008, 2016, 2011, 2015, 2015, 2008, 2014, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyK00v5xx</th>\n",
       "      <td>SyK00v5xx</td>\n",
       "      <td>None</td>\n",
       "      <td>448</td>\n",
       "      <td>None</td>\n",
       "      <td>1478291152993</td>\n",
       "      <td>1544202244497</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'A Simple but Tough-to-Beat Baseline...</td>\n",
       "      <td>SyK00v5xx</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'replyCount': 19}</td>\n",
       "      <td>A Simple but Tough-to-Beat Baseline for Senten...</td>\n",
       "      <td>[Sanjeev Arora, Yingyu Liang, Tengyu Ma]</td>\n",
       "      <td>\\nThe success of neural network methods for co...</td>\n",
       "      <td>[Natural language processing, Unsupervised Lea...</td>\n",
       "      <td>19</td>\n",
       "      <td>Accept</td>\n",
       "      <td>2016</td>\n",
       "      <td>49</td>\n",
       "      <td>[2012, 2012, 2013, 2013, 2014, 2015, 2016, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hkg4TI9xl</th>\n",
       "      <td>Hkg4TI9xl</td>\n",
       "      <td>None</td>\n",
       "      <td>331</td>\n",
       "      <td>None</td>\n",
       "      <td>1478286631603</td>\n",
       "      <td>1543468347892</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'A Baseline for Detecting Misclassif...</td>\n",
       "      <td>Hkg4TI9xl</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'replyCount': 12}</td>\n",
       "      <td>A Baseline for Detecting Misclassified and Out...</td>\n",
       "      <td>[Dan Hendrycks, Kevin Gimpel]</td>\n",
       "      <td>We consider the two related problems of detect...</td>\n",
       "      <td>[Computer vision]</td>\n",
       "      <td>12</td>\n",
       "      <td>Accept</td>\n",
       "      <td>2016</td>\n",
       "      <td>41</td>\n",
       "      <td>[2016, 2012, 2011, 2006, 2005, 1993, 2011, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hk1iOLcle</th>\n",
       "      <td>Hk1iOLcle</td>\n",
       "      <td>None</td>\n",
       "      <td>305</td>\n",
       "      <td>None</td>\n",
       "      <td>1478285463347</td>\n",
       "      <td>1528908097367</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'MS MARCO: A Human-Generated MAchine...</td>\n",
       "      <td>Hk1iOLcle</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'replyCount': 12}</td>\n",
       "      <td>MS MARCO: A Human-Generated MAchine Reading CO...</td>\n",
       "      <td>[Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng...</td>\n",
       "      <td>This paper presents our recent work on the des...</td>\n",
       "      <td>[]</td>\n",
       "      <td>12</td>\n",
       "      <td>Reject</td>\n",
       "      <td>2016</td>\n",
       "      <td>25</td>\n",
       "      <td>[2014, 2005, 2012, 2009, 2004, 2014, 2014, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H178hw9ex</th>\n",
       "      <td>H178hw9ex</td>\n",
       "      <td>None</td>\n",
       "      <td>430</td>\n",
       "      <td>None</td>\n",
       "      <td>1478290507268</td>\n",
       "      <td>1528907922165</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Dynamic Steerable Frame Networks', ...</td>\n",
       "      <td>H178hw9ex</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'replyCount': 11}</td>\n",
       "      <td>Dynamic Steerable Frame Networks</td>\n",
       "      <td>[Jörn-Henrik Jacobsen, Bert De Brabandere, Arn...</td>\n",
       "      <td>Filters in a convolutional network are typical...</td>\n",
       "      <td>[Computer vision, Deep learning]</td>\n",
       "      <td>11</td>\n",
       "      <td>Reject</td>\n",
       "      <td>2017</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, 2015, 2013, 2015, 2003, 2014, 2016, 200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id original number cdate         tcdate         tmdate  \\\n",
       "HJWHIKqgl  HJWHIKqgl     None    494  None  1478297149874  1559850667018   \n",
       "SyK00v5xx  SyK00v5xx     None    448  None  1478291152993  1544202244497   \n",
       "Hkg4TI9xl  Hkg4TI9xl     None    331  None  1478286631603  1543468347892   \n",
       "Hk1iOLcle  Hk1iOLcle     None    305  None  1478285463347  1528908097367   \n",
       "H178hw9ex  H178hw9ex     None    430  None  1478290507268  1528907922165   \n",
       "\n",
       "          ddate                                            content      forum  \\\n",
       "HJWHIKqgl  None  {'title': 'Generative Models and Model Critici...  HJWHIKqgl   \n",
       "SyK00v5xx  None  {'title': 'A Simple but Tough-to-Beat Baseline...  SyK00v5xx   \n",
       "Hkg4TI9xl  None  {'title': 'A Baseline for Detecting Misclassif...  Hkg4TI9xl   \n",
       "Hk1iOLcle  None  {'title': 'MS MARCO: A Human-Generated MAchine...  Hk1iOLcle   \n",
       "H178hw9ex  None  {'title': 'Dynamic Steerable Frame Networks', ...  H178hw9ex   \n",
       "\n",
       "          referent  ...             details  \\\n",
       "HJWHIKqgl     None  ...  {'replyCount': 12}   \n",
       "SyK00v5xx     None  ...  {'replyCount': 19}   \n",
       "Hkg4TI9xl     None  ...  {'replyCount': 12}   \n",
       "Hk1iOLcle     None  ...  {'replyCount': 12}   \n",
       "H178hw9ex     None  ...  {'replyCount': 11}   \n",
       "\n",
       "                                                       title  \\\n",
       "HJWHIKqgl  Generative Models and Model Criticism via Opti...   \n",
       "SyK00v5xx  A Simple but Tough-to-Beat Baseline for Senten...   \n",
       "Hkg4TI9xl  A Baseline for Detecting Misclassified and Out...   \n",
       "Hk1iOLcle  MS MARCO: A Human-Generated MAchine Reading CO...   \n",
       "H178hw9ex                   Dynamic Steerable Frame Networks   \n",
       "\n",
       "                                                     authors  \\\n",
       "HJWHIKqgl  [Dougal J. Sutherland, Hsiao-Yu Tung, Heiko St...   \n",
       "SyK00v5xx           [Sanjeev Arora, Yingyu Liang, Tengyu Ma]   \n",
       "Hkg4TI9xl                      [Dan Hendrycks, Kevin Gimpel]   \n",
       "Hk1iOLcle  [Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng...   \n",
       "H178hw9ex  [Jörn-Henrik Jacobsen, Bert De Brabandere, Arn...   \n",
       "\n",
       "                                                    abstract  \\\n",
       "HJWHIKqgl  We propose a method to optimize the representa...   \n",
       "SyK00v5xx  \\nThe success of neural network methods for co...   \n",
       "Hkg4TI9xl  We consider the two related problems of detect...   \n",
       "Hk1iOLcle  This paper presents our recent work on the des...   \n",
       "H178hw9ex  Filters in a convolutional network are typical...   \n",
       "\n",
       "                                                    keywords replyCount  \\\n",
       "HJWHIKqgl                            [Unsupervised Learning]         12   \n",
       "SyK00v5xx  [Natural language processing, Unsupervised Lea...         19   \n",
       "Hkg4TI9xl                                  [Computer vision]         12   \n",
       "Hk1iOLcle                                                 []         12   \n",
       "H178hw9ex                   [Computer vision, Deep learning]         11   \n",
       "\n",
       "            label ref_latest ref_len  \\\n",
       "HJWHIKqgl  Accept       2019      34   \n",
       "SyK00v5xx  Accept       2016      49   \n",
       "Hkg4TI9xl  Accept       2016      41   \n",
       "Hk1iOLcle  Reject       2016      25   \n",
       "H178hw9ex  Reject       2017      32   \n",
       "\n",
       "                                                   ref_years  \n",
       "HJWHIKqgl  [2008, 2016, 2011, 2015, 2015, 2008, 2014, 200...  \n",
       "SyK00v5xx  [2012, 2012, 2013, 2013, 2014, 2015, 2016, 200...  \n",
       "Hkg4TI9xl  [2016, 2012, 2011, 2006, 2005, 1993, 2011, 201...  \n",
       "Hk1iOLcle  [2014, 2005, 2012, 2009, 2004, 2014, 2014, 201...  \n",
       "H178hw9ex  [2016, 2015, 2013, 2015, 2003, 2014, 2016, 200...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_pickle('../features/data_features_csv-2017.pkl')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw[[\"id\", \"title\", \"label\", \"authors\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HJWHIKqgl</th>\n",
       "      <td>HJWHIKqgl</td>\n",
       "      <td>Generative Models and Model Criticism via Opti...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>[Dougal J. Sutherland, Hsiao-Yu Tung, Heiko St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyK00v5xx</th>\n",
       "      <td>SyK00v5xx</td>\n",
       "      <td>A Simple but Tough-to-Beat Baseline for Senten...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>[Sanjeev Arora, Yingyu Liang, Tengyu Ma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hkg4TI9xl</th>\n",
       "      <td>Hkg4TI9xl</td>\n",
       "      <td>A Baseline for Detecting Misclassified and Out...</td>\n",
       "      <td>Accept</td>\n",
       "      <td>[Dan Hendrycks, Kevin Gimpel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hk1iOLcle</th>\n",
       "      <td>Hk1iOLcle</td>\n",
       "      <td>MS MARCO: A Human-Generated MAchine Reading CO...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H178hw9ex</th>\n",
       "      <td>H178hw9ex</td>\n",
       "      <td>Dynamic Steerable Frame Networks</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[Jörn-Henrik Jacobsen, Bert De Brabandere, Arn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                              title  \\\n",
       "HJWHIKqgl  HJWHIKqgl  Generative Models and Model Criticism via Opti...   \n",
       "SyK00v5xx  SyK00v5xx  A Simple but Tough-to-Beat Baseline for Senten...   \n",
       "Hkg4TI9xl  Hkg4TI9xl  A Baseline for Detecting Misclassified and Out...   \n",
       "Hk1iOLcle  Hk1iOLcle  MS MARCO: A Human-Generated MAchine Reading CO...   \n",
       "H178hw9ex  H178hw9ex                   Dynamic Steerable Frame Networks   \n",
       "\n",
       "            label                                            authors  \n",
       "HJWHIKqgl  Accept  [Dougal J. Sutherland, Hsiao-Yu Tung, Heiko St...  \n",
       "SyK00v5xx  Accept           [Sanjeev Arora, Yingyu Liang, Tengyu Ma]  \n",
       "Hkg4TI9xl  Accept                      [Dan Hendrycks, Kevin Gimpel]  \n",
       "Hk1iOLcle  Reject  [Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng...  \n",
       "H178hw9ex  Reject  [Jörn-Henrik Jacobsen, Bert De Brabandere, Arn...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_papers = data.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "\n",
    "for k,v in org_papers.items():\n",
    "    t = v[\"title\"].lower()\n",
    "    t = ''.join(filter(str.isalpha, t))\n",
    "    if t in mag_papers:\n",
    "        org_papers[k][\"found\"] = True\n",
    "        org_papers[k][\"mag_data\"] = mag_papers[t]\n",
    "        found += 1\n",
    "    else:\n",
    "        org_papers[k][\"found\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 488)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(org_papers), found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'rkpACe1lx', 'title': 'HyperNetworks', 'label': 'Accept', 'authors': ['David Ha', 'Andrew M. Dai', 'Quoc V. Le'], 'found': True, 'mag_data': {'id': '2884340900', 'title': 'HyperNetworks', 'authors': [{'name': 'David Ha', 'id': '2585023694'}, {'name': 'Andrew M. Dai', 'id': '2083455184'}, {'name': 'Quoc V. Le', 'id': '2148448995'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2017, 'n_citation': 48, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': '', 'volume': '', 'issue': ''}}\n"
     ]
    }
   ],
   "source": [
    "for k, v in org_papers.items():\n",
    "    if v[\"found\"]:\n",
    "        print(v)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2882995289', 'title': 'Joint Embeddings of Scene Graphs and Images', 'authors': [{'name': 'Eugene Belilovsky', 'id': '1237683228'}, {'name': 'Matthew B. Blaschko', 'id': '209766775'}, {'name': 'Jamie Kiros', 'id': '2517897944'}, {'name': 'Raquel Urtasun', 'id': '2291154966'}, {'name': 'Richard S. Zemel', 'id': '2149392531'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2016, 'n_citation': 0, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': '', 'volume': '', 'issue': ''}\n",
      "{'id': '2884257646', 'title': 'HexaConv', 'authors': [{'name': 'Emiel Hoogeboom', 'id': '2884849408'}, {'name': 'Jorn W.T. Peters', 'id': '2884062723'}, {'name': 'Taco S. Cohen', 'id': '2167890275'}, {'name': 'Max Welling', 'id': '2014508897'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2018, 'n_citation': 0, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': '', 'volume': '', 'issue': ''}\n",
      "{'id': '2884340900', 'title': 'HyperNetworks', 'authors': [{'name': 'David Ha', 'id': '2585023694'}, {'name': 'Andrew M. Dai', 'id': '2083455184'}, {'name': 'Quoc V. Le', 'id': '2148448995'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2017, 'n_citation': 48, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': '', 'volume': '', 'issue': ''}\n",
      "{'id': '2885318751', 'title': 'Categorical Reparametrization with Gumble-Softmax', 'authors': [{'name': 'Eric Jang', 'id': '2731650952'}, {'name': 'Shixiang Gu', 'id': '2112773189'}, {'name': 'Ben Poole', 'id': '2164532021'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2017, 'n_citation': 1, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': 'OpenReviews.net', 'volume': '', 'issue': ''}\n",
      "{'id': '769612788', 'title': 'Distributional Smoothing with Virtual Adversarial Training', 'authors': [{'name': 'Takeru Miyato', 'id': '2252860004'}, {'name': 'Shin-ichi Maeda', 'id': '2127973671'}, {'name': 'Masanori Koyama', 'id': '2485198271'}, {'name': 'Ken Nakae', 'id': '2159123898'}, {'name': 'Shin Ishii', 'id': '2063114072'}], 'venue': {'raw': 'international conference on learning representations', 'id': '2584161585'}, 'year': 2016, 'n_citation': 96, 'page_start': '', 'page_end': '', 'doc_type': 'Conference', 'publisher': '', 'volume': '', 'issue': ''}\n"
     ]
    }
   ],
   "source": [
    "iclr_count =0\n",
    "\n",
    "for k, v in mag_papers.items():\n",
    "#     print(v)\n",
    "#     break\n",
    "    if \"venue\" in v and \"id\" in v[\"venue\"] and v[\"venue\"][\"id\"] == \"2584161585\":\n",
    "        iclr_count += 1\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authors': ['Tri Nguyen',\n",
      "             'Mir Rosenberg',\n",
      "             'Xia Song',\n",
      "             'Jianfeng Gao',\n",
      "             'Saurabh Tiwary',\n",
      "             'Rangan Majumder',\n",
      "             'Li Deng'],\n",
      " 'found': True,\n",
      " 'id': 'Hk1iOLcle',\n",
      " 'label': 'Reject',\n",
      " 'mag_data': {'authors': [{'id': '2557846212', 'name': 'Tri Nguyen'},\n",
      "                          {'id': '2557760238', 'name': 'Mir Rosenberg'},\n",
      "                          {'id': '2559582735', 'name': 'Xia Song'},\n",
      "                          {'id': '2104437897', 'name': 'Jianfeng Gao'},\n",
      "                          {'id': '2642799031', 'name': 'Saurabh Tiwary'},\n",
      "                          {'id': '2274851310', 'name': 'Rangan Majumder'},\n",
      "                          {'id': '2101552792', 'name': 'Li Deng'}],\n",
      "              'doc_type': 'Conference',\n",
      "              'id': '2558203065',\n",
      "              'issue': '',\n",
      "              'n_citation': 55,\n",
      "              'page_end': '',\n",
      "              'page_start': '',\n",
      "              'publisher': '',\n",
      "              'title': 'MS MARCO: A Human-Generated MAchine Reading '\n",
      "                       'COmprehension Dataset',\n",
      "              'venue': {'id': '1127325140',\n",
      "                        'raw': 'neural information processing systems'},\n",
      "              'volume': '',\n",
      "              'year': 2017},\n",
      " 'title': 'MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for k,v in org_papers.items():\n",
    "    if v[\"label\"] == \"Reject\":\n",
    "        pprint(v)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in org_papers.items():\n",
    "    org_papers[k][\"mag_author_ids\"] = []\n",
    "    \n",
    "    if \"mag_data\" in v and \"authors\" in v[\"mag_data\"]:\n",
    "        for a in v[\"mag_data\"][\"authors\"]:\n",
    "            if \"id\" in a:\n",
    "                org_papers[k][\"mag_author_ids\"].append(a[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Hk1iOLcle',\n",
       " 'title': 'MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset',\n",
       " 'label': 'Reject',\n",
       " 'authors': ['Tri Nguyen',\n",
       "  'Mir Rosenberg',\n",
       "  'Xia Song',\n",
       "  'Jianfeng Gao',\n",
       "  'Saurabh Tiwary',\n",
       "  'Rangan Majumder',\n",
       "  'Li Deng'],\n",
       " 'found': True,\n",
       " 'mag_data': {'id': '2558203065',\n",
       "  'title': 'MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset',\n",
       "  'authors': [{'name': 'Tri Nguyen', 'id': '2557846212'},\n",
       "   {'name': 'Mir Rosenberg', 'id': '2557760238'},\n",
       "   {'name': 'Xia Song', 'id': '2559582735'},\n",
       "   {'name': 'Jianfeng Gao', 'id': '2104437897'},\n",
       "   {'name': 'Saurabh Tiwary', 'id': '2642799031'},\n",
       "   {'name': 'Rangan Majumder', 'id': '2274851310'},\n",
       "   {'name': 'Li Deng', 'id': '2101552792'}],\n",
       "  'venue': {'raw': 'neural information processing systems',\n",
       "   'id': '1127325140'},\n",
       "  'year': 2017,\n",
       "  'n_citation': 55,\n",
       "  'page_start': '',\n",
       "  'page_end': '',\n",
       "  'doc_type': 'Conference',\n",
       "  'publisher': '',\n",
       "  'volume': '',\n",
       "  'issue': ''},\n",
       " 'mag_author_ids': ['2557846212',\n",
       "  '2557760238',\n",
       "  '2559582735',\n",
       "  '2104437897',\n",
       "  '2642799031',\n",
       "  '2274851310',\n",
       "  '2101552792']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_papers[\"Hk1iOLcle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mag_augmented_2017_iclr.pickle', 'wb') as handle:\n",
    "    pickle.dump(org_papers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Author IDs from MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mag_augmented_2017_iclr.pickle', 'rb') as handle:\n",
    "    org_papers = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aids_all = {}\n",
    "\n",
    "for k, v in org_papers.items():\n",
    "    if \"mag_author_ids\" in v:\n",
    "        for idx in v[\"mag_author_ids\"]:\n",
    "            aids_all[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aids_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mag_authors_10.txt', 'mag_authors_11.txt', 'mag_authors_12.txt']\n",
      "Read file mag_authors_10.txt in archive ['mag_authors_10.txt', 'mag_authors_11.txt', 'mag_authors_12.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_11.txt in archive ['mag_authors_10.txt', 'mag_authors_11.txt', 'mag_authors_12.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_12.txt in archive ['mag_authors_10.txt', 'mag_authors_11.txt', 'mag_authors_12.txt']\n",
      "Length of file:  13144302\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Read file mag_authors_0.txt in archive ['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_1.txt in archive ['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_2.txt in archive ['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_3.txt in archive ['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_4.txt in archive ['mag_authors_0.txt', 'mag_authors_1.txt', 'mag_authors_2.txt', 'mag_authors_3.txt', 'mag_authors_4.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Read file mag_authors_5.txt in archive ['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_6.txt in archive ['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_7.txt in archive ['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_8.txt in archive ['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Read file mag_authors_9.txt in archive ['mag_authors_5.txt', 'mag_authors_6.txt', 'mag_authors_7.txt', 'mag_authors_8.txt', 'mag_authors_9.txt']\n",
      "Length of file:  20000001\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "err in json loading\n",
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "authors_dict = {}\n",
    "\n",
    "for f in author_files:\n",
    "    archive = zipfile.ZipFile(f, 'r')\n",
    "    zip_files = archive.namelist()\n",
    "    print(zip_files)\n",
    "    \n",
    "    for fi in zip_files:\n",
    "        bytes_text = archive.read(fi)\n",
    "        print(\"Read file {} in archive {}\".format(fi, zip_files))\n",
    "        \n",
    "        try:\n",
    "            str_list = bytes_text.decode('utf-8').split(\"\\n\")\n",
    "            print(\"Length of file: \", len(str_list))\n",
    "            idx = 0\n",
    "            \n",
    "            for l in str_list:\n",
    "                if idx % 1000000 == 0:\n",
    "                    print(idx)\n",
    "                idx += 1\n",
    "                \n",
    "                try:\n",
    "                    author_info_dict = json.loads(l)\n",
    "                    if \"id\" in author_info_dict:\n",
    "                        if author_info_dict[\"id\"] in aids_all:\n",
    "                            authors_dict[author_info_dict[\"id\"]] = author_info_dict\n",
    "                except Exception as ex:\n",
    "                    print(\"err in json loading\")\n",
    "                    print(ex)\n",
    "        except Exception as ex:\n",
    "            print(\"err in bytes decoding\")\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2806500922',\n",
       " '2806505101',\n",
       " '2807295408',\n",
       " '280780484',\n",
       " '2809708345',\n",
       " '2811485176',\n",
       " '2820585936',\n",
       " '2833214316',\n",
       " '2838961412',\n",
       " '2841437152']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(authors_dict.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2809708345',\n",
       " 'name': 'Hang Qi',\n",
       " 'normalized_name': 'hang qi',\n",
       " 'org': 'University of California, Los Angeles',\n",
       " 'orgs': ['University of California, Los Angeles'],\n",
       " 'pubs': [{'i': '2752512710', 'r': 0}],\n",
       " 'n_pubs': 1,\n",
       " 'n_citation': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_dict[\"2809708345\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mag_authors_pubs_cits_2017_iclr.pickle', 'wb') as handle:\n",
    "    pickle.dump(authors_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in org_papers.items():\n",
    "    org_papers[k][\"num_pubs\"] = []\n",
    "    org_papers[k][\"num_cits\"] = []\n",
    "    \n",
    "    if \"mag_author_ids\" in v:\n",
    "        for auid in v[\"mag_author_ids\"]:\n",
    "            if \"n_pubs\" in authors_dict[auid]:\n",
    "                org_papers[k][\"num_pubs\"].append(authors_dict[auid][\"n_pubs\"])\n",
    "            if \"n_citation\" in authors_dict[auid]:\n",
    "                org_papers[k][\"num_cits\"].append(authors_dict[auid][\"n_citation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HJWHIKqgl', 'SyK00v5xx', 'Hkg4TI9xl', 'Hk1iOLcle', 'H178hw9ex']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(org_papers.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 'HJWHIKqgl',\n",
       "  'title': 'Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy',\n",
       "  'label': 'Accept',\n",
       "  'authors': ['Dougal J. Sutherland',\n",
       "   'Hsiao-Yu Tung',\n",
       "   'Heiko Strathmann',\n",
       "   'Soumyajit De',\n",
       "   'Aaditya Ramdas',\n",
       "   'Alex Smola',\n",
       "   'Arthur Gretton'],\n",
       "  'found': True,\n",
       "  'mag_data': {'id': '2562221994',\n",
       "   'title': 'Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy',\n",
       "   'authors': [{'name': 'Dougal J. Sutherland', 'id': '2122024741'},\n",
       "    {'name': 'Hsiao-Yu Fish Tung', 'id': '2898197610'},\n",
       "    {'name': 'Heiko Strathmann', 'id': '1967795448'},\n",
       "    {'name': 'Soumyajit De', 'id': '2564638990'},\n",
       "    {'name': 'Aaditya Ramdas', 'id': '2022285571'},\n",
       "    {'name': 'Alexander J. Smola', 'id': '1972291593'},\n",
       "    {'name': 'Arthur Gretton', 'id': '2468960519'}],\n",
       "   'venue': {'raw': 'international conference on learning representations',\n",
       "    'id': '2584161585'},\n",
       "   'year': 2017,\n",
       "   'n_citation': 29,\n",
       "   'page_start': '',\n",
       "   'page_end': '',\n",
       "   'doc_type': 'Conference',\n",
       "   'publisher': '',\n",
       "   'volume': '',\n",
       "   'issue': ''},\n",
       "  'mag_author_ids': ['2122024741',\n",
       "   '2898197610',\n",
       "   '1967795448',\n",
       "   '2564638990',\n",
       "   '2022285571',\n",
       "   '1972291593',\n",
       "   '2468960519'],\n",
       "  'num_pubs': [22, 4, 17, 1, 55, 370, 191],\n",
       "  'num_cits': [163, 53, 187, 29, 250, 53943, 7336]},\n",
       " {'id': 'SyK00v5xx',\n",
       "  'title': 'A Simple but Tough-to-Beat Baseline for Sentence Embeddings',\n",
       "  'label': 'Accept',\n",
       "  'authors': ['Sanjeev Arora', 'Yingyu Liang', 'Tengyu Ma'],\n",
       "  'found': True,\n",
       "  'mag_data': {'id': '2752172973',\n",
       "   'title': 'A Simple but Tough-to-Beat Baseline for Sentence Embeddings',\n",
       "   'authors': [{'name': 'Sanjeev Arora', 'id': '2791527347'},\n",
       "    {'name': 'Yingyu Liang', 'id': '2124668569'},\n",
       "    {'name': 'Tengyu Ma', 'id': '2171800532'}],\n",
       "   'venue': {'raw': 'international conference on learning representations',\n",
       "    'id': '2584161585'},\n",
       "   'year': 2017,\n",
       "   'n_citation': 63,\n",
       "   'page_start': '',\n",
       "   'page_end': '',\n",
       "   'doc_type': 'Conference',\n",
       "   'publisher': '',\n",
       "   'volume': '',\n",
       "   'issue': ''},\n",
       "  'mag_author_ids': ['2791527347', '2124668569', '2171800532'],\n",
       "  'num_pubs': [6, 50, 44],\n",
       "  'num_cits': [90, 545, 730]},\n",
       " {'id': 'Hkg4TI9xl',\n",
       "  'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks',\n",
       "  'label': 'Accept',\n",
       "  'authors': ['Dan Hendrycks', 'Kevin Gimpel'],\n",
       "  'found': True,\n",
       "  'mag_data': {'id': '2531327146',\n",
       "   'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks',\n",
       "   'authors': [{'name': 'Dan Hendrycks', 'id': '2461221787'},\n",
       "    {'name': 'Kevin Gimpel', 'id': '2000806699'}],\n",
       "   'venue': {'raw': 'international conference on learning representations',\n",
       "    'id': '2584161585'},\n",
       "   'year': 2017,\n",
       "   'n_citation': 25,\n",
       "   'page_start': '',\n",
       "   'page_end': '',\n",
       "   'doc_type': 'Conference',\n",
       "   'publisher': '',\n",
       "   'volume': '',\n",
       "   'issue': ''},\n",
       "  'mag_author_ids': ['2461221787', '2000806699'],\n",
       "  'num_pubs': [9, 69],\n",
       "  'num_cits': [53, 2114]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_papers[\"HJWHIKqgl\"], org_papers[\"SyK00v5xx\"], org_papers[\"Hkg4TI9xl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2791527347',\n",
       " 'name': 'Sanjeev Arora',\n",
       " 'normalized_name': 'sanjeev arora',\n",
       " 'org': 'Princeton University',\n",
       " 'orgs': ['Princeton University'],\n",
       " 'pubs': [{'i': '2768080738', 'r': 0},\n",
       "  {'i': '2565444551', 'r': 0},\n",
       "  {'i': '2625387573', 'r': 0},\n",
       "  {'i': '2518186251', 'r': 0},\n",
       "  {'i': '2794612894', 'r': 0},\n",
       "  {'i': '2752172973', 'r': 0}],\n",
       " 'n_pubs': 6,\n",
       " 'n_citation': 90}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_dict[\"2791527347\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../features/mag_features_2017_iclr.pickle', 'wb') as handle:\n",
    "    pickle.dump(org_papers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
