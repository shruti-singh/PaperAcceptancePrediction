{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../reviewratings_iclr17_peeread.pkl\", \"rb\") as f:\n",
    "    rr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT_LIST SAMPLE:\n",
    "# \n",
    "# {'abaselinefordetectingmisclassifiedandoutofdistributionexamplesinneuralnetworks': {'AnonReviewer1': {'MEANINGFUL_COMPARISON': [4,\n",
    "#     datetime.datetime(2016, 12, 19, 0, 0)],\n",
    "#    'ORIGINALITY': [4, datetime.datetime(2016, 12, 19, 0, 0)],\n",
    "#    'RECOMMENDATION': [6, datetime.datetime(2016, 12, 19, 0, 0)]},\n",
    "#   'AnonReviewer2': {'RECOMMENDATION': [6,\n",
    "#     datetime.datetime(2016, 12, 16, 0, 0)]},\n",
    "#   'AnonReviewer3': {'IMPACT': [2, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'ORIGINALITY': [3, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'RECOMMENDATION': [6, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'SOUNDNESS_CORRECTNESS': [3, datetime.datetime(2017, 1, 20, 0, 0)]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_aspects = [\"MEANINGFUL_COMPARISON\", \"IMPACT\", \"ORIGINALITY\", \"RECOMMENDATION\", \"SUBSTANCE\", \"SOUNDNESS_CORRECTNESS\", \"APPROPRIATENESS\", \"CLARITY\"]\n",
    "\n",
    "aspect_dict = defaultdict(dict)\n",
    "inspect_list = {}\n",
    "\n",
    "for k in rr:\n",
    "    new_key = rr[k][\"title\"].strip().lower()\n",
    "    \n",
    "    new_key = re.sub('[^0-9a-zA-Z]+', '', new_key)\n",
    "    \n",
    "    aspect_dict[new_key][\"title\"] = rr[k][\"title\"]\n",
    "    aspect_dict[new_key][\"dec\"] = rr[k][\"accepted\"]\n",
    "    aspect_dict[new_key][\"pr_id\"] = k\n",
    "    \n",
    "    inspect_list[new_key] = {}\n",
    "    \n",
    "    if \"reviews\" in rr[k]:\n",
    "        for rev in rr[k][\"reviews\"]:\n",
    "            if \"OTHER_KEYS\" in rev:\n",
    "                if rev[\"OTHER_KEYS\"].find(\"AnonReviewer\") > -1:\n",
    "                    anon_reviewer = rev[\"OTHER_KEYS\"].split(\" \")[-1]\n",
    "                    if anon_reviewer in inspect_list[new_key]:\n",
    "                        #inspect_list[new_key][anon_reviewer]\n",
    "                        dummy = 1\n",
    "                    else:\n",
    "                        inspect_list[new_key][anon_reviewer] = {}\n",
    "                    if \"DATE\" in rev:\n",
    "                        if rev[\"DATE\"].find(\"modified\") > -1:\n",
    "                            d = rev[\"DATE\"]\n",
    "                            try:\n",
    "                                rev[\"DATE\"] = re.findall('([0-9]+ [A-Za-z]+ [0-9][0-9][0-9][0-9]\\))$', d)[0][:-1]\n",
    "                            except Exception:\n",
    "                                print(rev[\"DATE\"])\n",
    "                        else:\n",
    "                            try:\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].replace(\"(\", \"\")\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].replace(\")\", \"\")\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].strip()\n",
    "                                date_of_review = parse(rev[\"DATE\"])\n",
    "                            except Exception:\n",
    "                                print(rev[\"DATE\"], k)\n",
    "                    else:\n",
    "                        date_of_review = parse(\"1 Jan 2000\")\n",
    "                    \n",
    "                    for asp in acl_aspects:\n",
    "                        if asp in rev:\n",
    "                            if asp in inspect_list[new_key][anon_reviewer]:\n",
    "                                prev_date = inspect_list[new_key][anon_reviewer][asp][1]\n",
    "                                if prev_date < date_of_review:\n",
    "                                    prev_rev_text = inspect_list[new_key][anon_reviewer][asp][2]\n",
    "                                    inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"] + prev_rev_text]\n",
    "                                else:\n",
    "                                    inspect_list[new_key][anon_reviewer][asp][2] = inspect_list[new_key][anon_reviewer][asp][2] + \". \" +  rev[\"TITLE\"] + \". \" + rev[\"comments\"]\n",
    "                            else:\n",
    "                                inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"], \" \"]\n",
    "\n",
    "#                         if asp in rev:\n",
    "#                             if asp in inspect_list[new_key][anon_reviewer]:\n",
    "#                                 prev_date = inspect_list[new_key][anon_reviewer][asp][1]\n",
    "#                                 if prev_date < date_of_review:\n",
    "#                                     prev_rev_text = inspect_list[new_key][anon_reviewer][asp][2] + \". \" + inspect_list[new_key][anon_reviewer][asp][3]\n",
    "#                                     # current rev text, prev_rev_text\n",
    "#                                     inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"], prev_rev_text]\n",
    "#                                 else:\n",
    "#                                     inspect_list[new_key][anon_reviewer][asp][3] = inspect_list[new_key][anon_reviewer][asp][3] + \". \" +  rev[\"TITLE\"] + \". \" + rev[\"comments\"]\n",
    "#                             else:\n",
    "#                                 inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"], \" \"]\n",
    "            else:\n",
    "                for asp in acl_aspects:\n",
    "                    if asp in rev:\n",
    "                        inspect_list.append((k, rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../ICLR data/masterdata_unbalanced/\"\n",
    "year = 2017\n",
    "paper_file = \"papers_{}.pkl\".format(year)\n",
    "\n",
    "\n",
    "with open(data_dir+paper_file, \"rb\") as f:\n",
    "    papers_data = pickle.load(f)\n",
    "\n",
    "\n",
    "final_dict = {}\n",
    "\n",
    "not_found = []\n",
    "\n",
    "for k in papers_data:\n",
    "    t = papers_data[k][\"content\"][\"title\"].strip().lower()\n",
    "    t = re.sub('[^0-9a-zA-Z]+', '', t)\n",
    "    if t in aspect_dict:\n",
    "        final_dict[k] = aspect_dict[t]\n",
    "        final_dict[k][\"rev_info\"] = inspect_list[t]\n",
    "    else:\n",
    "#         print(t, k)\n",
    "        not_found.append(t)\n",
    "print(len(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dec': False,\n",
       " 'pr_id': '618',\n",
       " 'rev_info': {'AnonReviewer1': {'RECOMMENDATION': [5,\n",
       "    datetime.datetime(2016, 12, 26, 0, 0),\n",
       "    'review. This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features. The network can estimate the transformation of filters given the input images. \\n\\nThis work is based on a solid technical foundation and is motivated by a plausible rationale. Yet, the value of this work in practice is subject to questions:\\n\\n(1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally). Do such transformations constitute real challenges in practice? State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations. What such components would add to the state of the art? Limited experiments on Cifar-10 does not seem to provide a very strong argument.\\n\\n(2) The computational cost is not discussed.',\n",
       "    ' . review. This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features. The network can estimate the transformation of filters given the input images. \\n\\nThis work is based on a solid technical foundation and is motivated by a plausible rationale. Yet, the value of this work in practice is subject to questions:\\n\\n(1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally). Do such transformations constitute real challenges in practice? State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations. What such components would add to the state of the art? Limited experiments on Cifar-10 does not seem to provide a very strong argument.\\n\\n(2) The computational cost is not discussed.']},\n",
       "  'AnonReviewer2': {'RECOMMENDATION': [7,\n",
       "    datetime.datetime(2016, 12, 16, 0, 0),\n",
       "    'Interesting approach for adaptable convolutional filters. This works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied. Authors provide a detailed overview of steerable frames followed with an experimental section which applies dynamic steerable network to small machine learning problems where the steerability is conceptually useful.\\n\\nEven though the evaluation is performed only on few small tasks, the reason why more tasks were not evaluated is that piece-wise pose invariance is needed only for a subset of tasks. The fact, that simply using overcomplete bases as a sort of \"feature pre-processing\" improves the results for already highly optimized ResNet and DenseNet architectures is quite interesting achievement.\\n\\nFor the edge detection, a relatively hard baseline is selected - the Dynamic Filter Networks, which already attempts to achieve position invariant filters. The fact that DSFN improves the performance on this task verifies that regressing the parametrization of the steerable filters yields better results than regressing the filters directly.\\n\\nIn the last experiment authors apply the network to video classification using LSTMs and they show that the improved performance is not due to increased capacity of the network.\\n\\nIn general, it is quite interesting work. Even though it does not offer ground-breaking results (mainly in a sense of not performing experiments on larger tasks), it is theoretically interesting and shows promising results.\\n\\nThere are few minor issues and suggestions related to the paper:\\n* For the LSTM experiment, in order to be more exact, it would be useful to include information about total number of parameters, as the network which estimates the pose also increases the number of parameters.\\n* Would it be possible to provide more details about how the back-propagation is done through the steerable filters?\\n* For the Edge Detection experiment, it would be useful to provide results for some standard baseline - e.g. CNN with a similar number of parameters. Simply to see how useful it is to have location-variant filters for this task.\\n* The last sentence in second paragraph on page 1 is missing a verb. Also it is maybe unnecessary.\\n* The hyphenation for ConvNet is incorrect on multiple places (probably `\\\\hyphenation{Conv-Net}` would fix it).\\n',\n",
       "    ' . Interesting approach for adaptable convolutional filters. This works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied. Authors provide a detailed overview of steerable frames followed with an experimental section which applies dynamic steerable network to small machine learning problems where the steerability is conceptually useful.\\n\\nEven though the evaluation is performed only on few small tasks, the reason why more tasks were not evaluated is that piece-wise pose invariance is needed only for a subset of tasks. The fact, that simply using overcomplete bases as a sort of \"feature pre-processing\" improves the results for already highly optimized ResNet and DenseNet architectures is quite interesting achievement.\\n\\nFor the edge detection, a relatively hard baseline is selected - the Dynamic Filter Networks, which already attempts to achieve position invariant filters. The fact that DSFN improves the performance on this task verifies that regressing the parametrization of the steerable filters yields better results than regressing the filters directly.\\n\\nIn the last experiment authors apply the network to video classification using LSTMs and they show that the improved performance is not due to increased capacity of the network.\\n\\nIn general, it is quite interesting work. Even though it does not offer ground-breaking results (mainly in a sense of not performing experiments on larger tasks), it is theoretically interesting and shows promising results.\\n\\nThere are few minor issues and suggestions related to the paper:\\n* For the LSTM experiment, in order to be more exact, it would be useful to include information about total number of parameters, as the network which estimates the pose also increases the number of parameters.\\n* Would it be possible to provide more details about how the back-propagation is done through the steerable filters?\\n* For the Edge Detection experiment, it would be useful to provide results for some standard baseline - e.g. CNN with a similar number of parameters. Simply to see how useful it is to have location-variant filters for this task.\\n* The last sentence in second paragraph on page 1 is missing a verb. Also it is maybe unnecessary.\\n* The hyphenation for ConvNet is incorrect on multiple places (probably `\\\\hyphenation{Conv-Net}` would fix it).\\n']},\n",
       "  'AnonReviewer3': {'RECOMMENDATION': [4,\n",
       "    datetime.datetime(2016, 12, 20, 0, 0),\n",
       "    'No Title. I sincerely apologize for the late review!\\n\\nThe first part has a strong emphasis on the technical part. It could benefit from some high level arguments on what the method aims to achieve, what limitation is there to overcome. I may have misunderstood the contribution (in which case please correct me) that the main novel part of the paper is the suggestion to learn the group parameterizations instead of pre-fixing them. So instead of applying it to common spatial filters as in De Brabandere et al., it is applied to Steerable Frames?\\n\\nThe first contribution suggests that \"general frame bases are better suited to represent sensory input data than the commonly used pixel basis.\". The experiments on Cifar10+ indicate that this is not true in general. Considering the basis as a hyper-parameter, expensive search has to be conducted to find that the Gauss-Frame gives better results. I assume this does not suggest that the Gauss-Frame is always better, at least there is weak evidence on a single network presented. Maybe the first contribution has to be re-stated. Further is the \"Pixel\" network representation corrected for the larger number of parameters. As someone who is interested in using this, what are the runtime considerations? \\n\\nI would strongly suggest to improve Fig.3. The Figure uses \"w\" several times in different notations and depictions. It mixes boxes, single symbols and illustrative figures. It took some time to decipher the Figure and its flow. \\n\\n\\nSummary: The paper is sufficiently clear, technical at many places and readability can be improved. E.g., the introduction of frames in the beginning lacks motivation and is rather unclear to someone new to this concept. The work falls in the general category of methods that impose knowledge about filter transformations into the network architecture. For me that has always two sides, the algorithmic and technical part (there are several ways to do this) and the practical side (should I do it)? This is a possible approach to this problem but after the paper I was a bit wondering what I have learned, I am certainly not inspired based on the content of the paper to integrate or build on this work. I am lacking insights into transformational parameters that are relevant for a problem. While the spatial transformer network paper was weaker on the technical elegance side, it provided exactly this: an insight into the feature transformation learned by the algorithm. I am missing this here, e.g., from Table 2  I learn that among four choices one works empirically better. What is destroyed by the x^py^p and Hermite frames that the ResNet is *not* able to recover from? You can construct network architectures that are the superset of both, so that inferior performance could be avoided. \\n\\nThe algorithm is clear but it is similar to the Dynamic Filter Networks paper. And I am unfortunately not convinced about the usefulness of this particular formulation. I\\'d expect a stronger paper with more insights into transformations and comparisons to standard techniques, a clear delineation of when this is advised. ',\n",
       "    ' . No Title. I sincerely apologize for the late review!\\n\\nThe first part has a strong emphasis on the technical part. It could benefit from some high level arguments on what the method aims to achieve, what limitation is there to overcome. I may have misunderstood the contribution (in which case please correct me) that the main novel part of the paper is the suggestion to learn the group parameterizations instead of pre-fixing them. So instead of applying it to common spatial filters as in De Brabandere et al., it is applied to Steerable Frames?\\n\\nThe first contribution suggests that \"general frame bases are better suited to represent sensory input data than the commonly used pixel basis.\". The experiments on Cifar10+ indicate that this is not true in general. Considering the basis as a hyper-parameter, expensive search has to be conducted to find that the Gauss-Frame gives better results. I assume this does not suggest that the Gauss-Frame is always better, at least there is weak evidence on a single network presented. Maybe the first contribution has to be re-stated. Further is the \"Pixel\" network representation corrected for the larger number of parameters. As someone who is interested in using this, what are the runtime considerations? \\n\\nI would strongly suggest to improve Fig.3. The Figure uses \"w\" several times in different notations and depictions. It mixes boxes, single symbols and illustrative figures. It took some time to decipher the Figure and its flow. \\n\\n\\nSummary: The paper is sufficiently clear, technical at many places and readability can be improved. E.g., the introduction of frames in the beginning lacks motivation and is rather unclear to someone new to this concept. The work falls in the general category of methods that impose knowledge about filter transformations into the network architecture. For me that has always two sides, the algorithmic and technical part (there are several ways to do this) and the practical side (should I do it)? This is a possible approach to this problem but after the paper I was a bit wondering what I have learned, I am certainly not inspired based on the content of the paper to integrate or build on this work. I am lacking insights into transformational parameters that are relevant for a problem. While the spatial transformer network paper was weaker on the technical elegance side, it provided exactly this: an insight into the feature transformation learned by the algorithm. I am missing this here, e.g., from Table 2  I learn that among four choices one works empirically better. What is destroyed by the x^py^p and Hermite frames that the ResNet is *not* able to recover from? You can construct network architectures that are the superset of both, so that inferior performance could be avoided. \\n\\nThe algorithm is clear but it is similar to the Dynamic Filter Networks paper. And I am unfortunately not convinced about the usefulness of this particular formulation. I\\'d expect a stronger paper with more insights into transformations and comparisons to standard techniques, a clear delineation of when this is advised. ']}},\n",
       " 'title': 'Dynamic Steerable Frame Networks'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[\"H178hw9ex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = []\n",
    "keywords = [\"original\", \"proposal\", \"originality\", \"unique\", \"novelty\", \"novel\", \"contribution\", \"significance\", \"significant\", \"new way\"]\n",
    "\n",
    "for k in final_dict:\n",
    "    if \"rev_info\" in final_dict[k]:\n",
    "        for reviewer_num in final_dict[k]['rev_info']:\n",
    "            if \"ORIGINALITY\" in final_dict[k]['rev_info'][reviewer_num]:\n",
    "                #excel_data[k+\"_\"+reviewer_num] = { \"dec\": final_dict[k][\"dec\"],\"score\": final_dict[k]['rev_info'][reviewer_num][\"ORIGINALITY\"][0] }\n",
    "                data_tuple = [k+\"_\"+reviewer_num, final_dict[k][\"dec\"], final_dict[k]['rev_info'][reviewer_num][\"ORIGINALITY\"][0]]\n",
    "\n",
    "                current_text = final_dict[k]['rev_info'][reviewer_num][\"ORIGINALITY\"][2]\n",
    "#                 other_text = final_dict[k]['rev_info'][reviewer_num][\"ORIGINALITY\"][3]\n",
    "\n",
    "                doc = nlp(current_text)\n",
    "                curr_comm = []\n",
    "                for s in doc.sents:\n",
    "                    sent_text = s.text.lower()\n",
    "                    sent_text = sent_text.replace(\"\\n\", \" \")\n",
    "                    if sent_text.find(\"proposal\") > -1 or (sent_text.find(\"proposed\") > -1 and sent_text.find(\"new\") > -1):\n",
    "                        curr_comm.append(sent_text)\n",
    "                    for kw in keywords:\n",
    "                        if sent_text.find(kw) > -1:\n",
    "                            curr_comm.append(sent_text)\n",
    "\n",
    "#                 doc = nlp(other_text)\n",
    "#                 other_comm = []\n",
    "#                 for s in doc.sents:\n",
    "#                     sent_text = s.text.lower()\n",
    "#                     if sent_text.find(\"proposal\") > -1 or (sent_text.find(\"proposed\") > -1 and sent_text.find(\"new\") > -1):\n",
    "#                         other_comm.append(sent_text)\n",
    "#                     for kw in keywords:\n",
    "#                         if sent_text.find(kw) > -1:\n",
    "#                             other_comm.append(sent_text)\n",
    "\n",
    "                data_tuple.append(\" \".join(curr_comm))\n",
    "                data_tuple.append(\"https://openreview.net/forum?id={}\".format(k))\n",
    "                excel_data.append(data_tuple)\n",
    "    else:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Paper_ReviewId  Accept  NoveltyScore  \\\n",
      "0  SJJKxrsgl_AnonReviewer2    True             3   \n",
      "1  BJrFC6ceg_AnonReviewer1    True             5   \n",
      "\n",
      "                                             Comment  \\\n",
      "0                                                      \n",
      "1  my summary of the main contribution: autoregre...   \n",
      "\n",
      "                                  OpenReview  \n",
      "0  https://openreview.net/forum?id=SJJKxrsgl  \n",
      "1  https://openreview.net/forum?id=BJrFC6ceg  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(excel_data, columns = ['Paper_ReviewId', 'Accept', 'NoveltyScore', \"Comment\", \"OpenReview\"])\n",
    "print(df.head(2))\n",
    "df.to_excel('2017_novelty_comments.xlsx', sheet_name='sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features/rev_aspects_2017_peerread.pkl\", \"rb\") as f:\n",
    "    review_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B1-Hhnslg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '559',\n",
       "  'title': 'Prototypical Networks for Few-shot Learning'},\n",
       " 'B1-q5Pqxl': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 6, 6],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '384',\n",
       "  'title': 'Machine Comprehension Using Match-LSTM and Answer Pointer'},\n",
       " 'B16Jem9xe': {'RECOMMENDATION': [8, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '534',\n",
       "  'title': 'Learning in Implicit Generative Models'},\n",
       " 'B16dGcqlx': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [1],\n",
       "  'RECOMMENDATION': [6, 5],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '341',\n",
       "  'title': 'Third Person Imitation Learning'},\n",
       " 'B184E5qee': {'CLARITY': [5],\n",
       "  'IMPACT': [2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [5, 7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '339',\n",
       "  'title': 'Improving Neural Language Models with a Continuous Cache'},\n",
       " 'B186cP9gx': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '623',\n",
       "  'title': 'Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond'},\n",
       " 'B1E7Pwqgl': {'RECOMMENDATION': [3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '633',\n",
       "  'title': 'Cooperative Training of Descriptor and Generator Networks'},\n",
       " 'B1ElR4cgg': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '446',\n",
       "  'title': 'Adversarially Learned Inference'},\n",
       " 'B1G9tvcgx': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '627',\n",
       "  'title': 'Neural Machine Translation with Latent Semantic of Image and Text'},\n",
       " 'B1GOWV5eg': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '452',\n",
       "  'title': 'Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning'},\n",
       " 'B1Igu2ogg': {'CLARITY': [5, 4, 5],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '330',\n",
       "  'title': 'Efficient Vector Representation for Documents through Corruption'},\n",
       " 'B1IzH7cxl': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '712',\n",
       "  'title': 'A Neural Stochastic Volatility Model'},\n",
       " 'B1KBHtcel': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '604',\n",
       "  'title': \"Here's My Point: Argumentation Mining with Pointer Networks\"},\n",
       " 'B1M8JF9xx': {'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SUBSTANCE': [4, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '368',\n",
       "  'title': 'On the Quantitative Analysis of Decoder-Based Generative Models'},\n",
       " 'B1PA8fqeg': {'RECOMMENDATION': [2, 3, 1],\n",
       "  'dec': False,\n",
       "  'pr_id': '718',\n",
       "  'title': 'Multiagent System for Layer Free Network'},\n",
       " 'B1TTpYKgx': {'RECOMMENDATION': [6, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '742',\n",
       "  'title': 'On the Expressive Power of Deep Neural Networks'},\n",
       " 'B1YfAfcgl': {'RECOMMENDATION': [9, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '458',\n",
       "  'title': 'Entropy-SGD: Biasing Gradient Descent Into Wide Valleys'},\n",
       " 'B1ZXuTolx': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '550',\n",
       "  'title': 'Revisiting Denoising Auto-Encoders'},\n",
       " 'B1akgy9xx': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '725',\n",
       "  'title': 'Making Stochastic Neural Networks from Deterministic Ones'},\n",
       " 'B1ckMDqlg': {'IMPACT': [5],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '399',\n",
       "  'title': ' Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer'},\n",
       " 'B1ewdt9xe': {'CLARITY': [5],\n",
       "  'MEANINGFUL_COMPARISON': [5, 2],\n",
       "  'ORIGINALITY': [4, 4, 4],\n",
       "  'RECOMMENDATION': [6, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '350',\n",
       "  'title': 'Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning'},\n",
       " 'B1gtu5ilg': {'CLARITY': [5, 5],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'RECOMMENDATION': [5, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '332',\n",
       "  'title': 'Transfer of View-manifold Learning to Similarity Perception of Novel Objects'},\n",
       " 'B1hdzd5lg': {'CLARITY': [3, 4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '374',\n",
       "  'title': 'Words or Characters? Fine-grained Gating for Reading Comprehension'},\n",
       " 'B1jnyXXJx': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '548',\n",
       "  'title': 'Charged Point Normalization: An Efficient Solution to the Saddle Point Problem'},\n",
       " 'B1kJ6H9ex': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '432',\n",
       "  'title': 'Combining policy gradient and Q-learning'},\n",
       " 'B1mAJI9gl': {'RECOMMENDATION': [4, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '674',\n",
       "  'title': 'Towards Understanding the Invertibility of Convolutional Neural Networks'},\n",
       " 'B1oK8aoxe': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '321',\n",
       "  'title': 'Stochastic Neural Networks for Hierarchical Reinforcement Learning'},\n",
       " 'B1s6xvqlx': {'CLARITY': [5],\n",
       "  'IMPACT': [5, 4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [8, 7, 5],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '405',\n",
       "  'title': 'Recurrent Environment Simulators'},\n",
       " 'B1vRTeqxg': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '538',\n",
       "  'title': 'Learning Continuous Semantic Representations of Symbolic Expressions'},\n",
       " 'BJ--gPcxl': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '648',\n",
       "  'title': 'Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks'},\n",
       " 'BJ0Ee8cxx': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '673',\n",
       "  'title': 'Hierarchical Memory Networks'},\n",
       " 'BJ3filKll': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '485',\n",
       "  'title': 'Efficient Representation of Low-Dimensional Manifolds using Deep Networks'},\n",
       " 'BJ46w6Ule': {'RECOMMENDATION': [3, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '781',\n",
       "  'title': 'Dynamic Partition Models'},\n",
       " 'BJ5UeU9xx': {'RECOMMENDATION': [6, 9, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '427',\n",
       "  'title': 'Visualizing Deep Neural Network Decisions: Prediction Difference Analysis'},\n",
       " 'BJ6oOfqge': {'RECOMMENDATION': [7, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '461',\n",
       "  'title': 'Temporal Ensembling for Semi-Supervised Learning'},\n",
       " 'BJ8fyHceg': {'RECOMMENDATION': [6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '529',\n",
       "  'title': 'Tuning Recurrent Neural Networks with Reinforcement Learning'},\n",
       " 'BJ9fZNqle': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '706',\n",
       "  'title': 'Multi-modal Variational Encoder-Decoders'},\n",
       " 'BJAA4wKxg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '748',\n",
       "  'title': 'A Convolutional Encoder Model for Neural Machine Translation'},\n",
       " 'BJAFbaolg': {'APPROPRIATENESS': [3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '325',\n",
       "  'title': 'Learning to Generate Samples from Noise through Infusion Training'},\n",
       " 'BJC8LF9ex': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '599',\n",
       "  'title': 'Recurrent Neural Networks for Multivariate Time Series with Missing Values'},\n",
       " 'BJFG8Yqxl': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '600',\n",
       "  'title': 'Group Sparse CNNs for Question Sentence Classification with Answer Sets'},\n",
       " 'BJK3Xasel': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 5, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '322',\n",
       "  'title': 'Nonparametric Neural Networks'},\n",
       " 'BJKYvt5lg': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '353',\n",
       "  'title': 'PixelVAE: A Latent Variable Model for Natural Images'},\n",
       " 'BJRIA3Fgg': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '540',\n",
       "  'title': 'Modularized Morphing of Neural Networks'},\n",
       " 'BJVEEF9lx': {'RECOMMENDATION': [4, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '606',\n",
       "  'title': 'Learning Approximate Distribution-Sensitive Data Structures'},\n",
       " 'BJYwwY9ll': {'CLARITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '354',\n",
       "  'title': 'Snapshot Ensembles: Train 1, Get M for Free'},\n",
       " 'BJ_MGwqlg': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '642',\n",
       "  'title': 'Rethinking Numerical Representations for Deep Neural Networks'},\n",
       " 'BJa0ECFxe': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '726',\n",
       "  'title': 'Information Dropout: learning optimal representations through noise'},\n",
       " 'BJbD_Pqlg': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '629',\n",
       "  'title': 'Human perception in computer vision'},\n",
       " 'BJh6Ztuxl': {'RECOMMENDATION': [8, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '489',\n",
       "  'title': 'Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks'},\n",
       " 'BJhZeLsxx': {'CLARITY': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '333',\n",
       "  'title': 'What does it take to generate natural textures?'},\n",
       " 'BJjn-Yixl': {'RECOMMENDATION': [5, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '569',\n",
       "  'title': 'Attentive Recurrent Comparators'},\n",
       " 'BJluGHcee': {'RECOMMENDATION': [7, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '689',\n",
       "  'title': 'Tensorial Mixture Models'},\n",
       " 'BJm4T4Kgx': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '481',\n",
       "  'title': 'Adversarial Machine Learning at Scale'},\n",
       " 'BJrFC6ceg': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '336',\n",
       "  'title': 'PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications'},\n",
       " 'BJtNZAFgg': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '467',\n",
       "  'title': 'Adversarial Feature Learning'},\n",
       " 'BJuysoFeg': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '736',\n",
       "  'title': 'Revisiting Batch Normalization For Practical Domain Adaptation'},\n",
       " 'BJwFrvOeg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '770',\n",
       "  'title': 'A Neural Knowledge Language Model'},\n",
       " 'BJxhLAuxg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '765',\n",
       "  'title': 'A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games'},\n",
       " 'Bk0FWVcgx': {'RECOMMENDATION': [7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '451',\n",
       "  'title': 'Topology and Geometry of Half-Rectified Network Optimization'},\n",
       " 'Bk0MRI5lg': {'RECOMMENDATION': [5, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '651',\n",
       "  'title': 'Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units'},\n",
       " 'Bk2TqVcxe': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '530',\n",
       "  'title': 'Discovering objects and their relations from entangled scene representations'},\n",
       " 'Bk3F5Y9lx': {'RECOMMENDATION': [4, 8, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '592',\n",
       "  'title': 'Epitomic Variational Autoencoders'},\n",
       " 'Bk8BvDqex': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [8, 8, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 4],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '390',\n",
       "  'title': 'Metacontrol for Adaptive Imagination-Based Optimization'},\n",
       " 'Bk8N0RLxx': {'RECOMMENDATION': [4, 5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '779',\n",
       "  'title': 'Vocabulary Selection Strategies for Neural Machine Translation'},\n",
       " 'Bk8aOm9xl': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '533',\n",
       "  'title': 'Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning'},\n",
       " 'BkCPyXm1l': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '792',\n",
       "  'title': 'SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks'},\n",
       " 'BkGakb9lx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '537',\n",
       "  'title': 'RenderGAN: Generating Realistic Labeled Data'},\n",
       " 'BkIqod5ll': {'RECOMMENDATION': [6, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '609',\n",
       "  'title': 'Convolutional Neural Networks Generalization Utilizing the Data Graph Structure'},\n",
       " 'BkLhzHtlg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '480',\n",
       "  'title': 'Learning Recurrent Representations for Hierarchical Behavior Modeling'},\n",
       " 'BkSmc8qll': {'RECOMMENDATION': [4, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '662',\n",
       "  'title': 'Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes'},\n",
       " 'BkSqjHqxg': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '677',\n",
       "  'title': 'Skip-graph: Learning graph embeddings with an encoder-decoder model'},\n",
       " 'BkUDvt5gg': {'RECOMMENDATION': [4, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '598',\n",
       "  'title': 'Wav2Letter: an End-to-End ConvNet-based Speech Recognition System'},\n",
       " 'BkV4VS9ll': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '687',\n",
       "  'title': 'The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning'},\n",
       " 'BkVsEMYel': {'RECOMMENDATION': [6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '484',\n",
       "  'title': 'Inductive Bias of Deep Convolutional Networks through Pooling Geometry'},\n",
       " 'BkXMikqxx': {'RECOMMENDATION': [5, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '723',\n",
       "  'title': 'Cortical-Inspired Open-Bigram Representation for Handwritten Word Recognition'},\n",
       " 'Bk_zTU5eg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '653',\n",
       "  'title': 'Inefficiency of stochastic gradient descent with larger mini-batches (and more learners)'},\n",
       " 'Bkab5dqxe': {'CLARITY': [3, 4],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [9, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '371',\n",
       "  'title': 'A Compositional Object-Based Approach to Learning Physical Dynamics'},\n",
       " 'BkbY4psgg': {'CLARITY': [3],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [8, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '304',\n",
       "  'title': 'Making Neural Programming Architectures Generalize via Recursion'},\n",
       " 'Bkbc-Vqeg': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '705',\n",
       "  'title': 'Learning Word-Like Units from Joint Audio-Visual Analylsis'},\n",
       " 'Bkepl7cee': {'RECOMMENDATION': [7, 6, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '713',\n",
       "  'title': 'Parametric Exponential Linear Unit for Deep Convolutional Neural Networks'},\n",
       " 'BkfiXiUlg': {'RECOMMENDATION': [3, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '782',\n",
       "  'title': 'Learning Efficient Algorithms with Hierarchical Attentive Memory'},\n",
       " 'Bkfwyw5xg': {'RECOMMENDATION': [6, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '649',\n",
       "  'title': 'Investigating Different Context Types and Representations for Learning Word Embeddings'},\n",
       " 'BkjLkSqxg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '694',\n",
       "  'title': 'LipNet: End-to-End Sentence-level Lipreading'},\n",
       " 'Bkp_y7qxe': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '714',\n",
       "  'title': 'Unsupervised Deep Learning of State Representation Using Robotic Priors '},\n",
       " 'Bkul3t9ee': {'RECOMMENDATION': [6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '504',\n",
       "  'title': 'Unsupervised Perceptual Rewards for Imitation Learning'},\n",
       " 'By1snw5gl': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '615',\n",
       "  'title': 'L-SR1: A Second Order Optimization Method for Deep Learning'},\n",
       " 'By5e2L9gl': {'CLARITY': [3],\n",
       "  'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '412',\n",
       "  'title': 'Trusting SVM for Piecewise Linear CNNs'},\n",
       " 'ByC7ww9le': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '632',\n",
       "  'title': 'Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering'},\n",
       " 'ByEPMj5el': {'RECOMMENDATION': [5, 4, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '583',\n",
       "  'title': 'Out-of-class novelty generation: an experimental foundation'},\n",
       " 'ByG4hz5le': {'RECOMMENDATION': [7, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '535',\n",
       "  'title': 'Adaptive Feature Abstraction for Translating Video to Language'},\n",
       " 'ByG8A7cee': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '707',\n",
       "  'title': 'Reference-Aware Language Models'},\n",
       " 'ByIAPUcee': {'CLARITY': [3, 2],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [3, 5],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '420',\n",
       "  'title': 'Frustratingly Short Attention Spans in Neural Language Modeling'},\n",
       " 'ByOK0rwlx': {'RECOMMENDATION': [6, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '778',\n",
       "  'title': 'Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network'},\n",
       " 'ByOvsIqeg': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '415',\n",
       "  'title': 'Regularizing CNNs with Locally Constrained Decorrelations'},\n",
       " 'ByQPVFull': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '768',\n",
       "  'title': 'Training Group Orthogonal Neural Networks with Privileged Information'},\n",
       " 'ByToKu9ll': {'RECOMMENDATION': [5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '610',\n",
       "  'title': 'Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models'},\n",
       " 'ByW2Avqgg': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '613',\n",
       "  'title': 'Neural Causal Regularization under the Independence of Mechanisms Assumption'},\n",
       " 'ByZvfijeg': {'RECOMMENDATION': [4, 3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '564',\n",
       "  'title': 'Higher Order Recurrent Neural Networks'},\n",
       " 'BybtVK9lg': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [3, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 3],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '366',\n",
       "  'title': 'Autoencoding Variational Inference For Topic Models'},\n",
       " 'BycCx8qex': {'RECOMMENDATION': [7, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '671',\n",
       "  'title': 'DRAGNN: A Transition-Based Framework for Dynamically Connected Neural Networks'},\n",
       " 'BydARw9ex': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '376',\n",
       "  'title': 'Capacity and Trainability in Recurrent Neural Networks'},\n",
       " 'BydrOIcle': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [2],\n",
       "  'IMPACT': [4],\n",
       "  'RECOMMENDATION': [7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '418',\n",
       "  'title': 'Unrolled Generative Adversarial Networks'},\n",
       " 'Bygq-H9eg': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '690',\n",
       "  'title': 'An Analysis of Deep Neural Network Models for Practical Applications'},\n",
       " 'Byiy-Pqlx': {'APPROPRIATENESS': [2],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 8, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '403',\n",
       "  'title': 'Lie-Access Neural Turing Machines'},\n",
       " 'Byj72udxe': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '490',\n",
       "  'title': 'Pointer Sentinel Mixture Models'},\n",
       " 'Byk-VI9eg': {'IMPACT': [1],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '423',\n",
       "  'title': 'Generative Multi-Adversarial Networks'},\n",
       " 'BylSPv9gx': {'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [2, 3],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '391',\n",
       "  'title': 'Exploring Sparsity in Recurrent Neural Networks'},\n",
       " 'ByldLrqlx': {'RECOMMENDATION': [6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '439',\n",
       "  'title': 'DeepCoder: Learning to Write Programs'},\n",
       " 'BymIbLKgl': {'RECOMMENDATION': [8, 5, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '478',\n",
       "  'title': 'Learning Invariant Representations Of Planar Curves '},\n",
       " 'BysZhEqee': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '700',\n",
       "  'title': 'Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications'},\n",
       " 'BysvGP5ee': {'CLARITY': [5, 5, 4],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [1, 3],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '397',\n",
       "  'title': 'Variational Lossy Autoencoder'},\n",
       " 'ByvJuTigl': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '551',\n",
       "  'title': 'End-to-End Learnable Histogram Filters'},\n",
       " 'Byx5BTilg': {'RECOMMENDATION': [3, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '555',\n",
       "  'title': 'Exploring the Application of Deep Learning for Supervised Learning Problems'},\n",
       " 'ByxpMd9lx': {'MEANINGFUL_COMPARISON': [4],\n",
       "  'RECOMMENDATION': [8, 7, 5],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '373',\n",
       "  'title': 'Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks'},\n",
       " 'H12GRgcxg': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '463',\n",
       "  'title': 'Training deep neural-networks using a noise adaptation layer'},\n",
       " 'H13F3Pqll': {'RECOMMENDATION': [5, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '616',\n",
       "  'title': 'Inverse Problems in Computer Vision using  Adversarial  Imagination Priors'},\n",
       " 'H178hw9ex': {'RECOMMENDATION': [5, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '618',\n",
       "  'title': 'Dynamic Steerable Frame Networks'},\n",
       " 'H1Fk2Iqex': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '521',\n",
       "  'title': 'Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech'},\n",
       " 'H1GEvHcee': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '682',\n",
       "  'title': 'Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM'},\n",
       " 'H1Go7Koex': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '568',\n",
       "  'title': 'Character-aware Attention Residual Network for Sentence Representation'},\n",
       " 'H1Gq5Q9el': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '709',\n",
       "  'title': 'Unsupervised Pretraining for Sequence to Sequence Learning'},\n",
       " 'H1Heentlx': {'RECOMMENDATION': [5, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '734',\n",
       "  'title': 'Deep Variational Canonical Correlation Analysis'},\n",
       " 'H1MjAnqxg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '580',\n",
       "  'title': 'Intelligible Language Modeling with Input Switched Affine Networks'},\n",
       " 'H1W1UN9gg': {'RECOMMENDATION': [8, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '448',\n",
       "  'title': 'Deep Information Propagation'},\n",
       " 'H1_EDpogx': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '553',\n",
       "  'title': 'Near-Data Processing for Machine Learning'},\n",
       " 'H1_QSDqxl': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '637',\n",
       "  'title': 'Rule Mining in Feature Space'},\n",
       " 'H1acq85gx': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [9, 6, 6],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '416',\n",
       "  'title': 'Maximum Entropy Flow Networks'},\n",
       " 'H1fl8S9ee': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '440',\n",
       "  'title': 'Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks'},\n",
       " 'H1hoFU9xe': {'RECOMMENDATION': [5, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '664',\n",
       "  'title': 'Generative Adversarial Networks for Image Steganography'},\n",
       " 'H1kjdOYlx': {'RECOMMENDATION': [3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '542',\n",
       "  'title': 'Modular Multitask Reinforcement Learning with Policy Sketches'},\n",
       " 'H1oRQDqlg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '518',\n",
       "  'title': 'Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning'},\n",
       " 'H1oyRlYgg': {'CLARITY': [4],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 10, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '315',\n",
       "  'title': 'On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima'},\n",
       " 'H1wgawqxl': {'RECOMMENDATION': [6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '512',\n",
       "  'title': 'Nonparametrically Learning Activation Functions in Deep Neural Nets'},\n",
       " 'H1zJ-v5xl': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '404',\n",
       "  'title': 'Quasi-Recurrent Neural Networks'},\n",
       " 'HJ0NvFzxl': {'CLARITY': [5],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'RECOMMENDATION': [9, 9, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '318',\n",
       "  'title': 'Learning Graphical State Transitions'},\n",
       " 'HJ1kmv9xx': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5, 4],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '396',\n",
       "  'title': 'LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation'},\n",
       " 'HJ5PIaseg': {'RECOMMENDATION': [4, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '502',\n",
       "  'title': 'Towards an automatic Turing test: Learning to evaluate dialogue responses'},\n",
       " 'HJ6idTdgg': {'RECOMMENDATION': [3, 2, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '766',\n",
       "  'title': 'Pedestrian Detection Based On Fast R-CNN and Batch Normalization '},\n",
       " 'HJ7O61Yxe': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '763',\n",
       "  'title': 'Modelling Relational Time Series using Gaussian Embeddings'},\n",
       " 'HJ9rLLcxg': {'RECOMMENDATION': [7, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '524',\n",
       "  'title': 'Dataset Augmentation in Feature Space'},\n",
       " 'HJDBUF5le': {'CLARITY': [3],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 8, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '358',\n",
       "  'title': 'Towards a Neural Statistician'},\n",
       " 'HJF3iD9xe': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '514',\n",
       "  'title': 'Deep Learning with Sets and Point Clouds'},\n",
       " 'HJGODLqgx': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '421',\n",
       "  'title': 'Recurrent Hidden Semi-Markov Model'},\n",
       " 'HJGwcKclx': {'CLARITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '345',\n",
       "  'title': 'Soft Weight-Sharing for Neural Network Compression'},\n",
       " 'HJIY0E9ge': {'RECOMMENDATION': [3, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '695',\n",
       "  'title': 'A Simple yet Effective Method to Prune Dense Layers of Neural Networks'},\n",
       " 'HJOZBvcel': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '517',\n",
       "  'title': 'Learning to Discover Sparse Graphical Models'},\n",
       " 'HJPmdP9le': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '630',\n",
       "  'title': 'Efficient Summarization with Read-Again and Copy Mechanism'},\n",
       " 'HJSCGD9ex': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '640',\n",
       "  'title': 'Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context'},\n",
       " 'HJTXaw9gx': {'RECOMMENDATION': [5, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '511',\n",
       "  'title': 'Recursive Regression with Neural Networks: Approximating the HJI PDE Solution'},\n",
       " 'HJTzHtqee': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '363',\n",
       "  'title': 'A Compare-Aggregate Model for Matching Text Sequences'},\n",
       " 'HJV1zP5xg': {'RECOMMENDATION': [4, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '644',\n",
       "  'title': 'Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models'},\n",
       " 'HJWzXsKxx': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '738',\n",
       "  'title': 'Training Long Short-Term Memory With Sparsified Stochastic Gradient Descent'},\n",
       " 'HJcLcw9xg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '626',\n",
       "  'title': 'The Preimage of Rectifier Network Activities'},\n",
       " 'HJeqWztlg': {'RECOMMENDATION': [5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '760',\n",
       "  'title': 'Hierarchical compositional feature learning'},\n",
       " 'HJgXCV9xx': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '445',\n",
       "  'title': 'Dialogue Learning With Human-in-the-Loop'},\n",
       " 'HJhcg6Fxg': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '731',\n",
       "  'title': 'Binary Paragraph Vectors'},\n",
       " 'HJlgm-B9lx': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '692',\n",
       "  'title': 'Learning to Understand: Incorporating Local Contexts with Global Attention for Sentiment Classification'},\n",
       " 'HJrDIpiee': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '554',\n",
       "  'title': 'Investigating Recurrence and Eligibility Traces in Deep Q-Networks'},\n",
       " 'HJtN5K9gx': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '593',\n",
       "  'title': 'Learning Disentangled Representations in Deep Generative Models'},\n",
       " 'HJy_5Mcll': {'RECOMMENDATION': [4, 5, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '716',\n",
       "  'title': 'ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation'},\n",
       " 'Hk-mgcsgx': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '567',\n",
       "  'title': 'An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views'},\n",
       " 'Hk1iOLcle': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '665',\n",
       "  'title': 'MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset'},\n",
       " 'Hk1l9Xqxe': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '710',\n",
       "  'title': 'BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL'},\n",
       " 'Hk3mPK5gg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [6, 7, 4],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '355',\n",
       "  'title': 'Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning'},\n",
       " 'Hk4_qw5xe': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [4, 3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '308',\n",
       "  'title': 'Towards Principled Methods for Training Generative Adversarial Networks'},\n",
       " 'Hk4kQHceg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '527',\n",
       "  'title': 'Multiplicative LSTM for sequence modelling'},\n",
       " 'Hk6a8N5xe': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '702',\n",
       "  'title': 'Classify or Select: Neural Architectures for Extractive Document Summarization'},\n",
       " 'Hk85q85ee': {'RECOMMENDATION': [4, 8, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '522',\n",
       "  'title': 'Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity'},\n",
       " 'Hk8N3Sclg': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [5, 3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '310',\n",
       "  'title': 'Multi-Agent Cooperation and the Emergence of (Natural) Language'},\n",
       " 'Hk8TGSKlg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '479',\n",
       "  'title': 'Reasoning with Memory Augmented Neural Networks for Language Comprehension'},\n",
       " 'Hk8rlUqge': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '672',\n",
       "  'title': 'Joint Multimodal Learning with Deep Generative Models'},\n",
       " 'HkCjNI5ex': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '668',\n",
       "  'title': 'Regularizing Neural Networks by Penalizing Confident Output Distributions'},\n",
       " 'HkE0Nvqlg': {'CLARITY': [3],\n",
       "  'IMPACT': [1, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 2],\n",
       "  'SUBSTANCE': [1],\n",
       "  'dec': True,\n",
       "  'pr_id': '393',\n",
       "  'title': 'Structured Attention Networks'},\n",
       " 'HkEI22jeg': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 4],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '328',\n",
       "  'title': 'Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses'},\n",
       " 'HkIQH7qel': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '711',\n",
       "  'title': 'Learning Recurrent Span Representations for Extractive Question Answering'},\n",
       " 'HkJq1Ocxl': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '509',\n",
       "  'title': 'Programming With a Differentiable Forth Interpreter'},\n",
       " 'HkNEuToge': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '549',\n",
       "  'title': 'Energy-Based Spherical Sparse Coding'},\n",
       " 'HkNRsU5ge': {'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [1],\n",
       "  'RECOMMENDATION': [8, 6, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '413',\n",
       "  'title': 'Sigma Delta Quantized Networks'},\n",
       " 'HkSOlP9lg': {'RECOMMENDATION': [4, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '647',\n",
       "  'title': 'Recurrent Inference Machines for Solving Inverse Problems'},\n",
       " 'HkYhZDqxg': {'CLARITY': [2, 5],\n",
       "  'IMPACT': [1],\n",
       "  'MEANINGFUL_COMPARISON': [1, 2],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '400',\n",
       "  'title': 'Tree-structured decoding with doubly-recurrent neural networks'},\n",
       " 'HkcdHtqlx': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '602',\n",
       "  'title': 'Gated-Attention Readers for Text Comprehension'},\n",
       " 'Hkg4TI9xl': {'IMPACT': [2],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '410',\n",
       "  'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks'},\n",
       " 'Hkg8bDqee': {'CLARITY': [5],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 9, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '401',\n",
       "  'title': 'Introspection:Accelerating Neural Network Training By Learning Weight Evolution'},\n",
       " 'HkljfjFee': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '472',\n",
       "  'title': 'Support Regularized Sparse Coding and Its Fast Encoder'},\n",
       " 'HkpLeH9el': {'RECOMMENDATION': [6, 7, 4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '528',\n",
       "  'title': 'Neural Functional Programming'},\n",
       " 'HkpbnH9lx': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '433',\n",
       "  'title': 'Density estimation using Real NVP'},\n",
       " 'Hku9NK5lx': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [9, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '365',\n",
       "  'title': 'Training Compressed Fully-Connected Networks with a Density-Diversity Penalty'},\n",
       " 'HkuVu3ige': {'RECOMMENDATION': [7, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '560',\n",
       "  'title': 'On orthogonality and learning recurrent networks with long term dependencies'},\n",
       " 'HkvS3Mqxe': {'RECOMMENDATION': [5, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '715',\n",
       "  'title': 'Coarse Pruning of Convolutional Neural Networks with Random Masks'},\n",
       " 'HkwoSDPgg': {'APPROPRIATENESS': [5],\n",
       "  'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4, 5],\n",
       "  'ORIGINALITY': [5, 5, 5],\n",
       "  'RECOMMENDATION': [9, 9, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '316',\n",
       "  'title': 'Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data'},\n",
       " 'HkxAAvcxx': {'RECOMMENDATION': [3, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '612',\n",
       "  'title': 'Transformation-based Models of Video Sequences'},\n",
       " 'HkyYqU9lx': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '659',\n",
       "  'title': 'Sequence to Sequence Transduction with Hard Monotonic Attention'},\n",
       " 'HkzuKpLgg': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '780',\n",
       "  'title': 'Efficient Communications in Training Large Scale Neural Networks'},\n",
       " 'Hy-2G6ile': {'RECOMMENDATION': [6, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '503',\n",
       "  'title': 'Gated Multimodal Units for Information Fusion'},\n",
       " 'Hy-lMNqex': {'RECOMMENDATION': [6, 4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '703',\n",
       "  'title': 'Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability'},\n",
       " 'Hy0L4t5el': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '605',\n",
       "  'title': 'Tree-Structured Variational Autoencoder'},\n",
       " 'Hy3_KuYxg': {'RECOMMENDATION': [4, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '746',\n",
       "  'title': 'Divide and Conquer with Neural Networks'},\n",
       " 'Hy6b4Pqee': {'CLARITY': [1, 3],\n",
       "  'IMPACT': [3, 4],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [8, 5, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '395',\n",
       "  'title': 'Deep Probabilistic Programming'},\n",
       " 'HyAbMKwxe': {'RECOMMENDATION': [8, 4, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '493',\n",
       "  'title': 'Tighter bounds lead to improved classifiers'},\n",
       " 'HyAddcLge': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '783',\n",
       "  'title': 'Revisiting Distributed Synchronous SGD'},\n",
       " 'HyCRyS9gx': {'RECOMMENDATION': [5, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '693',\n",
       "  'title': 'Fast Adaptation in Generative Models with Generative Matching Networks'},\n",
       " 'HyET6tYex': {'RECOMMENDATION': [5, 5, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '743',\n",
       "  'title': 'Universality in halting time'},\n",
       " 'HyGTuv9eg': {'CLARITY': [3],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4, 5],\n",
       "  'RECOMMENDATION': [5, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5],\n",
       "  'SUBSTANCE': [3, 2, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '387',\n",
       "  'title': 'Incorporating long-range consistency in CNN-based texture generation'},\n",
       " 'HyM25Mqel': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '460',\n",
       "  'title': 'Sample Efficient Actor-Critic with  Experience Replay'},\n",
       " 'HyNxRZ9xg': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '720',\n",
       "  'title': 'Cat2Vec: Learning Distributed Representation of Multi-field Categorical Data'},\n",
       " 'HyQJ-mclg': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '457',\n",
       "  'title': 'Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights'},\n",
       " 'HyTqHL5xg': {'IMPACT': [2, 3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [6, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [1, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '422',\n",
       "  'title': 'Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data'},\n",
       " 'HyWDCXjgx': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '574',\n",
       "  'title': 'Multi-label learning with the RNNs for Fashion Search'},\n",
       " 'HyWG0H5ge': {'RECOMMENDATION': [7, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '526',\n",
       "  'title': 'Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks'},\n",
       " 'HyWWpw5ex': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '614',\n",
       "  'title': 'Recurrent Coevolutionary Feature Embedding Processes for Recommendation'},\n",
       " 'HyY4Owjll': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '571',\n",
       "  'title': 'Boosted Generative Models'},\n",
       " 'Hyanrrqlg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '686',\n",
       "  'title': 'HFH: Homologically Functional Hashing for Compressing Deep Neural Networks'},\n",
       " 'HycUbvcge': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '645',\n",
       "  'title': 'Deep Generalized Canonical Correlation Analysis'},\n",
       " 'HyecJGP5ge': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '643',\n",
       "  'title': 'NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD'},\n",
       " 'HyoST_9xl': {'CLARITY': [4, 4],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [5, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '370',\n",
       "  'title': 'DSD: Dense-Sparse-Dense Training for Deep Neural Networks'},\n",
       " 'Hyq4yhile': {'CLARITY': [5],\n",
       "  'IMPACT': [4, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '331',\n",
       "  'title': 'Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning'},\n",
       " 'HysBZSqlx': {'RECOMMENDATION': [5, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '691',\n",
       "  'title': 'Playing SNES in the Retro Learning Environment'},\n",
       " 'Hyvw0L9el': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '520',\n",
       "  'title': 'Generating Interpretable Images with Controllable Structure'},\n",
       " 'HyxQzBceg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '442',\n",
       "  'title': 'Deep Variational Information Bottleneck'},\n",
       " 'S11KBYclx': {'APPROPRIATENESS': [5],\n",
       "  'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [3, 2, 3],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '361',\n",
       "  'title': 'Learning Curve Prediction with Bayesian Neural Networks'},\n",
       " 'S13wCE9xx': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '697',\n",
       "  'title': 'Riemannian Optimization for Skip-Gram Negative Sampling'},\n",
       " 'S19eAF9ee': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '589',\n",
       "  'title': 'Structured Sequence Modeling with Graph Convolutional Recurrent Networks'},\n",
       " 'S1Bb3D5gg': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [8, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '307',\n",
       "  'title': 'Learning End-to-End Goal-Oriented Dialog'},\n",
       " 'S1Bm3T_lg': {'RECOMMENDATION': [6, 5, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '545',\n",
       "  'title': 'Compositional Kernel Machines'},\n",
       " 'S1HEBe_Jl': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '790',\n",
       "  'title': 'Learning to Protect Communications with Adversarial Neural Cryptography'},\n",
       " 'S1HcOI5le': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '666',\n",
       "  'title': 'OMG: Orthogonal Method of Grouping With Application of K-Shot Learning'},\n",
       " 'S1J0E-71l': {'RECOMMENDATION': [3, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '793',\n",
       "  'title': 'Surprisal-Driven Feedback in Recurrent Networks'},\n",
       " 'S1JG13oee': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '563',\n",
       "  'title': 'b-GAN: Unified Framework of Generative Adversarial Networks'},\n",
       " 'S1LVSrcge': {'RECOMMENDATION': [7, 7, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '441',\n",
       "  'title': 'Variable Computation in Recurrent Neural Networks'},\n",
       " 'S1QefL5ge': {'RECOMMENDATION': [6, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '525',\n",
       "  'title': 'Online Structure Learning for Sum-Product Networks with Gaussian Leaves'},\n",
       " 'S1RP6GLle': {'CLARITY': [5, 4],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '317',\n",
       "  'title': 'Amortised MAP Inference for Image Super-resolution'},\n",
       " 'S1VaB4cex': {'RECOMMENDATION': [6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '449',\n",
       "  'title': 'FractalNet: Ultra-Deep Neural Networks without Residuals'},\n",
       " 'S1X7nhsxl': {'CLARITY': [5, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '329',\n",
       "  'title': 'Improving Generative Adversarial Networks with Denoising Feature Matching'},\n",
       " 'S1Y0td9ee': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '508',\n",
       "  'title': 'Shift Aggregate Extract Networks'},\n",
       " 'S1_pAu9xl': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [7, 7, 3, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '369',\n",
       "  'title': 'Trained Ternary Quantization'},\n",
       " 'S1c2cvqee': {'APPROPRIATENESS': [3],\n",
       "  'CLARITY': [5, 4],\n",
       "  'IMPACT': [4, 2],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3, 5, 3],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '383',\n",
       "  'title': 'Designing Neural Network Architectures using Reinforcement Learning'},\n",
       " 'S1dIzvclg': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [5, 4, 3],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '398',\n",
       "  'title': 'A recurrent neural network without chaos'},\n",
       " 'S1di0sfgl': {'RECOMMENDATION': [8, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '496',\n",
       "  'title': 'Hierarchical Multiscale Recurrent Neural Networks'},\n",
       " 'S1j4RqYxg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '739',\n",
       "  'title': 'Efficient Calculation of Polynomial Features on Sparse Matrices'},\n",
       " 'S1jmAotxg': {'RECOMMENDATION': [8, 4, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '470',\n",
       "  'title': 'Stick-Breaking Variational Autoencoders'},\n",
       " 'S1oWlN9ll': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '453',\n",
       "  'title': 'Loss-aware Binarization of Deep Networks'},\n",
       " 'S1vyujVye': {'RECOMMENDATION': [7, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '791',\n",
       "  'title': 'Deep unsupervised learning through spatial contrasting'},\n",
       " 'S1xh5sYgx': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '737',\n",
       "  'title': 'SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size'},\n",
       " 'SJ-uGHcee': {'RECOMMENDATION': [5, 3, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '688',\n",
       "  'title': 'Efficient iterative policy optimization'},\n",
       " 'SJ25-B5eg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '443',\n",
       "  'title': 'The Neural Noisy Channel'},\n",
       " 'SJ6yPD5xg': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '309',\n",
       "  'title': 'Reinforcement Learning with Unsupervised Auxiliary Tasks'},\n",
       " 'SJAr0QFxe': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '755',\n",
       "  'title': 'Demystifying ResNet'},\n",
       " 'SJBr9Mcxl': {'RECOMMENDATION': [7, 3, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '717',\n",
       "  'title': 'Understanding trained CNNs by indexing neuron selectivity'},\n",
       " 'SJCscQcge': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '708',\n",
       "  'title': 'Simple Black-Box Adversarial Perturbations for Deep Networks'},\n",
       " 'SJGCiw5gl': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [9, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '381',\n",
       "  'title': 'Pruning Convolutional Neural Networks for Resource Efficient Inference'},\n",
       " 'SJIMPr9eg': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '683',\n",
       "  'title': 'Boosted Residual Networks'},\n",
       " 'SJJKxrsgl': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [6, 5, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '334',\n",
       "  'title': 'Emergence of foveal image sampling from learning to attend in visual scenes'},\n",
       " 'SJJN38cge': {'RECOMMENDATION': [3, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '655',\n",
       "  'title': 'Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment'},\n",
       " 'SJMGPrcle': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '438',\n",
       "  'title': 'Learning to Navigate in Complex Environments'},\n",
       " 'SJNDWNOlg': {'RECOMMENDATION': [3, 3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '772',\n",
       "  'title': 'What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?'},\n",
       " 'SJQNqLFgl': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '749',\n",
       "  'title': 'Deep Convolutional Neural Network Design Patterns'},\n",
       " 'SJRpRfKxx': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '483',\n",
       "  'title': 'Recurrent Mixture Density Network for Spatiotemporal Visual Attention'},\n",
       " 'SJTQLdqlg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [8, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '372',\n",
       "  'title': 'Learning to Remember Rare Events'},\n",
       " 'SJU4ayYgl': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '486',\n",
       "  'title': 'Semi-Supervised Classification with Graph Convolutional Networks'},\n",
       " 'SJZAb5cel': {'RECOMMENDATION': [5, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '584',\n",
       "  'title': 'A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks'},\n",
       " 'SJ_QCYqle': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '588',\n",
       "  'title': 'Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets'},\n",
       " 'SJc1hL5ee': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '657',\n",
       "  'title': 'FastText.zip: Compressing text classification models'},\n",
       " 'SJg498clg': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '661',\n",
       "  'title': 'Neural Graph Machines: Learning Neural Networks Using Graphs'},\n",
       " 'SJiFvr9el': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '681',\n",
       "  'title': 'Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants'},\n",
       " 'SJk01vogl': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '572',\n",
       "  'title': 'Adversarial examples for generative models'},\n",
       " 'SJkXfE5xx': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '450',\n",
       "  'title': 'Revisiting Classifier Two-Sample Tests'},\n",
       " 'SJttqw5ge': {'RECOMMENDATION': [4, 5, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '625',\n",
       "  'title': 'Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization'},\n",
       " 'SJvYgH9xe': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '444',\n",
       "  'title': 'Automatic Rule Extraction from Long Short Term Memory Networks'},\n",
       " 'SJzCSf9xg': {'RECOMMENDATION': [7, 5, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '462',\n",
       "  'title': 'On Detecting Adversarial Perturbations'},\n",
       " 'Sk-oDY9ge': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '351',\n",
       "  'title': 'Diet Networks: Thin Parameters for Fat Genomics'},\n",
       " 'Sk2Im59ex': {'CLARITY': [4],\n",
       "  'IMPACT': [4, 2],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '340',\n",
       "  'title': 'Unsupervised Cross-Domain Image Generation'},\n",
       " 'Sk2iistgg': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '735',\n",
       "  'title': 'Non-linear Dimensionality Regularizer for Solving Inverse Problems'},\n",
       " 'Sk36NgFeg': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '762',\n",
       "  'title': 'Filling in the details: Perceiving from low fidelity visual input'},\n",
       " 'Sk8J83oee': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '562',\n",
       "  'title': 'Generative Adversarial Parallelization'},\n",
       " 'Sk8csP5ex': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '622',\n",
       "  'title': 'The loss surface of residual networks: Ensembles and the role of batch normalization'},\n",
       " 'SkB-_mcel': {'RECOMMENDATION': [6, 9, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '456',\n",
       "  'title': 'Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning'},\n",
       " 'SkBsEQYll': {'RECOMMENDATION': [3, 3, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '756',\n",
       "  'title': 'Learning similarity preserving representations with neural similarity and context encoders'},\n",
       " 'SkCILwqex': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '634',\n",
       "  'title': 'Exploring LOTS in Deep Neural Networks'},\n",
       " 'SkJeEtclx': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '607',\n",
       "  'title': 'Memory-augmented Attention Modelling for Videos'},\n",
       " 'SkXIrV9le': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '531',\n",
       "  'title': 'Perception Updating Networks: On architectural constraints for interpretable video generative models'},\n",
       " 'SkYbF1slg': {'IMPACT': [4, 3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '335',\n",
       "  'title': 'An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax'},\n",
       " 'SkgSXUKxx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '750',\n",
       "  'title': 'An Analysis of Feature Regularization for Low-shot Learning'},\n",
       " 'SkgewU5ll': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '667',\n",
       "  'title': 'GRAM: Graph-based Attention Model for Healthcare Representation Learning'},\n",
       " 'SkhU2fcll': {'RECOMMENDATION': [5, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '459',\n",
       "  'title': 'Deep Multi-task Representation Learning: A Tensor Factorisation Approach'},\n",
       " 'Skn9Shcxe': {'IMPACT': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '338',\n",
       "  'title': 'Highway and Residual Networks learn Unrolled Iterative Estimation'},\n",
       " 'SkpSlKIel': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '495',\n",
       "  'title': 'Why Deep Neural Networks for Function Approximation?'},\n",
       " 'Skq89Scxx': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '435',\n",
       "  'title': 'SGDR: Stochastic Gradient Descent with Warm Restarts'},\n",
       " 'SkqMSCHxe': {'RECOMMENDATION': [2, 2, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '785',\n",
       "  'title': 'PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING'},\n",
       " 'Sks3zF9eg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '608',\n",
       "  'title': 'Taming the waves: sine as activation function in deep neural networks'},\n",
       " 'Sks9_ajex': {'CLARITY': [5, 5],\n",
       "  'MEANINGFUL_COMPARISON': [3, 5],\n",
       "  'ORIGINALITY': [2, 5, 2],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '319',\n",
       "  'title': 'Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer'},\n",
       " 'SkuqA_cgx': {'RECOMMENDATION': [5, 8, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '507',\n",
       "  'title': 'Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations'},\n",
       " 'Skvgqgqxe': {'RECOMMENDATION': [6, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '464',\n",
       "  'title': 'Learning to Compose Words into Sentences with Reinforcement Learning'},\n",
       " 'SkwSJ99ex': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '587',\n",
       "  'title': 'DeepRebirth: A General Approach for Accelerating Deep Neural Network Execution on Mobile Devices'},\n",
       " 'SkxKPDv5xl': {'APPROPRIATENESS': [4],\n",
       "  'CLARITY': [3],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [9, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '389',\n",
       "  'title': 'SampleRNN: An Unconditional End-to-End Neural Audio Generation Model'},\n",
       " 'SkyQWDcex': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '646',\n",
       "  'title': 'A Context-aware Attention Network for Interactive Question Answering'},\n",
       " 'Sy1rwtKxg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '745',\n",
       "  'title': 'Parallel Stochastic Gradient Descent with Sound Combiners'},\n",
       " 'Sy4tzwqxe': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '641',\n",
       "  'title': 'Two Methods for Wild Variational Inference'},\n",
       " 'Sy6iJDqlx': {'IMPACT': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '407',\n",
       "  'title': 'Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain'},\n",
       " 'Sy7m72Ogg': {'RECOMMENDATION': [3, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '767',\n",
       "  'title': 'An Actor-critic Algorithm for Learning Rate Learning'},\n",
       " 'SyCSsUDee': {'RECOMMENDATION': [3, 4, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '777',\n",
       "  'title': 'Semantic Noise Modeling for Better Representation Learning'},\n",
       " 'SyEiHNKxx': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '544',\n",
       "  'title': 'A Differentiable Physics Engine for Deep Learning in Robotics'},\n",
       " 'SyJNmVqgg': {'RECOMMENDATION': [6, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '532',\n",
       "  'title': 'Neural Data Filter for Bootstrapping Stochastic Gradient Descent'},\n",
       " 'SyK00v5xx': {'CLARITY': [5, 4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '375',\n",
       "  'title': 'A Simple but Tough-to-Beat Baseline for Sentence Embeddings'},\n",
       " 'SyOvg6jxx': {'RECOMMENDATION': [6, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '558',\n",
       "  'title': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'},\n",
       " 'SyQq185lg': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '430',\n",
       "  'title': 'Latent Sequence Decompositions'},\n",
       " 'SyVVJ85lg': {'RECOMMENDATION': [7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '431',\n",
       "  'title': 'Paleo: A Performance Model for Deep Neural Networks'},\n",
       " 'SyW2QSige': {'RECOMMENDATION': [4, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '573',\n",
       "  'title': 'Towards Information-Seeking Agents'},\n",
       " 'SyWvgP5el': {'CLARITY': [2],\n",
       "  'IMPACT': [1, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [4, 3, 3],\n",
       "  'RECOMMENDATION': [7, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3, 2, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '406',\n",
       "  'title': 'EPOpt: Learning Robust Neural Network Policies Using Model Ensembles'},\n",
       " 'SyZprb5xg': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '536',\n",
       "  'title': 'On Robust Concepts and Small Neural Nets'},\n",
       " 'Syfkm6cgx': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '578',\n",
       "  'title': 'Improving Invariance and Equivariance Properties of Convolutional Neural Networks'},\n",
       " 'SygGlIBcel': {'RECOMMENDATION': [3, 4, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '685',\n",
       "  'title': 'Opening the vocabulary of  neural language models with character-level word representations'},\n",
       " 'SygvTcYee': {'RECOMMENDATION': [6, 6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '740',\n",
       "  'title': 'ParMAC: distributed optimisation of nested functions, with application to binary autoencoders'},\n",
       " 'Syoiqwcxx': {'RECOMMENDATION': [5, 3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '624',\n",
       "  'title': 'Local minima in training of deep networks'},\n",
       " 'SypU81Ole': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '774',\n",
       "  'title': 'Sampling Generative Networks'},\n",
       " 'Sys6GJqxl': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '465',\n",
       "  'title': 'Delving into Transferable Adversarial Examples and Black-box Attacks'},\n",
       " 'Sywh5KYex': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '744',\n",
       "  'title': 'Learning Identity Mappings with Residual Gates'},\n",
       " 'SyxeqhP9ll': {'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4, 4],\n",
       "  'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '380',\n",
       "  'title': 'Calibrating Energy-based Generative Adversarial Networks'},\n",
       " 'r10FA8Kxg': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '476',\n",
       "  'title': 'Do Deep Convolutional Nets Really Need to be Deep and Convolutional?'},\n",
       " 'r17RD2oxe': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '561',\n",
       "  'title': 'Deep Neural Networks and the Tree of Life'},\n",
       " 'r1Aab85gg': {'IMPACT': [3, 3],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [3, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '426',\n",
       "  'title': 'Offline bilingual word vectors, orthogonal transformations and the inverted softmax'},\n",
       " 'r1BJLw9ex': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '636',\n",
       "  'title': 'Adjusting for Dropout Variance in Batch Normalization and Weight Initialization'},\n",
       " 'r1Bjj8qge': {'RECOMMENDATION': [6, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '658',\n",
       "  'title': 'Encoding and Decoding Representations with Sum- and Max-Product Networks'},\n",
       " 'r1Chut9xl': {'RECOMMENDATION': [5, 5, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '595',\n",
       "  'title': 'Inference and Introspection in Deep Generative Models of Sparse Data'},\n",
       " 'r1G4z8cge': {'CLARITY': [4, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '424',\n",
       "  'title': 'Mollifying Networks'},\n",
       " 'r1GKzP5xx': {'RECOMMENDATION': [4, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '519',\n",
       "  'title': 'Recurrent Normalization Propagation'},\n",
       " 'r1IRctqxg': {'RECOMMENDATION': [7, 3, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '591',\n",
       "  'title': 'Sample Importance in Training Deep Neural Networks'},\n",
       " 'r1LXit5ee': {'CLARITY': [5],\n",
       "  'IMPACT': [5, 3],\n",
       "  'MEANINGFUL_COMPARISON': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '344',\n",
       "  'title': 'Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement'},\n",
       " 'r1PRvK9el': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '596',\n",
       "  'title': 'Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory'},\n",
       " 'r1S083cgx': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '581',\n",
       "  'title': 'Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks'},\n",
       " 'r1Ue8Hcxg': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [9, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '312',\n",
       "  'title': 'Neural Architecture Search with Reinforcement Learning'},\n",
       " 'r1Usiwcex': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '621',\n",
       "  'title': 'Counterpoint by Convolution'},\n",
       " 'r1VGvBcxl': {'RECOMMENDATION': [7, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '437',\n",
       "  'title': 'Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU'},\n",
       " 'r1VdcHcxx': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '434',\n",
       "  'title': 'Recurrent Batch Normalization'},\n",
       " 'r1WUqIceg': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '660',\n",
       "  'title': 'Improving Stochastic Gradient Descent with Feedback'},\n",
       " 'r1X3g2_xl': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '488',\n",
       "  'title': 'Adversarial Training Methods for Semi-Supervised Text Classification'},\n",
       " 'r1YNw6sxg': {'APPROPRIATENESS': [3, 2],\n",
       "  'CLARITY': [5, 2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '320',\n",
       "  'title': 'Learning Visual Servoing with Deep Features and Fitted Q-Iteration'},\n",
       " 'r1aGWUqgg': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '670',\n",
       "  'title': 'Unsupervised Learning of State Representations for Multiple Tasks'},\n",
       " 'r1aPbsFle': {'RECOMMENDATION': [6, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '473',\n",
       "  'title': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'},\n",
       " 'r1fYuytex': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '487',\n",
       "  'title': 'Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks'},\n",
       " 'r1kGbydxg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '775',\n",
       "  'title': 'Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space Matter?'},\n",
       " 'r1kQkVFgl': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '754',\n",
       "  'title': 'Learning Python Code Suggestion with a Sparse Pointer Network'},\n",
       " 'r1nTpv9eg': {'IMPACT': [4],\n",
       "  'RECOMMENDATION': [7, 6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '377',\n",
       "  'title': 'Learning to Perform Physics Experiments via Deep Reinforcement Learning'},\n",
       " 'r1osyr_xg': {'RECOMMENDATION': [6, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '771',\n",
       "  'title': 'Fuzzy paraphrases in learning word representations with a lexicon'},\n",
       " 'r1rz6U5lg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '411',\n",
       "  'title': 'Learning to superoptimize programs'},\n",
       " 'r1tHvHKge': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '751',\n",
       "  'title': \"Combating Deep Reinforcement Learning's Sisyphean Curse with Intrinsic Fear\"},\n",
       " 'r1te3Fqel': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '590',\n",
       "  'title': 'End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension'},\n",
       " 'r1w7Jdqxl': {'RECOMMENDATION': [4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '611',\n",
       "  'title': 'Collaborative Deep Embedding via Dual Networks'},\n",
       " 'r1xUYDYgg': {'RECOMMENDATION': [7, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '543',\n",
       "  'title': 'Development of JavaScript-based deep learning platform and application to distributed training'},\n",
       " 'r1y1aawlg': {'RECOMMENDATION': [7, 4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '776',\n",
       "  'title': 'Iterative Refinement for Machine Translation'},\n",
       " 'r1yjkAtxe': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '728',\n",
       "  'title': 'Spatio-Temporal Abstractions in Reinforcement Learning Through Neural Encoding'},\n",
       " 'rJ0-tY5xe': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '349',\n",
       "  'title': 'Learning to Query, Reason, and Answer Questions On Ambiguous Texts'},\n",
       " 'rJ0JwFcex': {'APPROPRIATENESS': [1],\n",
       "  'CLARITY': [4],\n",
       "  'IMPACT': [4, 2, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 2],\n",
       "  'ORIGINALITY': [4, 4, 2],\n",
       "  'RECOMMENDATION': [7, 8, 5],\n",
       "  'SUBSTANCE': [2, 1],\n",
       "  'dec': True,\n",
       "  'pr_id': '356',\n",
       "  'title': 'Neuro-Symbolic Program Synthesis'},\n",
       " 'rJ6DhP5xe': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '513',\n",
       "  'title': 'Generalizable Features From Unsupervised Learning'},\n",
       " 'rJ8uNptgl': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '468',\n",
       "  'title': 'Towards the Limit of Network Quantization'},\n",
       " 'rJEgeXFex': {'RECOMMENDATION': [8, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '482',\n",
       "  'title': 'Predicting Medications from Diagnostic Codes with Recurrent Neural Networks'},\n",
       " 'rJJ3YU5ge': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '663',\n",
       "  'title': 'Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce'},\n",
       " 'rJJRDvcex': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '631',\n",
       "  'title': 'Layer Recurrent Neural Networks'},\n",
       " 'rJLS7qKel': {'CLARITY': [4, 5],\n",
       "  'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [5, 4, 4],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 4],\n",
       "  'SUBSTANCE': [3, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '314',\n",
       "  'title': 'Learning to Act by Predicting the Future'},\n",
       " 'rJM69B5xx': {'RECOMMENDATION': [4, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '678',\n",
       "  'title': 'Finding a Jack-of-All-Trades: An Examination of Semi-supervised Learning in Reading Comprehension'},\n",
       " 'rJPcZ3txx': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '469',\n",
       "  'title': 'Faster CNNs with Direct Sparse Convolutions and Guided Pruning'},\n",
       " 'rJQKYt5ll': {'CLARITY': [3, 3],\n",
       "  'IMPACT': [5],\n",
       "  'MEANINGFUL_COMPARISON': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 8],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '348',\n",
       "  'title': 'Steerable CNNs'},\n",
       " 'rJY0-Kcll': {'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [5, 4, 5],\n",
       "  'RECOMMENDATION': [6, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '306',\n",
       "  'title': 'Optimization as a Model for Few-Shot Learning'},\n",
       " 'rJY3vK9eg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '597',\n",
       "  'title': 'Neural Combinatorial Optimization with Reinforcement Learning'},\n",
       " 'rJbPBt9lg': {'RECOMMENDATION': [5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '603',\n",
       "  'title': 'Neural Code Completion'},\n",
       " 'rJbbOLcex': {'CLARITY': [3, 3],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 6, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '419',\n",
       "  'title': 'TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency'},\n",
       " 'rJe-Pr9le': {'RECOMMENDATION': [2, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '684',\n",
       "  'title': 'Multi-task learning with deep model based reinforcement learning'},\n",
       " 'rJeKjwvclx': {'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '388',\n",
       "  'title': 'Dynamic Coattention Networks For Question Answering'},\n",
       " 'rJfMusFll': {'RECOMMENDATION': [8, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '471',\n",
       "  'title': 'Batch Policy Gradient  Methods for  Improving Neural Conversation Models'},\n",
       " 'rJg_1L5gg': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '675',\n",
       "  'title': 'Incremental Sequence Learning'},\n",
       " 'rJiNwv9gg': {'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [5, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '392',\n",
       "  'title': 'Lossy Image Compression with Compressive Autoencoders'},\n",
       " 'rJo9n9Feg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '741',\n",
       "  'title': 'Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe'},\n",
       " 'rJqBEPcxe': {'CLARITY': [5, 2],\n",
       "  'IMPACT': [2, 2, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 1],\n",
       "  'ORIGINALITY': [4, 1, 2],\n",
       "  'RECOMMENDATION': [7, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [2, 2, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '394',\n",
       "  'title': 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations'},\n",
       " 'rJqFGTslg': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '324',\n",
       "  'title': 'Pruning Filters for Efficient ConvNets'},\n",
       " 'rJq_YBqxx': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '680',\n",
       "  'title': 'Deep Character-Level Neural Machine Translation By Learning Morphology'},\n",
       " 'rJsiFTYex': {'RECOMMENDATION': [5, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '730',\n",
       "  'title': 'A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs'},\n",
       " 'rJxDkvqee': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [6, 5, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '408',\n",
       "  'title': 'Multi-view Recurrent Neural Acoustic Word Embeddings'},\n",
       " 'rJxdQ3jeg': {'CLARITY': [5, 3],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [8, 8, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '305',\n",
       "  'title': 'End-to-end Optimized Image Compression'},\n",
       " 'rJzaDdYxx': {'RECOMMENDATION': [5, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '747',\n",
       "  'title': 'Gradients of Counterfactuals'},\n",
       " 'rk9eAFcxg': {'APPROPRIATENESS': [3, 1],\n",
       "  'CLARITY': [3],\n",
       "  'IMPACT': [4, 5],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '342',\n",
       "  'title': 'Variational Recurrent Adversarial Deep Domain Adaptation'},\n",
       " 'rkE8pVcle': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '447',\n",
       "  'title': 'Learning through Dialogue Interactions by Asking Questions'},\n",
       " 'rkEFLFqee': {'CLARITY': [4],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '357',\n",
       "  'title': 'Decomposing Motion and Content for Natural Video Sequence Prediction'},\n",
       " 'rkFBJv9gg': {'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [6, 8, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '409',\n",
       "  'title': 'Learning Features of Music From Scratch'},\n",
       " 'rkFd2P5gl': {'RECOMMENDATION': [5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '617',\n",
       "  'title': 'Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning'},\n",
       " 'rkGabzZgl': {'RECOMMENDATION': [8, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '498',\n",
       "  'title': 'Dropout with Expectation-linear Regularization'},\n",
       " 'rkYmiD9lg': {'RECOMMENDATION': [7, 5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '515',\n",
       "  'title': 'Exponential Machines'},\n",
       " 'rkaRFYcgl': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '594',\n",
       "  'title': 'Low-rank passthrough neural networks'},\n",
       " 'rkjZ2Pcxe': {'RECOMMENDATION': [4, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '619',\n",
       "  'title': 'Adding Gradient Noise Improves Learning for Very Deep Networks'},\n",
       " 'rkmDI85ge': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '523',\n",
       "  'title': 'Efficient Softmax Approximation for GPUs'},\n",
       " 'rkpACe1lx': {'RECOMMENDATION': [7, 8, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '499',\n",
       "  'title': 'HyperNetworks'},\n",
       " 'rkpdnIqlx': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '654',\n",
       "  'title': 'The Variational Walkback Algorithm'},\n",
       " 'rksfwnFxl': {'RECOMMENDATION': [8, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '733',\n",
       "  'title': 'LSTM-Based System-Call Language Modeling and Ensemble Method for Host-Based Intrusion Detection'},\n",
       " 'rkuDV6iex': {'RECOMMENDATION': [4, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '556',\n",
       "  'title': 'An Empirical Analysis of Deep Network Loss Surfaces'},\n",
       " 'rky3QW9le': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '721',\n",
       "  'title': 'Transformational Sparse Coding'},\n",
       " 'ry18Ww5ee': {'CLARITY': [3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4, 5],\n",
       "  'RECOMMENDATION': [8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '402',\n",
       "  'title': 'Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization'},\n",
       " 'ry2YOrcge': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '436',\n",
       "  'title': 'Learning a Natural Language Interface with Neural Programmer'},\n",
       " 'ry3iBFqgl': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '601',\n",
       "  'title': 'NEWSQA: A MACHINE COMPREHENSION DATASET'},\n",
       " 'ry4Vrt5gl': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '362',\n",
       "  'title': 'Learning to Optimize'},\n",
       " 'ry54RWtxx': {'RECOMMENDATION': [4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '761',\n",
       "  'title': 'Learning a Static Analyzer: A Case Study on a Toy Language'},\n",
       " 'ryAe2WBee': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '787',\n",
       "  'title': 'Multi-label learning with semantic embeddings'},\n",
       " 'ryCcJaqgl': {'RECOMMENDATION': [5],\n",
       "  'dec': False,\n",
       "  'pr_id': '579',\n",
       "  'title': 'TreNet: Hybrid Neural Networks for Learning the Local Trend in Time Series'},\n",
       " 'ryEGFD9gl': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '628',\n",
       "  'title': 'Submodular Sum-product Networks for Scene Understanding'},\n",
       " 'ryF7rTqgl': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '577',\n",
       "  'title': 'Understanding intermediate layers using linear classifier probes'},\n",
       " 'ryHlUtqge': {'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '360',\n",
       "  'title': 'Generalizing Skills with Semi-Supervised Reinforcement Learning'},\n",
       " 'ryMxXPFex': {'RECOMMENDATION': [8, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '475',\n",
       "  'title': 'Discrete Variational Autoencoders'},\n",
       " 'ryPx38qge': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '656',\n",
       "  'title': 'A hybrid network: Scattering and Convnet'},\n",
       " 'ryQbbFile': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '570',\n",
       "  'title': 'CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS'},\n",
       " 'ryT4pvqll': {'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SUBSTANCE': [2, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '378',\n",
       "  'title': 'Improving Policy Gradient by Exploring Under-appreciated Rewards'},\n",
       " 'ryT9R3Yxe': {'RECOMMENDATION': [2, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '732',\n",
       "  'title': 'Generative Paragraph Vector'},\n",
       " 'ryTYxh5ll': {'RECOMMENDATION': [3, 3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '582',\n",
       "  'title': 'CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT IMAGES AND TEXT FOR THE TASK OF PRODUCT RECOMMENDATION'},\n",
       " 'ryUPiRvge': {'RECOMMENDATION': [7, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '546',\n",
       "  'title': 'Extrapolation and learning equations'},\n",
       " 'ryWKREqxx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '696',\n",
       "  'title': 'Emergent Predication Structure in Vector Representations of Neural Readers'},\n",
       " 'ryXZmzNeg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '789',\n",
       "  'title': 'Improving Sampling from Generative Autoencoders with Markov Chains'},\n",
       " 'ryZqPN5xe': {'RECOMMENDATION': [6, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '701',\n",
       "  'title': 'Beyond Fine Tuning: A Modular Approach to Learning on Small Data'},\n",
       " 'ry_4vpixl': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '552',\n",
       "  'title': 'Rotation Plane Doubly Orthogonal Recurrent Neural Networks'},\n",
       " 'ry_sjFqgx': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [5, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5],\n",
       "  'SUBSTANCE': [4, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '343',\n",
       "  'title': 'Program Synthesis for Character Level Language Modeling'},\n",
       " 'ryaFG5ige': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '566',\n",
       "  'title': 'Introducing Active Learning for CNN under the light of Variational Inference'},\n",
       " 'ryb-q1Olg': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '773',\n",
       "  'title': 'Rectified Factor Networks for Biclustering'},\n",
       " 'ryelgY5eg': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '367',\n",
       "  'title': 'Optimal Binary Autoencoding with Pairwise Correlations'},\n",
       " 'ryh9pmcee': {'RECOMMENDATION': [7, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '455',\n",
       "  'title': 'Energy-based Generative Adversarial Networks'},\n",
       " 'ryh_8f9lg': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '719',\n",
       "  'title': 'Classless Association using Neural Networks'},\n",
       " 'ryhqQFKgl': {'RECOMMENDATION': [8, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '474',\n",
       "  'title': 'Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music'},\n",
       " 'ryjp1c9xg': {'RECOMMENDATION': [4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '586',\n",
       "  'title': 'Extensions and Limitations of the Neural GPU'},\n",
       " 'ryrGawqex': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [4, 5],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '379',\n",
       "  'title': 'Deep Learning with Dynamic Computation Graphs'},\n",
       " 'ryuxYmvel': {'RECOMMENDATION': [8, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '494',\n",
       "  'title': 'HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving'},\n",
       " 'rywUcQogx': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '575',\n",
       "  'title': 'Differentiable Canonical Correlation Analysis'},\n",
       " 'ryxB0Rtxx': {'RECOMMENDATION': [6, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '466',\n",
       "  'title': 'Identity Matters in Deep Learning'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLARITY': [5],\n",
       " 'ORIGINALITY': [1],\n",
       " 'RECOMMENDATION': [6, 5],\n",
       " 'SOUNDNESS_CORRECTNESS': [4],\n",
       " 'dec': True,\n",
       " 'pr_id': '341',\n",
       " 'title': 'Third Person Imitation Learning'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_scores[\"B16dGcqlx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features/rev_aspects_2017_peerread.pkl\", \"rb\") as f:\n",
    "    review_scores = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Emergence of foveal image sampling from learning to attend in visual scenes', 'ORIGINALITY': [3], 'dec': True, 'RECOMMENDATION': [6, 5, 6], 'SOUNDNESS_CORRECTNESS': [5, 5], 'pr_id': '334', 'CLARITY': [5]}\n"
     ]
    }
   ],
   "source": [
    "for k in review_scores:\n",
    "#     print(k, review_scores[k])\n",
    "#     break\n",
    "    if k == \"SJJKxrsgl\":\n",
    "        print(review_scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../reviewratings_iclr17_peeread.pkl\", \"rb\") as f:\n",
    "    rr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IS_META_REVIEW': True,\n",
       "  'comments': \"This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \\n\\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\\n\\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.\"},\n",
       " {'DATE': '06 Feb 2017',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 pcs',\n",
       "  'TITLE': 'ICLR committee final decision',\n",
       "  'comments': 'This was a borderline case. All reviewers and the AC appeared to find the paper interesting, while having some reservations. Given the originality of the work, the PCs decided to lean toward acceptance. We do encourage however the authors to revise their paper based on reviewer feedback as much as possible, to increase its potential for impact.'},\n",
       " {'DATE': '24 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer1',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'Solid hypothesis but experiments leave doubts',\n",
       "  'comments': 'This paper presents a succinct argument that the principle of optimizing receptive field location and size in a simulated eye that can make saccades with respect to a classification error of images of data whose labels depend on variable-size and variable-location subimages, explains the existence of a foveal area in e.g. the primate retina.\\n\\nThe argument could be improved by using more-realistic image data and drawing more direct correspondence with the number, receptive field sizes and eccentricities of retinal cells in e.g. the macaque, but the authors would then face the challenge of identifying a loss function that is both biologically plausible and supportive of their claim.\\n\\nThe argument could also be improved by commenting on the timescales involved. Presumably the density of the foveal center depends on the number of of saccades allowed by the inference process, as well as the size of the target sub-images, and also has an impact on the overall classification accuracy.\\n\\nWhy does the classification error rate of dataset 2 remain stubbornly at 24%? This seems so high that the model may not be working the way we’d like it to. It seems that the overall argument of the paper pre-supposes that the model can be trained to be a good classifier. If there are other training strategies or other models that work better and differently, then it raises the question of why do our eyes and visual cortex not work more like *those ones* if evolutionary pressures are applying the same pressure as our training objective.\\n\\nWhy does the model with zooming powers out-do the translation-only model on dataset 1 (where all target images are the same size) and tie the translation-only model dataset 2 (where the target images have different sizes, for which the zooming model should be tailor-made?). Between this strange tie and the high classification rate on Dataset 2, I wonder if maybe one or both models isn’t being trained to its potential, which would undermine the overall claim.\\n\\nComparing this model to other attention models (e.g. spatial transformer networks, DRAW) would be irrelevant to what I take to be the main point of the paper, but it would address the potential concerns above that training just didn’t go very well, or there was some problem with the model parameterization that could be easily fixed.'},\n",
       " {'DATE': '20 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 3,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION': 5,\n",
       "  'RECOMMENDATION_UNOFFICIAL': 2,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Review',\n",
       "  'comments': 'The paper presented an extension to the current visual attention model that learns a deformable sampling lattice.  Comparing to the fixed sampling lattice from previous works, the proposed method shows different sampling strategy can emerge depending on the visual classification tasks. The authors empirically demonstrated the learnt sampling lattice outperforms the fixed strategies. More interestingly, when the attention mechanism is constrained  to be translation only, the proposed model learns a sampling lattice resembles the retina found in the primate retina.  \\n\\n\\nPros:\\n+ The paper is generally well organized and written \\n+ The qualitative analysis in the experimental section is very comprehensive.\\n\\nCons:\\n-  The paper could benefit substantially from additional experiments on different datasets.\\n-  It is not clear from the tables the proposed learnt sampling  lattice offer any computation benefit when comparing to  a fixed sampling strategy with zooming capability, e.g. the one used in DRAW model.\\n\\nOverall, I really like the paper. I think the experimental section can be improved by additional experiments and more quantitative analysis with other baselines. Because the current revision of the paper only shows experiments on digit dataset with black background, it is hard to generalize the finding or even to verify the claims in the paper, e.g.  linear relationship\\nbetween eccentricity and sampling interval leads to the primate retina, from the results on a single dataset.'},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 5,\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'A good apporach to attention-based models',\n",
       "  'comments': \"This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \\n\\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\\n\\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.\"},\n",
       " {'DATE': '11 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer1',\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': \"Comparison to distribution of some primate's receptive fields?\",\n",
       "  'comments': ''},\n",
       " {'DATE': '08 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 3,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION_UNOFFICIAL': 2,\n",
       "  'TITLE': 'interesting experiments',\n",
       "  'comments': ''},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '30 Nov 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'experiments on other real datasets',\n",
       "  'comments': ''},\n",
       " {'IS_META_REVIEW': True,\n",
       "  'comments': \"This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \\n\\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\\n\\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.\"},\n",
       " {'DATE': '06 Feb 2017',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 pcs',\n",
       "  'TITLE': 'ICLR committee final decision',\n",
       "  'comments': 'This was a borderline case. All reviewers and the AC appeared to find the paper interesting, while having some reservations. Given the originality of the work, the PCs decided to lean toward acceptance. We do encourage however the authors to revise their paper based on reviewer feedback as much as possible, to increase its potential for impact.'},\n",
       " {'DATE': '24 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer1',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'Solid hypothesis but experiments leave doubts',\n",
       "  'comments': 'This paper presents a succinct argument that the principle of optimizing receptive field location and size in a simulated eye that can make saccades with respect to a classification error of images of data whose labels depend on variable-size and variable-location subimages, explains the existence of a foveal area in e.g. the primate retina.\\n\\nThe argument could be improved by using more-realistic image data and drawing more direct correspondence with the number, receptive field sizes and eccentricities of retinal cells in e.g. the macaque, but the authors would then face the challenge of identifying a loss function that is both biologically plausible and supportive of their claim.\\n\\nThe argument could also be improved by commenting on the timescales involved. Presumably the density of the foveal center depends on the number of of saccades allowed by the inference process, as well as the size of the target sub-images, and also has an impact on the overall classification accuracy.\\n\\nWhy does the classification error rate of dataset 2 remain stubbornly at 24%? This seems so high that the model may not be working the way we’d like it to. It seems that the overall argument of the paper pre-supposes that the model can be trained to be a good classifier. If there are other training strategies or other models that work better and differently, then it raises the question of why do our eyes and visual cortex not work more like *those ones* if evolutionary pressures are applying the same pressure as our training objective.\\n\\nWhy does the model with zooming powers out-do the translation-only model on dataset 1 (where all target images are the same size) and tie the translation-only model dataset 2 (where the target images have different sizes, for which the zooming model should be tailor-made?). Between this strange tie and the high classification rate on Dataset 2, I wonder if maybe one or both models isn’t being trained to its potential, which would undermine the overall claim.\\n\\nComparing this model to other attention models (e.g. spatial transformer networks, DRAW) would be irrelevant to what I take to be the main point of the paper, but it would address the potential concerns above that training just didn’t go very well, or there was some problem with the model parameterization that could be easily fixed.'},\n",
       " {'DATE': '20 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 3,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION': 5,\n",
       "  'RECOMMENDATION_UNOFFICIAL': 2,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Review',\n",
       "  'comments': 'The paper presented an extension to the current visual attention model that learns a deformable sampling lattice.  Comparing to the fixed sampling lattice from previous works, the proposed method shows different sampling strategy can emerge depending on the visual classification tasks. The authors empirically demonstrated the learnt sampling lattice outperforms the fixed strategies. More interestingly, when the attention mechanism is constrained  to be translation only, the proposed model learns a sampling lattice resembles the retina found in the primate retina.  \\n\\n\\nPros:\\n+ The paper is generally well organized and written \\n+ The qualitative analysis in the experimental section is very comprehensive.\\n\\nCons:\\n-  The paper could benefit substantially from additional experiments on different datasets.\\n-  It is not clear from the tables the proposed learnt sampling  lattice offer any computation benefit when comparing to  a fixed sampling strategy with zooming capability, e.g. the one used in DRAW model.\\n\\nOverall, I really like the paper. I think the experimental section can be improved by additional experiments and more quantitative analysis with other baselines. Because the current revision of the paper only shows experiments on digit dataset with black background, it is hard to generalize the finding or even to verify the claims in the paper, e.g.  linear relationship\\nbetween eccentricity and sampling interval leads to the primate retina, from the results on a single dataset.'},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 5,\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'A good apporach to attention-based models',\n",
       "  'comments': \"This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The experiments showed that the model can learn a meaning lattice to the visual search task where the sampling lattice looks similar to human being's. \\n\\nThe main concern of the paper is that experiments are not sufficient. The paper only reports the results on a modified clustered MNIST dataset. It would be more interesting if the authors could conduct  the model on real datasets, such as Toronto Face dataset, CUB bird dataset and SVHN. For example, for the Face dataset, it would be nice if the model can learn to attend different parts of the face for expression recognition, or attend different part of birds for fine-grained classification. Since the authors replied in the pre-review question that the model can learn meaningful lattice on MSCOCO dataset, I think it would be better to add that results into the paper.\\n\\nAnother drawback of the model is that the paper only compare with different variants of itselves. I suggest that this paper should compare with  Spatial Transformer Networks, DRAW, etc., on the same dataset to show the advantage of the learned sampling lattice.\"},\n",
       " {'DATE': '11 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer1',\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': \"Comparison to distribution of some primate's receptive fields?\",\n",
       "  'comments': ''},\n",
       " {'DATE': '08 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 3,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION_UNOFFICIAL': 2,\n",
       "  'TITLE': 'interesting experiments',\n",
       "  'comments': ''},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '30 Nov 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'SOUNDNESS_CORRECTNESS': 5,\n",
       "  'TITLE': 'experiments on other real datasets',\n",
       "  'comments': ''}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr['334'][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
