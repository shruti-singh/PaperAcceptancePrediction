{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../reviewratings_iclr17_peeread.pkl\", \"rb\") as f:\n",
    "    rr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT_LIST SAMPLE:\n",
    "# \n",
    "# {'abaselinefordetectingmisclassifiedandoutofdistributionexamplesinneuralnetworks': {'AnonReviewer1': {'MEANINGFUL_COMPARISON': [4,\n",
    "#     datetime.datetime(2016, 12, 19, 0, 0)],\n",
    "#    'ORIGINALITY': [4, datetime.datetime(2016, 12, 19, 0, 0)],\n",
    "#    'RECOMMENDATION': [6, datetime.datetime(2016, 12, 19, 0, 0)]},\n",
    "#   'AnonReviewer2': {'RECOMMENDATION': [6,\n",
    "#     datetime.datetime(2016, 12, 16, 0, 0)]},\n",
    "#   'AnonReviewer3': {'IMPACT': [2, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'ORIGINALITY': [3, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'RECOMMENDATION': [6, datetime.datetime(2017, 1, 20, 0, 0)],\n",
    "#    'SOUNDNESS_CORRECTNESS': [3, datetime.datetime(2017, 1, 20, 0, 0)]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_aspects = [\"MEANINGFUL_COMPARISON\", \"IMPACT\", \"ORIGINALITY\", \"RECOMMENDATION\", \"SUBSTANCE\", \"SOUNDNESS_CORRECTNESS\", \"APPROPRIATENESS\", \"CLARITY\"]\n",
    "\n",
    "aspect_dict = defaultdict(dict)\n",
    "inspect_list = {}\n",
    "\n",
    "for k in rr:\n",
    "    new_key = rr[k][\"title\"].strip().lower()\n",
    "    \n",
    "    new_key = re.sub('[^0-9a-zA-Z]+', '', new_key)\n",
    "    \n",
    "    aspect_dict[new_key][\"title\"] = rr[k][\"title\"]\n",
    "    aspect_dict[new_key][\"dec\"] = rr[k][\"accepted\"]\n",
    "    aspect_dict[new_key][\"pr_id\"] = k\n",
    "    \n",
    "    inspect_list[new_key] = {}\n",
    "    \n",
    "    if \"reviews\" in rr[k]:\n",
    "        for rev in rr[k][\"reviews\"]:\n",
    "            if \"OTHER_KEYS\" in rev:\n",
    "                if rev[\"OTHER_KEYS\"].find(\"AnonReviewer\") > -1:\n",
    "                    anon_reviewer = rev[\"OTHER_KEYS\"].split(\" \")[-1]\n",
    "                    if anon_reviewer in inspect_list[new_key]:\n",
    "                        #inspect_list[new_key][anon_reviewer]\n",
    "                        dummy = 1\n",
    "                    else:\n",
    "                        inspect_list[new_key][anon_reviewer] = {}\n",
    "                    if \"DATE\" in rev:\n",
    "                        if rev[\"DATE\"].find(\"modified\") > -1:\n",
    "                            d = rev[\"DATE\"]\n",
    "                            try:\n",
    "                                rev[\"DATE\"] = re.findall('([0-9]+ [A-Za-z]+ [0-9][0-9][0-9][0-9]\\))$', d)[0][:-1]\n",
    "                            except Exception:\n",
    "                                print(rev[\"DATE\"])\n",
    "                        else:\n",
    "                            try:\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].replace(\"(\", \"\")\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].replace(\")\", \"\")\n",
    "                                rev[\"DATE\"] = rev[\"DATE\"].strip()\n",
    "                                date_of_review = parse(rev[\"DATE\"])\n",
    "                            except Exception:\n",
    "                                print(rev[\"DATE\"], k)\n",
    "                    else:\n",
    "                        date_of_review = parse(\"1 Jan 2000\")\n",
    "                    \n",
    "                    for asp in acl_aspects:\n",
    "                        if asp in rev:\n",
    "                            if asp in inspect_list[new_key][anon_reviewer]:\n",
    "                                prev_date = inspect_list[new_key][anon_reviewer][asp][1]\n",
    "                                if prev_date < date_of_review:\n",
    "                                    prev_rev_text = inspect_list[new_key][anon_reviewer][asp][2] + \". \" + inspect_list[new_key][anon_reviewer][asp][3]\n",
    "                                    # current rev text, prev_rev_text\n",
    "                                    inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"], prev_rev_text]\n",
    "                                else:\n",
    "                                    inspect_list[new_key][anon_reviewer][asp][3] = inspect_list[new_key][anon_reviewer][asp][3] + \". \" +  rev[\"TITLE\"] + \". \" + rev[\"comments\"]\n",
    "                            else:\n",
    "                                inspect_list[new_key][anon_reviewer][asp] = [rev[asp], date_of_review, rev[\"TITLE\"] + \". \" + rev[\"comments\"], \" \"]\n",
    "            else:\n",
    "                for asp in acl_aspects:\n",
    "                    if asp in rev:\n",
    "                        inspect_list.append((k, rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../ICLR data/masterdata_unbalanced/\"\n",
    "year = 2017\n",
    "paper_file = \"papers_{}.pkl\".format(year)\n",
    "\n",
    "\n",
    "with open(data_dir+paper_file, \"rb\") as f:\n",
    "    papers_data = pickle.load(f)\n",
    "\n",
    "\n",
    "final_dict = {}\n",
    "\n",
    "not_found = []\n",
    "\n",
    "for k in papers_data:\n",
    "    t = papers_data[k][\"content\"][\"title\"].strip().lower()\n",
    "    t = re.sub('[^0-9a-zA-Z]+', '', t)\n",
    "    if t in aspect_dict:\n",
    "        final_dict[k] = aspect_dict[t]\n",
    "        final_dict[k][\"rev_info\"] = inspect_list[t]\n",
    "    else:\n",
    "#         print(t, k)\n",
    "        not_found.append(t)\n",
    "print(len(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dec': False,\n",
       " 'pr_id': '618',\n",
       " 'rev_info': {'AnonReviewer1': {'RECOMMENDATION': [5,\n",
       "    datetime.datetime(2016, 12, 26, 0, 0),\n",
       "    'review. This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features. The network can estimate the transformation of filters given the input images. \\n\\nThis work is based on a solid technical foundation and is motivated by a plausible rationale. Yet, the value of this work in practice is subject to questions:\\n\\n(1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally). Do such transformations constitute real challenges in practice? State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations. What such components would add to the state of the art? Limited experiments on Cifar-10 does not seem to provide a very strong argument.\\n\\n(2) The computational cost is not discussed.',\n",
       "    ' . review. This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features. The network can estimate the transformation of filters given the input images. \\n\\nThis work is based on a solid technical foundation and is motivated by a plausible rationale. Yet, the value of this work in practice is subject to questions:\\n\\n(1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally). Do such transformations constitute real challenges in practice? State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations. What such components would add to the state of the art? Limited experiments on Cifar-10 does not seem to provide a very strong argument.\\n\\n(2) The computational cost is not discussed.']},\n",
       "  'AnonReviewer2': {'RECOMMENDATION': [7,\n",
       "    datetime.datetime(2016, 12, 16, 0, 0),\n",
       "    'Interesting approach for adaptable convolutional filters. This works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied. Authors provide a detailed overview of steerable frames followed with an experimental section which applies dynamic steerable network to small machine learning problems where the steerability is conceptually useful.\\n\\nEven though the evaluation is performed only on few small tasks, the reason why more tasks were not evaluated is that piece-wise pose invariance is needed only for a subset of tasks. The fact, that simply using overcomplete bases as a sort of \"feature pre-processing\" improves the results for already highly optimized ResNet and DenseNet architectures is quite interesting achievement.\\n\\nFor the edge detection, a relatively hard baseline is selected - the Dynamic Filter Networks, which already attempts to achieve position invariant filters. The fact that DSFN improves the performance on this task verifies that regressing the parametrization of the steerable filters yields better results than regressing the filters directly.\\n\\nIn the last experiment authors apply the network to video classification using LSTMs and they show that the improved performance is not due to increased capacity of the network.\\n\\nIn general, it is quite interesting work. Even though it does not offer ground-breaking results (mainly in a sense of not performing experiments on larger tasks), it is theoretically interesting and shows promising results.\\n\\nThere are few minor issues and suggestions related to the paper:\\n* For the LSTM experiment, in order to be more exact, it would be useful to include information about total number of parameters, as the network which estimates the pose also increases the number of parameters.\\n* Would it be possible to provide more details about how the back-propagation is done through the steerable filters?\\n* For the Edge Detection experiment, it would be useful to provide results for some standard baseline - e.g. CNN with a similar number of parameters. Simply to see how useful it is to have location-variant filters for this task.\\n* The last sentence in second paragraph on page 1 is missing a verb. Also it is maybe unnecessary.\\n* The hyphenation for ConvNet is incorrect on multiple places (probably `\\\\hyphenation{Conv-Net}` would fix it).\\n',\n",
       "    ' . Interesting approach for adaptable convolutional filters. This works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied. Authors provide a detailed overview of steerable frames followed with an experimental section which applies dynamic steerable network to small machine learning problems where the steerability is conceptually useful.\\n\\nEven though the evaluation is performed only on few small tasks, the reason why more tasks were not evaluated is that piece-wise pose invariance is needed only for a subset of tasks. The fact, that simply using overcomplete bases as a sort of \"feature pre-processing\" improves the results for already highly optimized ResNet and DenseNet architectures is quite interesting achievement.\\n\\nFor the edge detection, a relatively hard baseline is selected - the Dynamic Filter Networks, which already attempts to achieve position invariant filters. The fact that DSFN improves the performance on this task verifies that regressing the parametrization of the steerable filters yields better results than regressing the filters directly.\\n\\nIn the last experiment authors apply the network to video classification using LSTMs and they show that the improved performance is not due to increased capacity of the network.\\n\\nIn general, it is quite interesting work. Even though it does not offer ground-breaking results (mainly in a sense of not performing experiments on larger tasks), it is theoretically interesting and shows promising results.\\n\\nThere are few minor issues and suggestions related to the paper:\\n* For the LSTM experiment, in order to be more exact, it would be useful to include information about total number of parameters, as the network which estimates the pose also increases the number of parameters.\\n* Would it be possible to provide more details about how the back-propagation is done through the steerable filters?\\n* For the Edge Detection experiment, it would be useful to provide results for some standard baseline - e.g. CNN with a similar number of parameters. Simply to see how useful it is to have location-variant filters for this task.\\n* The last sentence in second paragraph on page 1 is missing a verb. Also it is maybe unnecessary.\\n* The hyphenation for ConvNet is incorrect on multiple places (probably `\\\\hyphenation{Conv-Net}` would fix it).\\n']},\n",
       "  'AnonReviewer3': {'RECOMMENDATION': [4,\n",
       "    datetime.datetime(2016, 12, 20, 0, 0),\n",
       "    'No Title. I sincerely apologize for the late review!\\n\\nThe first part has a strong emphasis on the technical part. It could benefit from some high level arguments on what the method aims to achieve, what limitation is there to overcome. I may have misunderstood the contribution (in which case please correct me) that the main novel part of the paper is the suggestion to learn the group parameterizations instead of pre-fixing them. So instead of applying it to common spatial filters as in De Brabandere et al., it is applied to Steerable Frames?\\n\\nThe first contribution suggests that \"general frame bases are better suited to represent sensory input data than the commonly used pixel basis.\". The experiments on Cifar10+ indicate that this is not true in general. Considering the basis as a hyper-parameter, expensive search has to be conducted to find that the Gauss-Frame gives better results. I assume this does not suggest that the Gauss-Frame is always better, at least there is weak evidence on a single network presented. Maybe the first contribution has to be re-stated. Further is the \"Pixel\" network representation corrected for the larger number of parameters. As someone who is interested in using this, what are the runtime considerations? \\n\\nI would strongly suggest to improve Fig.3. The Figure uses \"w\" several times in different notations and depictions. It mixes boxes, single symbols and illustrative figures. It took some time to decipher the Figure and its flow. \\n\\n\\nSummary: The paper is sufficiently clear, technical at many places and readability can be improved. E.g., the introduction of frames in the beginning lacks motivation and is rather unclear to someone new to this concept. The work falls in the general category of methods that impose knowledge about filter transformations into the network architecture. For me that has always two sides, the algorithmic and technical part (there are several ways to do this) and the practical side (should I do it)? This is a possible approach to this problem but after the paper I was a bit wondering what I have learned, I am certainly not inspired based on the content of the paper to integrate or build on this work. I am lacking insights into transformational parameters that are relevant for a problem. While the spatial transformer network paper was weaker on the technical elegance side, it provided exactly this: an insight into the feature transformation learned by the algorithm. I am missing this here, e.g., from Table 2  I learn that among four choices one works empirically better. What is destroyed by the x^py^p and Hermite frames that the ResNet is *not* able to recover from? You can construct network architectures that are the superset of both, so that inferior performance could be avoided. \\n\\nThe algorithm is clear but it is similar to the Dynamic Filter Networks paper. And I am unfortunately not convinced about the usefulness of this particular formulation. I\\'d expect a stronger paper with more insights into transformations and comparisons to standard techniques, a clear delineation of when this is advised. ',\n",
       "    ' . No Title. I sincerely apologize for the late review!\\n\\nThe first part has a strong emphasis on the technical part. It could benefit from some high level arguments on what the method aims to achieve, what limitation is there to overcome. I may have misunderstood the contribution (in which case please correct me) that the main novel part of the paper is the suggestion to learn the group parameterizations instead of pre-fixing them. So instead of applying it to common spatial filters as in De Brabandere et al., it is applied to Steerable Frames?\\n\\nThe first contribution suggests that \"general frame bases are better suited to represent sensory input data than the commonly used pixel basis.\". The experiments on Cifar10+ indicate that this is not true in general. Considering the basis as a hyper-parameter, expensive search has to be conducted to find that the Gauss-Frame gives better results. I assume this does not suggest that the Gauss-Frame is always better, at least there is weak evidence on a single network presented. Maybe the first contribution has to be re-stated. Further is the \"Pixel\" network representation corrected for the larger number of parameters. As someone who is interested in using this, what are the runtime considerations? \\n\\nI would strongly suggest to improve Fig.3. The Figure uses \"w\" several times in different notations and depictions. It mixes boxes, single symbols and illustrative figures. It took some time to decipher the Figure and its flow. \\n\\n\\nSummary: The paper is sufficiently clear, technical at many places and readability can be improved. E.g., the introduction of frames in the beginning lacks motivation and is rather unclear to someone new to this concept. The work falls in the general category of methods that impose knowledge about filter transformations into the network architecture. For me that has always two sides, the algorithmic and technical part (there are several ways to do this) and the practical side (should I do it)? This is a possible approach to this problem but after the paper I was a bit wondering what I have learned, I am certainly not inspired based on the content of the paper to integrate or build on this work. I am lacking insights into transformational parameters that are relevant for a problem. While the spatial transformer network paper was weaker on the technical elegance side, it provided exactly this: an insight into the feature transformation learned by the algorithm. I am missing this here, e.g., from Table 2  I learn that among four choices one works empirically better. What is destroyed by the x^py^p and Hermite frames that the ResNet is *not* able to recover from? You can construct network architectures that are the superset of both, so that inferior performance could be avoided. \\n\\nThe algorithm is clear but it is similar to the Dynamic Filter Networks paper. And I am unfortunately not convinced about the usefulness of this particular formulation. I\\'d expect a stronger paper with more insights into transformations and comparisons to standard techniques, a clear delineation of when this is advised. ']}},\n",
       " 'title': 'Dynamic Steerable Frame Networks'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_data = {}\n",
    "keywords = [\"original\", \"proposal\", \"originality\", \"unique\", \"novelty\", \"novel\", \"contribution\", \"significance\", \"significant\"]\n",
    "\n",
    "for k final_dict:\n",
    "    for reviewer_num in final_dict['rev_info']:\n",
    "        if \"ORIGINALITY\" in final_dict['rev_info'][reviewer_num]:\n",
    "            excel_data[k+\"_\"+reviewer_num] = { \"dec\": final_dict[k][\"dec\"],\"score\": final_dict['rev_info'][reviewer_num][\"ORIGINALITY\"][0] }\n",
    "            current_text = final_dict['rev_info'][reviewer_num][\"ORIGINALITY\"][2]\n",
    "            other_text = final_dict['rev_info'][reviewer_num][\"ORIGINALITY\"][3]\n",
    "            \n",
    "            doc = nlp(current_text)\n",
    "            for s in doc.sents:\n",
    "                sent_text = s.text.lower()\n",
    "                for kw in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features/rev_aspects_2017_peerread.pkl\", \"rb\") as f:\n",
    "    review_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B1-Hhnslg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '559',\n",
       "  'title': 'Prototypical Networks for Few-shot Learning'},\n",
       " 'B1-q5Pqxl': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 6, 6],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '384',\n",
       "  'title': 'Machine Comprehension Using Match-LSTM and Answer Pointer'},\n",
       " 'B16Jem9xe': {'RECOMMENDATION': [8, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '534',\n",
       "  'title': 'Learning in Implicit Generative Models'},\n",
       " 'B16dGcqlx': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [1],\n",
       "  'RECOMMENDATION': [6, 5],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '341',\n",
       "  'title': 'Third Person Imitation Learning'},\n",
       " 'B184E5qee': {'CLARITY': [5],\n",
       "  'IMPACT': [2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [5, 7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '339',\n",
       "  'title': 'Improving Neural Language Models with a Continuous Cache'},\n",
       " 'B186cP9gx': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '623',\n",
       "  'title': 'Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond'},\n",
       " 'B1E7Pwqgl': {'RECOMMENDATION': [3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '633',\n",
       "  'title': 'Cooperative Training of Descriptor and Generator Networks'},\n",
       " 'B1ElR4cgg': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '446',\n",
       "  'title': 'Adversarially Learned Inference'},\n",
       " 'B1G9tvcgx': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '627',\n",
       "  'title': 'Neural Machine Translation with Latent Semantic of Image and Text'},\n",
       " 'B1GOWV5eg': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '452',\n",
       "  'title': 'Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning'},\n",
       " 'B1Igu2ogg': {'CLARITY': [5, 4, 5],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '330',\n",
       "  'title': 'Efficient Vector Representation for Documents through Corruption'},\n",
       " 'B1IzH7cxl': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '712',\n",
       "  'title': 'A Neural Stochastic Volatility Model'},\n",
       " 'B1KBHtcel': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '604',\n",
       "  'title': \"Here's My Point: Argumentation Mining with Pointer Networks\"},\n",
       " 'B1M8JF9xx': {'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SUBSTANCE': [4, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '368',\n",
       "  'title': 'On the Quantitative Analysis of Decoder-Based Generative Models'},\n",
       " 'B1PA8fqeg': {'RECOMMENDATION': [2, 3, 1],\n",
       "  'dec': False,\n",
       "  'pr_id': '718',\n",
       "  'title': 'Multiagent System for Layer Free Network'},\n",
       " 'B1TTpYKgx': {'RECOMMENDATION': [6, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '742',\n",
       "  'title': 'On the Expressive Power of Deep Neural Networks'},\n",
       " 'B1YfAfcgl': {'RECOMMENDATION': [9, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '458',\n",
       "  'title': 'Entropy-SGD: Biasing Gradient Descent Into Wide Valleys'},\n",
       " 'B1ZXuTolx': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '550',\n",
       "  'title': 'Revisiting Denoising Auto-Encoders'},\n",
       " 'B1akgy9xx': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '725',\n",
       "  'title': 'Making Stochastic Neural Networks from Deterministic Ones'},\n",
       " 'B1ckMDqlg': {'IMPACT': [5],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '399',\n",
       "  'title': ' Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer'},\n",
       " 'B1ewdt9xe': {'CLARITY': [5],\n",
       "  'MEANINGFUL_COMPARISON': [5, 2],\n",
       "  'ORIGINALITY': [4, 4, 4],\n",
       "  'RECOMMENDATION': [6, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '350',\n",
       "  'title': 'Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning'},\n",
       " 'B1gtu5ilg': {'CLARITY': [5, 5],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'RECOMMENDATION': [5, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '332',\n",
       "  'title': 'Transfer of View-manifold Learning to Similarity Perception of Novel Objects'},\n",
       " 'B1hdzd5lg': {'CLARITY': [3, 4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '374',\n",
       "  'title': 'Words or Characters? Fine-grained Gating for Reading Comprehension'},\n",
       " 'B1jnyXXJx': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '548',\n",
       "  'title': 'Charged Point Normalization: An Efficient Solution to the Saddle Point Problem'},\n",
       " 'B1kJ6H9ex': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '432',\n",
       "  'title': 'Combining policy gradient and Q-learning'},\n",
       " 'B1mAJI9gl': {'RECOMMENDATION': [4, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '674',\n",
       "  'title': 'Towards Understanding the Invertibility of Convolutional Neural Networks'},\n",
       " 'B1oK8aoxe': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '321',\n",
       "  'title': 'Stochastic Neural Networks for Hierarchical Reinforcement Learning'},\n",
       " 'B1s6xvqlx': {'CLARITY': [5],\n",
       "  'IMPACT': [5, 4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [8, 7, 5],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '405',\n",
       "  'title': 'Recurrent Environment Simulators'},\n",
       " 'B1vRTeqxg': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '538',\n",
       "  'title': 'Learning Continuous Semantic Representations of Symbolic Expressions'},\n",
       " 'BJ--gPcxl': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '648',\n",
       "  'title': 'Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks'},\n",
       " 'BJ0Ee8cxx': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '673',\n",
       "  'title': 'Hierarchical Memory Networks'},\n",
       " 'BJ3filKll': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '485',\n",
       "  'title': 'Efficient Representation of Low-Dimensional Manifolds using Deep Networks'},\n",
       " 'BJ46w6Ule': {'RECOMMENDATION': [3, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '781',\n",
       "  'title': 'Dynamic Partition Models'},\n",
       " 'BJ5UeU9xx': {'RECOMMENDATION': [6, 9, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '427',\n",
       "  'title': 'Visualizing Deep Neural Network Decisions: Prediction Difference Analysis'},\n",
       " 'BJ6oOfqge': {'RECOMMENDATION': [7, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '461',\n",
       "  'title': 'Temporal Ensembling for Semi-Supervised Learning'},\n",
       " 'BJ8fyHceg': {'RECOMMENDATION': [6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '529',\n",
       "  'title': 'Tuning Recurrent Neural Networks with Reinforcement Learning'},\n",
       " 'BJ9fZNqle': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '706',\n",
       "  'title': 'Multi-modal Variational Encoder-Decoders'},\n",
       " 'BJAA4wKxg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '748',\n",
       "  'title': 'A Convolutional Encoder Model for Neural Machine Translation'},\n",
       " 'BJAFbaolg': {'APPROPRIATENESS': [3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '325',\n",
       "  'title': 'Learning to Generate Samples from Noise through Infusion Training'},\n",
       " 'BJC8LF9ex': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '599',\n",
       "  'title': 'Recurrent Neural Networks for Multivariate Time Series with Missing Values'},\n",
       " 'BJFG8Yqxl': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '600',\n",
       "  'title': 'Group Sparse CNNs for Question Sentence Classification with Answer Sets'},\n",
       " 'BJK3Xasel': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 5, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '322',\n",
       "  'title': 'Nonparametric Neural Networks'},\n",
       " 'BJKYvt5lg': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '353',\n",
       "  'title': 'PixelVAE: A Latent Variable Model for Natural Images'},\n",
       " 'BJRIA3Fgg': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '540',\n",
       "  'title': 'Modularized Morphing of Neural Networks'},\n",
       " 'BJVEEF9lx': {'RECOMMENDATION': [4, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '606',\n",
       "  'title': 'Learning Approximate Distribution-Sensitive Data Structures'},\n",
       " 'BJYwwY9ll': {'CLARITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '354',\n",
       "  'title': 'Snapshot Ensembles: Train 1, Get M for Free'},\n",
       " 'BJ_MGwqlg': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '642',\n",
       "  'title': 'Rethinking Numerical Representations for Deep Neural Networks'},\n",
       " 'BJa0ECFxe': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '726',\n",
       "  'title': 'Information Dropout: learning optimal representations through noise'},\n",
       " 'BJbD_Pqlg': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '629',\n",
       "  'title': 'Human perception in computer vision'},\n",
       " 'BJh6Ztuxl': {'RECOMMENDATION': [8, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '489',\n",
       "  'title': 'Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks'},\n",
       " 'BJhZeLsxx': {'CLARITY': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '333',\n",
       "  'title': 'What does it take to generate natural textures?'},\n",
       " 'BJjn-Yixl': {'RECOMMENDATION': [5, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '569',\n",
       "  'title': 'Attentive Recurrent Comparators'},\n",
       " 'BJluGHcee': {'RECOMMENDATION': [7, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '689',\n",
       "  'title': 'Tensorial Mixture Models'},\n",
       " 'BJm4T4Kgx': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '481',\n",
       "  'title': 'Adversarial Machine Learning at Scale'},\n",
       " 'BJrFC6ceg': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '336',\n",
       "  'title': 'PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications'},\n",
       " 'BJtNZAFgg': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '467',\n",
       "  'title': 'Adversarial Feature Learning'},\n",
       " 'BJuysoFeg': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '736',\n",
       "  'title': 'Revisiting Batch Normalization For Practical Domain Adaptation'},\n",
       " 'BJwFrvOeg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '770',\n",
       "  'title': 'A Neural Knowledge Language Model'},\n",
       " 'BJxhLAuxg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '765',\n",
       "  'title': 'A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games'},\n",
       " 'Bk0FWVcgx': {'RECOMMENDATION': [7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '451',\n",
       "  'title': 'Topology and Geometry of Half-Rectified Network Optimization'},\n",
       " 'Bk0MRI5lg': {'RECOMMENDATION': [5, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '651',\n",
       "  'title': 'Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units'},\n",
       " 'Bk2TqVcxe': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '530',\n",
       "  'title': 'Discovering objects and their relations from entangled scene representations'},\n",
       " 'Bk3F5Y9lx': {'RECOMMENDATION': [4, 8, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '592',\n",
       "  'title': 'Epitomic Variational Autoencoders'},\n",
       " 'Bk8BvDqex': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [8, 8, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 4],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '390',\n",
       "  'title': 'Metacontrol for Adaptive Imagination-Based Optimization'},\n",
       " 'Bk8N0RLxx': {'RECOMMENDATION': [4, 5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '779',\n",
       "  'title': 'Vocabulary Selection Strategies for Neural Machine Translation'},\n",
       " 'Bk8aOm9xl': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '533',\n",
       "  'title': 'Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning'},\n",
       " 'BkCPyXm1l': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '792',\n",
       "  'title': 'SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks'},\n",
       " 'BkGakb9lx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '537',\n",
       "  'title': 'RenderGAN: Generating Realistic Labeled Data'},\n",
       " 'BkIqod5ll': {'RECOMMENDATION': [6, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '609',\n",
       "  'title': 'Convolutional Neural Networks Generalization Utilizing the Data Graph Structure'},\n",
       " 'BkLhzHtlg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '480',\n",
       "  'title': 'Learning Recurrent Representations for Hierarchical Behavior Modeling'},\n",
       " 'BkSmc8qll': {'RECOMMENDATION': [4, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '662',\n",
       "  'title': 'Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes'},\n",
       " 'BkSqjHqxg': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '677',\n",
       "  'title': 'Skip-graph: Learning graph embeddings with an encoder-decoder model'},\n",
       " 'BkUDvt5gg': {'RECOMMENDATION': [4, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '598',\n",
       "  'title': 'Wav2Letter: an End-to-End ConvNet-based Speech Recognition System'},\n",
       " 'BkV4VS9ll': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '687',\n",
       "  'title': 'The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning'},\n",
       " 'BkVsEMYel': {'RECOMMENDATION': [6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '484',\n",
       "  'title': 'Inductive Bias of Deep Convolutional Networks through Pooling Geometry'},\n",
       " 'BkXMikqxx': {'RECOMMENDATION': [5, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '723',\n",
       "  'title': 'Cortical-Inspired Open-Bigram Representation for Handwritten Word Recognition'},\n",
       " 'Bk_zTU5eg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '653',\n",
       "  'title': 'Inefficiency of stochastic gradient descent with larger mini-batches (and more learners)'},\n",
       " 'Bkab5dqxe': {'CLARITY': [3, 4],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [9, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '371',\n",
       "  'title': 'A Compositional Object-Based Approach to Learning Physical Dynamics'},\n",
       " 'BkbY4psgg': {'CLARITY': [3],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [8, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '304',\n",
       "  'title': 'Making Neural Programming Architectures Generalize via Recursion'},\n",
       " 'Bkbc-Vqeg': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '705',\n",
       "  'title': 'Learning Word-Like Units from Joint Audio-Visual Analylsis'},\n",
       " 'Bkepl7cee': {'RECOMMENDATION': [7, 6, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '713',\n",
       "  'title': 'Parametric Exponential Linear Unit for Deep Convolutional Neural Networks'},\n",
       " 'BkfiXiUlg': {'RECOMMENDATION': [3, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '782',\n",
       "  'title': 'Learning Efficient Algorithms with Hierarchical Attentive Memory'},\n",
       " 'Bkfwyw5xg': {'RECOMMENDATION': [6, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '649',\n",
       "  'title': 'Investigating Different Context Types and Representations for Learning Word Embeddings'},\n",
       " 'BkjLkSqxg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '694',\n",
       "  'title': 'LipNet: End-to-End Sentence-level Lipreading'},\n",
       " 'Bkp_y7qxe': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '714',\n",
       "  'title': 'Unsupervised Deep Learning of State Representation Using Robotic Priors '},\n",
       " 'Bkul3t9ee': {'RECOMMENDATION': [6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '504',\n",
       "  'title': 'Unsupervised Perceptual Rewards for Imitation Learning'},\n",
       " 'By1snw5gl': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '615',\n",
       "  'title': 'L-SR1: A Second Order Optimization Method for Deep Learning'},\n",
       " 'By5e2L9gl': {'CLARITY': [3],\n",
       "  'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '412',\n",
       "  'title': 'Trusting SVM for Piecewise Linear CNNs'},\n",
       " 'ByC7ww9le': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '632',\n",
       "  'title': 'Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering'},\n",
       " 'ByEPMj5el': {'RECOMMENDATION': [5, 4, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '583',\n",
       "  'title': 'Out-of-class novelty generation: an experimental foundation'},\n",
       " 'ByG4hz5le': {'RECOMMENDATION': [7, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '535',\n",
       "  'title': 'Adaptive Feature Abstraction for Translating Video to Language'},\n",
       " 'ByG8A7cee': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '707',\n",
       "  'title': 'Reference-Aware Language Models'},\n",
       " 'ByIAPUcee': {'CLARITY': [3, 2],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [3, 5],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '420',\n",
       "  'title': 'Frustratingly Short Attention Spans in Neural Language Modeling'},\n",
       " 'ByOK0rwlx': {'RECOMMENDATION': [6, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '778',\n",
       "  'title': 'Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network'},\n",
       " 'ByOvsIqeg': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '415',\n",
       "  'title': 'Regularizing CNNs with Locally Constrained Decorrelations'},\n",
       " 'ByQPVFull': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '768',\n",
       "  'title': 'Training Group Orthogonal Neural Networks with Privileged Information'},\n",
       " 'ByToKu9ll': {'RECOMMENDATION': [5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '610',\n",
       "  'title': 'Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models'},\n",
       " 'ByW2Avqgg': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '613',\n",
       "  'title': 'Neural Causal Regularization under the Independence of Mechanisms Assumption'},\n",
       " 'ByZvfijeg': {'RECOMMENDATION': [4, 3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '564',\n",
       "  'title': 'Higher Order Recurrent Neural Networks'},\n",
       " 'BybtVK9lg': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [3, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 3],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '366',\n",
       "  'title': 'Autoencoding Variational Inference For Topic Models'},\n",
       " 'BycCx8qex': {'RECOMMENDATION': [7, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '671',\n",
       "  'title': 'DRAGNN: A Transition-Based Framework for Dynamically Connected Neural Networks'},\n",
       " 'BydARw9ex': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '376',\n",
       "  'title': 'Capacity and Trainability in Recurrent Neural Networks'},\n",
       " 'BydrOIcle': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [2],\n",
       "  'IMPACT': [4],\n",
       "  'RECOMMENDATION': [7, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '418',\n",
       "  'title': 'Unrolled Generative Adversarial Networks'},\n",
       " 'Bygq-H9eg': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '690',\n",
       "  'title': 'An Analysis of Deep Neural Network Models for Practical Applications'},\n",
       " 'Byiy-Pqlx': {'APPROPRIATENESS': [2],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 8, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '403',\n",
       "  'title': 'Lie-Access Neural Turing Machines'},\n",
       " 'Byj72udxe': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '490',\n",
       "  'title': 'Pointer Sentinel Mixture Models'},\n",
       " 'Byk-VI9eg': {'IMPACT': [1],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '423',\n",
       "  'title': 'Generative Multi-Adversarial Networks'},\n",
       " 'BylSPv9gx': {'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [2, 3],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '391',\n",
       "  'title': 'Exploring Sparsity in Recurrent Neural Networks'},\n",
       " 'ByldLrqlx': {'RECOMMENDATION': [6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '439',\n",
       "  'title': 'DeepCoder: Learning to Write Programs'},\n",
       " 'BymIbLKgl': {'RECOMMENDATION': [8, 5, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '478',\n",
       "  'title': 'Learning Invariant Representations Of Planar Curves '},\n",
       " 'BysZhEqee': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '700',\n",
       "  'title': 'Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications'},\n",
       " 'BysvGP5ee': {'CLARITY': [5, 5, 4],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [1, 3],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '397',\n",
       "  'title': 'Variational Lossy Autoencoder'},\n",
       " 'ByvJuTigl': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '551',\n",
       "  'title': 'End-to-End Learnable Histogram Filters'},\n",
       " 'Byx5BTilg': {'RECOMMENDATION': [3, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '555',\n",
       "  'title': 'Exploring the Application of Deep Learning for Supervised Learning Problems'},\n",
       " 'ByxpMd9lx': {'MEANINGFUL_COMPARISON': [4],\n",
       "  'RECOMMENDATION': [8, 7, 5],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '373',\n",
       "  'title': 'Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks'},\n",
       " 'H12GRgcxg': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '463',\n",
       "  'title': 'Training deep neural-networks using a noise adaptation layer'},\n",
       " 'H13F3Pqll': {'RECOMMENDATION': [5, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '616',\n",
       "  'title': 'Inverse Problems in Computer Vision using  Adversarial  Imagination Priors'},\n",
       " 'H178hw9ex': {'RECOMMENDATION': [5, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '618',\n",
       "  'title': 'Dynamic Steerable Frame Networks'},\n",
       " 'H1Fk2Iqex': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '521',\n",
       "  'title': 'Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech'},\n",
       " 'H1GEvHcee': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '682',\n",
       "  'title': 'Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM'},\n",
       " 'H1Go7Koex': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '568',\n",
       "  'title': 'Character-aware Attention Residual Network for Sentence Representation'},\n",
       " 'H1Gq5Q9el': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '709',\n",
       "  'title': 'Unsupervised Pretraining for Sequence to Sequence Learning'},\n",
       " 'H1Heentlx': {'RECOMMENDATION': [5, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '734',\n",
       "  'title': 'Deep Variational Canonical Correlation Analysis'},\n",
       " 'H1MjAnqxg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '580',\n",
       "  'title': 'Intelligible Language Modeling with Input Switched Affine Networks'},\n",
       " 'H1W1UN9gg': {'RECOMMENDATION': [8, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '448',\n",
       "  'title': 'Deep Information Propagation'},\n",
       " 'H1_EDpogx': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '553',\n",
       "  'title': 'Near-Data Processing for Machine Learning'},\n",
       " 'H1_QSDqxl': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '637',\n",
       "  'title': 'Rule Mining in Feature Space'},\n",
       " 'H1acq85gx': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [9, 6, 6],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '416',\n",
       "  'title': 'Maximum Entropy Flow Networks'},\n",
       " 'H1fl8S9ee': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '440',\n",
       "  'title': 'Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks'},\n",
       " 'H1hoFU9xe': {'RECOMMENDATION': [5, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '664',\n",
       "  'title': 'Generative Adversarial Networks for Image Steganography'},\n",
       " 'H1kjdOYlx': {'RECOMMENDATION': [3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '542',\n",
       "  'title': 'Modular Multitask Reinforcement Learning with Policy Sketches'},\n",
       " 'H1oRQDqlg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '518',\n",
       "  'title': 'Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning'},\n",
       " 'H1oyRlYgg': {'CLARITY': [4],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 10, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '315',\n",
       "  'title': 'On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima'},\n",
       " 'H1wgawqxl': {'RECOMMENDATION': [6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '512',\n",
       "  'title': 'Nonparametrically Learning Activation Functions in Deep Neural Nets'},\n",
       " 'H1zJ-v5xl': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3],\n",
       "  'SUBSTANCE': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '404',\n",
       "  'title': 'Quasi-Recurrent Neural Networks'},\n",
       " 'HJ0NvFzxl': {'CLARITY': [5],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'RECOMMENDATION': [9, 9, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '318',\n",
       "  'title': 'Learning Graphical State Transitions'},\n",
       " 'HJ1kmv9xx': {'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5, 4],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '396',\n",
       "  'title': 'LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation'},\n",
       " 'HJ5PIaseg': {'RECOMMENDATION': [4, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '502',\n",
       "  'title': 'Towards an automatic Turing test: Learning to evaluate dialogue responses'},\n",
       " 'HJ6idTdgg': {'RECOMMENDATION': [3, 2, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '766',\n",
       "  'title': 'Pedestrian Detection Based On Fast R-CNN and Batch Normalization '},\n",
       " 'HJ7O61Yxe': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '763',\n",
       "  'title': 'Modelling Relational Time Series using Gaussian Embeddings'},\n",
       " 'HJ9rLLcxg': {'RECOMMENDATION': [7, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '524',\n",
       "  'title': 'Dataset Augmentation in Feature Space'},\n",
       " 'HJDBUF5le': {'CLARITY': [3],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 8, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '358',\n",
       "  'title': 'Towards a Neural Statistician'},\n",
       " 'HJF3iD9xe': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '514',\n",
       "  'title': 'Deep Learning with Sets and Point Clouds'},\n",
       " 'HJGODLqgx': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '421',\n",
       "  'title': 'Recurrent Hidden Semi-Markov Model'},\n",
       " 'HJGwcKclx': {'CLARITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '345',\n",
       "  'title': 'Soft Weight-Sharing for Neural Network Compression'},\n",
       " 'HJIY0E9ge': {'RECOMMENDATION': [3, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '695',\n",
       "  'title': 'A Simple yet Effective Method to Prune Dense Layers of Neural Networks'},\n",
       " 'HJOZBvcel': {'RECOMMENDATION': [5, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '517',\n",
       "  'title': 'Learning to Discover Sparse Graphical Models'},\n",
       " 'HJPmdP9le': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '630',\n",
       "  'title': 'Efficient Summarization with Read-Again and Copy Mechanism'},\n",
       " 'HJSCGD9ex': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '640',\n",
       "  'title': 'Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context'},\n",
       " 'HJTXaw9gx': {'RECOMMENDATION': [5, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '511',\n",
       "  'title': 'Recursive Regression with Neural Networks: Approximating the HJI PDE Solution'},\n",
       " 'HJTzHtqee': {'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '363',\n",
       "  'title': 'A Compare-Aggregate Model for Matching Text Sequences'},\n",
       " 'HJV1zP5xg': {'RECOMMENDATION': [4, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '644',\n",
       "  'title': 'Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models'},\n",
       " 'HJWzXsKxx': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '738',\n",
       "  'title': 'Training Long Short-Term Memory With Sparsified Stochastic Gradient Descent'},\n",
       " 'HJcLcw9xg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '626',\n",
       "  'title': 'The Preimage of Rectifier Network Activities'},\n",
       " 'HJeqWztlg': {'RECOMMENDATION': [5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '760',\n",
       "  'title': 'Hierarchical compositional feature learning'},\n",
       " 'HJgXCV9xx': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '445',\n",
       "  'title': 'Dialogue Learning With Human-in-the-Loop'},\n",
       " 'HJhcg6Fxg': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '731',\n",
       "  'title': 'Binary Paragraph Vectors'},\n",
       " 'HJlgm-B9lx': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '692',\n",
       "  'title': 'Learning to Understand: Incorporating Local Contexts with Global Attention for Sentiment Classification'},\n",
       " 'HJrDIpiee': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '554',\n",
       "  'title': 'Investigating Recurrence and Eligibility Traces in Deep Q-Networks'},\n",
       " 'HJtN5K9gx': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '593',\n",
       "  'title': 'Learning Disentangled Representations in Deep Generative Models'},\n",
       " 'HJy_5Mcll': {'RECOMMENDATION': [4, 5, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '716',\n",
       "  'title': 'ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation'},\n",
       " 'Hk-mgcsgx': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '567',\n",
       "  'title': 'An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views'},\n",
       " 'Hk1iOLcle': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '665',\n",
       "  'title': 'MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset'},\n",
       " 'Hk1l9Xqxe': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '710',\n",
       "  'title': 'BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL'},\n",
       " 'Hk3mPK5gg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [6, 7, 4],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '355',\n",
       "  'title': 'Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning'},\n",
       " 'Hk4_qw5xe': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [4, 3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '308',\n",
       "  'title': 'Towards Principled Methods for Training Generative Adversarial Networks'},\n",
       " 'Hk4kQHceg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '527',\n",
       "  'title': 'Multiplicative LSTM for sequence modelling'},\n",
       " 'Hk6a8N5xe': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '702',\n",
       "  'title': 'Classify or Select: Neural Architectures for Extractive Document Summarization'},\n",
       " 'Hk85q85ee': {'RECOMMENDATION': [4, 8, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '522',\n",
       "  'title': 'Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity'},\n",
       " 'Hk8N3Sclg': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [5, 3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '310',\n",
       "  'title': 'Multi-Agent Cooperation and the Emergence of (Natural) Language'},\n",
       " 'Hk8TGSKlg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '479',\n",
       "  'title': 'Reasoning with Memory Augmented Neural Networks for Language Comprehension'},\n",
       " 'Hk8rlUqge': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '672',\n",
       "  'title': 'Joint Multimodal Learning with Deep Generative Models'},\n",
       " 'HkCjNI5ex': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '668',\n",
       "  'title': 'Regularizing Neural Networks by Penalizing Confident Output Distributions'},\n",
       " 'HkE0Nvqlg': {'CLARITY': [3],\n",
       "  'IMPACT': [1, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2, 2],\n",
       "  'SUBSTANCE': [1],\n",
       "  'dec': True,\n",
       "  'pr_id': '393',\n",
       "  'title': 'Structured Attention Networks'},\n",
       " 'HkEI22jeg': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [8, 7, 4],\n",
       "  'SOUNDNESS_CORRECTNESS': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '328',\n",
       "  'title': 'Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses'},\n",
       " 'HkIQH7qel': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '711',\n",
       "  'title': 'Learning Recurrent Span Representations for Extractive Question Answering'},\n",
       " 'HkJq1Ocxl': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '509',\n",
       "  'title': 'Programming With a Differentiable Forth Interpreter'},\n",
       " 'HkNEuToge': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '549',\n",
       "  'title': 'Energy-Based Spherical Sparse Coding'},\n",
       " 'HkNRsU5ge': {'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [1],\n",
       "  'RECOMMENDATION': [8, 6, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '413',\n",
       "  'title': 'Sigma Delta Quantized Networks'},\n",
       " 'HkSOlP9lg': {'RECOMMENDATION': [4, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '647',\n",
       "  'title': 'Recurrent Inference Machines for Solving Inverse Problems'},\n",
       " 'HkYhZDqxg': {'CLARITY': [2, 5],\n",
       "  'IMPACT': [1],\n",
       "  'MEANINGFUL_COMPARISON': [1, 2],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '400',\n",
       "  'title': 'Tree-structured decoding with doubly-recurrent neural networks'},\n",
       " 'HkcdHtqlx': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '602',\n",
       "  'title': 'Gated-Attention Readers for Text Comprehension'},\n",
       " 'Hkg4TI9xl': {'IMPACT': [2],\n",
       "  'MEANINGFUL_COMPARISON': [4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '410',\n",
       "  'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks'},\n",
       " 'Hkg8bDqee': {'CLARITY': [5],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 9, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '401',\n",
       "  'title': 'Introspection:Accelerating Neural Network Training By Learning Weight Evolution'},\n",
       " 'HkljfjFee': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '472',\n",
       "  'title': 'Support Regularized Sparse Coding and Its Fast Encoder'},\n",
       " 'HkpLeH9el': {'RECOMMENDATION': [6, 7, 4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '528',\n",
       "  'title': 'Neural Functional Programming'},\n",
       " 'HkpbnH9lx': {'RECOMMENDATION': [7, 8, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '433',\n",
       "  'title': 'Density estimation using Real NVP'},\n",
       " 'Hku9NK5lx': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [9, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '365',\n",
       "  'title': 'Training Compressed Fully-Connected Networks with a Density-Diversity Penalty'},\n",
       " 'HkuVu3ige': {'RECOMMENDATION': [7, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '560',\n",
       "  'title': 'On orthogonality and learning recurrent networks with long term dependencies'},\n",
       " 'HkvS3Mqxe': {'RECOMMENDATION': [5, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '715',\n",
       "  'title': 'Coarse Pruning of Convolutional Neural Networks with Random Masks'},\n",
       " 'HkwoSDPgg': {'APPROPRIATENESS': [5],\n",
       "  'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4, 5],\n",
       "  'ORIGINALITY': [5, 5, 5],\n",
       "  'RECOMMENDATION': [9, 9, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '316',\n",
       "  'title': 'Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data'},\n",
       " 'HkxAAvcxx': {'RECOMMENDATION': [3, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '612',\n",
       "  'title': 'Transformation-based Models of Video Sequences'},\n",
       " 'HkyYqU9lx': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '659',\n",
       "  'title': 'Sequence to Sequence Transduction with Hard Monotonic Attention'},\n",
       " 'HkzuKpLgg': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '780',\n",
       "  'title': 'Efficient Communications in Training Large Scale Neural Networks'},\n",
       " 'Hy-2G6ile': {'RECOMMENDATION': [6, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '503',\n",
       "  'title': 'Gated Multimodal Units for Information Fusion'},\n",
       " 'Hy-lMNqex': {'RECOMMENDATION': [6, 4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '703',\n",
       "  'title': 'Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability'},\n",
       " 'Hy0L4t5el': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '605',\n",
       "  'title': 'Tree-Structured Variational Autoencoder'},\n",
       " 'Hy3_KuYxg': {'RECOMMENDATION': [4, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '746',\n",
       "  'title': 'Divide and Conquer with Neural Networks'},\n",
       " 'Hy6b4Pqee': {'CLARITY': [1, 3],\n",
       "  'IMPACT': [3, 4],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [8, 5, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '395',\n",
       "  'title': 'Deep Probabilistic Programming'},\n",
       " 'HyAbMKwxe': {'RECOMMENDATION': [8, 4, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '493',\n",
       "  'title': 'Tighter bounds lead to improved classifiers'},\n",
       " 'HyAddcLge': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '783',\n",
       "  'title': 'Revisiting Distributed Synchronous SGD'},\n",
       " 'HyCRyS9gx': {'RECOMMENDATION': [5, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '693',\n",
       "  'title': 'Fast Adaptation in Generative Models with Generative Matching Networks'},\n",
       " 'HyET6tYex': {'RECOMMENDATION': [5, 5, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '743',\n",
       "  'title': 'Universality in halting time'},\n",
       " 'HyGTuv9eg': {'CLARITY': [3],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4, 5],\n",
       "  'RECOMMENDATION': [5, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5],\n",
       "  'SUBSTANCE': [3, 2, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '387',\n",
       "  'title': 'Incorporating long-range consistency in CNN-based texture generation'},\n",
       " 'HyM25Mqel': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '460',\n",
       "  'title': 'Sample Efficient Actor-Critic with  Experience Replay'},\n",
       " 'HyNxRZ9xg': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '720',\n",
       "  'title': 'Cat2Vec: Learning Distributed Representation of Multi-field Categorical Data'},\n",
       " 'HyQJ-mclg': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '457',\n",
       "  'title': 'Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights'},\n",
       " 'HyTqHL5xg': {'IMPACT': [2, 3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [6, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [1, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '422',\n",
       "  'title': 'Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data'},\n",
       " 'HyWDCXjgx': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '574',\n",
       "  'title': 'Multi-label learning with the RNNs for Fashion Search'},\n",
       " 'HyWG0H5ge': {'RECOMMENDATION': [7, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '526',\n",
       "  'title': 'Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks'},\n",
       " 'HyWWpw5ex': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '614',\n",
       "  'title': 'Recurrent Coevolutionary Feature Embedding Processes for Recommendation'},\n",
       " 'HyY4Owjll': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '571',\n",
       "  'title': 'Boosted Generative Models'},\n",
       " 'Hyanrrqlg': {'RECOMMENDATION': [5, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '686',\n",
       "  'title': 'HFH: Homologically Functional Hashing for Compressing Deep Neural Networks'},\n",
       " 'HycUbvcge': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '645',\n",
       "  'title': 'Deep Generalized Canonical Correlation Analysis'},\n",
       " 'HyecJGP5ge': {'RECOMMENDATION': [5, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '643',\n",
       "  'title': 'NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD'},\n",
       " 'HyoST_9xl': {'CLARITY': [4, 4],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [5, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '370',\n",
       "  'title': 'DSD: Dense-Sparse-Dense Training for Deep Neural Networks'},\n",
       " 'Hyq4yhile': {'CLARITY': [5],\n",
       "  'IMPACT': [4, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '331',\n",
       "  'title': 'Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning'},\n",
       " 'HysBZSqlx': {'RECOMMENDATION': [5, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '691',\n",
       "  'title': 'Playing SNES in the Retro Learning Environment'},\n",
       " 'Hyvw0L9el': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '520',\n",
       "  'title': 'Generating Interpretable Images with Controllable Structure'},\n",
       " 'HyxQzBceg': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '442',\n",
       "  'title': 'Deep Variational Information Bottleneck'},\n",
       " 'S11KBYclx': {'APPROPRIATENESS': [5],\n",
       "  'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [3, 2, 3],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '361',\n",
       "  'title': 'Learning Curve Prediction with Bayesian Neural Networks'},\n",
       " 'S13wCE9xx': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '697',\n",
       "  'title': 'Riemannian Optimization for Skip-Gram Negative Sampling'},\n",
       " 'S19eAF9ee': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '589',\n",
       "  'title': 'Structured Sequence Modeling with Graph Convolutional Recurrent Networks'},\n",
       " 'S1Bb3D5gg': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [8, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '307',\n",
       "  'title': 'Learning End-to-End Goal-Oriented Dialog'},\n",
       " 'S1Bm3T_lg': {'RECOMMENDATION': [6, 5, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '545',\n",
       "  'title': 'Compositional Kernel Machines'},\n",
       " 'S1HEBe_Jl': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '790',\n",
       "  'title': 'Learning to Protect Communications with Adversarial Neural Cryptography'},\n",
       " 'S1HcOI5le': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '666',\n",
       "  'title': 'OMG: Orthogonal Method of Grouping With Application of K-Shot Learning'},\n",
       " 'S1J0E-71l': {'RECOMMENDATION': [3, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '793',\n",
       "  'title': 'Surprisal-Driven Feedback in Recurrent Networks'},\n",
       " 'S1JG13oee': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '563',\n",
       "  'title': 'b-GAN: Unified Framework of Generative Adversarial Networks'},\n",
       " 'S1LVSrcge': {'RECOMMENDATION': [7, 7, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '441',\n",
       "  'title': 'Variable Computation in Recurrent Neural Networks'},\n",
       " 'S1QefL5ge': {'RECOMMENDATION': [6, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '525',\n",
       "  'title': 'Online Structure Learning for Sum-Product Networks with Gaussian Leaves'},\n",
       " 'S1RP6GLle': {'CLARITY': [5, 4],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '317',\n",
       "  'title': 'Amortised MAP Inference for Image Super-resolution'},\n",
       " 'S1VaB4cex': {'RECOMMENDATION': [6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '449',\n",
       "  'title': 'FractalNet: Ultra-Deep Neural Networks without Residuals'},\n",
       " 'S1X7nhsxl': {'CLARITY': [5, 3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '329',\n",
       "  'title': 'Improving Generative Adversarial Networks with Denoising Feature Matching'},\n",
       " 'S1Y0td9ee': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '508',\n",
       "  'title': 'Shift Aggregate Extract Networks'},\n",
       " 'S1_pAu9xl': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [7, 7, 3, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '369',\n",
       "  'title': 'Trained Ternary Quantization'},\n",
       " 'S1c2cvqee': {'APPROPRIATENESS': [3],\n",
       "  'CLARITY': [5, 4],\n",
       "  'IMPACT': [4, 2],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [3, 5, 3],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '383',\n",
       "  'title': 'Designing Neural Network Architectures using Reinforcement Learning'},\n",
       " 'S1dIzvclg': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [5, 4, 3],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '398',\n",
       "  'title': 'A recurrent neural network without chaos'},\n",
       " 'S1di0sfgl': {'RECOMMENDATION': [8, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '496',\n",
       "  'title': 'Hierarchical Multiscale Recurrent Neural Networks'},\n",
       " 'S1j4RqYxg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '739',\n",
       "  'title': 'Efficient Calculation of Polynomial Features on Sparse Matrices'},\n",
       " 'S1jmAotxg': {'RECOMMENDATION': [8, 4, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '470',\n",
       "  'title': 'Stick-Breaking Variational Autoencoders'},\n",
       " 'S1oWlN9ll': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '453',\n",
       "  'title': 'Loss-aware Binarization of Deep Networks'},\n",
       " 'S1vyujVye': {'RECOMMENDATION': [7, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '791',\n",
       "  'title': 'Deep unsupervised learning through spatial contrasting'},\n",
       " 'S1xh5sYgx': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '737',\n",
       "  'title': 'SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size'},\n",
       " 'SJ-uGHcee': {'RECOMMENDATION': [5, 3, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '688',\n",
       "  'title': 'Efficient iterative policy optimization'},\n",
       " 'SJ25-B5eg': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '443',\n",
       "  'title': 'The Neural Noisy Channel'},\n",
       " 'SJ6yPD5xg': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '309',\n",
       "  'title': 'Reinforcement Learning with Unsupervised Auxiliary Tasks'},\n",
       " 'SJAr0QFxe': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '755',\n",
       "  'title': 'Demystifying ResNet'},\n",
       " 'SJBr9Mcxl': {'RECOMMENDATION': [7, 3, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '717',\n",
       "  'title': 'Understanding trained CNNs by indexing neuron selectivity'},\n",
       " 'SJCscQcge': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '708',\n",
       "  'title': 'Simple Black-Box Adversarial Perturbations for Deep Networks'},\n",
       " 'SJGCiw5gl': {'IMPACT': [4],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [9, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '381',\n",
       "  'title': 'Pruning Convolutional Neural Networks for Resource Efficient Inference'},\n",
       " 'SJIMPr9eg': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '683',\n",
       "  'title': 'Boosted Residual Networks'},\n",
       " 'SJJKxrsgl': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [6, 5, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '334',\n",
       "  'title': 'Emergence of foveal image sampling from learning to attend in visual scenes'},\n",
       " 'SJJN38cge': {'RECOMMENDATION': [3, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '655',\n",
       "  'title': 'Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment'},\n",
       " 'SJMGPrcle': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '438',\n",
       "  'title': 'Learning to Navigate in Complex Environments'},\n",
       " 'SJNDWNOlg': {'RECOMMENDATION': [3, 3, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '772',\n",
       "  'title': 'What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?'},\n",
       " 'SJQNqLFgl': {'RECOMMENDATION': [4, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '749',\n",
       "  'title': 'Deep Convolutional Neural Network Design Patterns'},\n",
       " 'SJRpRfKxx': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '483',\n",
       "  'title': 'Recurrent Mixture Density Network for Spatiotemporal Visual Attention'},\n",
       " 'SJTQLdqlg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [8, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '372',\n",
       "  'title': 'Learning to Remember Rare Events'},\n",
       " 'SJU4ayYgl': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '486',\n",
       "  'title': 'Semi-Supervised Classification with Graph Convolutional Networks'},\n",
       " 'SJZAb5cel': {'RECOMMENDATION': [5, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '584',\n",
       "  'title': 'A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks'},\n",
       " 'SJ_QCYqle': {'RECOMMENDATION': [6, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '588',\n",
       "  'title': 'Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets'},\n",
       " 'SJc1hL5ee': {'RECOMMENDATION': [6, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '657',\n",
       "  'title': 'FastText.zip: Compressing text classification models'},\n",
       " 'SJg498clg': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '661',\n",
       "  'title': 'Neural Graph Machines: Learning Neural Networks Using Graphs'},\n",
       " 'SJiFvr9el': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '681',\n",
       "  'title': 'Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants'},\n",
       " 'SJk01vogl': {'RECOMMENDATION': [5, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '572',\n",
       "  'title': 'Adversarial examples for generative models'},\n",
       " 'SJkXfE5xx': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '450',\n",
       "  'title': 'Revisiting Classifier Two-Sample Tests'},\n",
       " 'SJttqw5ge': {'RECOMMENDATION': [4, 5, 7, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '625',\n",
       "  'title': 'Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization'},\n",
       " 'SJvYgH9xe': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '444',\n",
       "  'title': 'Automatic Rule Extraction from Long Short Term Memory Networks'},\n",
       " 'SJzCSf9xg': {'RECOMMENDATION': [7, 5, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '462',\n",
       "  'title': 'On Detecting Adversarial Perturbations'},\n",
       " 'Sk-oDY9ge': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [2, 4],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '351',\n",
       "  'title': 'Diet Networks: Thin Parameters for Fat Genomics'},\n",
       " 'Sk2Im59ex': {'CLARITY': [4],\n",
       "  'IMPACT': [4, 2],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '340',\n",
       "  'title': 'Unsupervised Cross-Domain Image Generation'},\n",
       " 'Sk2iistgg': {'RECOMMENDATION': [3, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '735',\n",
       "  'title': 'Non-linear Dimensionality Regularizer for Solving Inverse Problems'},\n",
       " 'Sk36NgFeg': {'RECOMMENDATION': [4, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '762',\n",
       "  'title': 'Filling in the details: Perceiving from low fidelity visual input'},\n",
       " 'Sk8J83oee': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '562',\n",
       "  'title': 'Generative Adversarial Parallelization'},\n",
       " 'Sk8csP5ex': {'RECOMMENDATION': [7, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '622',\n",
       "  'title': 'The loss surface of residual networks: Ensembles and the role of batch normalization'},\n",
       " 'SkB-_mcel': {'RECOMMENDATION': [6, 9, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '456',\n",
       "  'title': 'Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning'},\n",
       " 'SkBsEQYll': {'RECOMMENDATION': [3, 3, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '756',\n",
       "  'title': 'Learning similarity preserving representations with neural similarity and context encoders'},\n",
       " 'SkCILwqex': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '634',\n",
       "  'title': 'Exploring LOTS in Deep Neural Networks'},\n",
       " 'SkJeEtclx': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '607',\n",
       "  'title': 'Memory-augmented Attention Modelling for Videos'},\n",
       " 'SkXIrV9le': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '531',\n",
       "  'title': 'Perception Updating Networks: On architectural constraints for interpretable video generative models'},\n",
       " 'SkYbF1slg': {'IMPACT': [4, 3],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '335',\n",
       "  'title': 'An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax'},\n",
       " 'SkgSXUKxx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '750',\n",
       "  'title': 'An Analysis of Feature Regularization for Low-shot Learning'},\n",
       " 'SkgewU5ll': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '667',\n",
       "  'title': 'GRAM: Graph-based Attention Model for Healthcare Representation Learning'},\n",
       " 'SkhU2fcll': {'RECOMMENDATION': [5, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '459',\n",
       "  'title': 'Deep Multi-task Representation Learning: A Tensor Factorisation Approach'},\n",
       " 'Skn9Shcxe': {'IMPACT': [5],\n",
       "  'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [7, 8, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '338',\n",
       "  'title': 'Highway and Residual Networks learn Unrolled Iterative Estimation'},\n",
       " 'SkpSlKIel': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '495',\n",
       "  'title': 'Why Deep Neural Networks for Function Approximation?'},\n",
       " 'Skq89Scxx': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '435',\n",
       "  'title': 'SGDR: Stochastic Gradient Descent with Warm Restarts'},\n",
       " 'SkqMSCHxe': {'RECOMMENDATION': [2, 2, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '785',\n",
       "  'title': 'PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING'},\n",
       " 'Sks3zF9eg': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '608',\n",
       "  'title': 'Taming the waves: sine as activation function in deep neural networks'},\n",
       " 'Sks9_ajex': {'CLARITY': [5, 5],\n",
       "  'MEANINGFUL_COMPARISON': [3, 5],\n",
       "  'ORIGINALITY': [2, 5, 2],\n",
       "  'RECOMMENDATION': [6, 6, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '319',\n",
       "  'title': 'Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer'},\n",
       " 'SkuqA_cgx': {'RECOMMENDATION': [5, 8, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '507',\n",
       "  'title': 'Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations'},\n",
       " 'Skvgqgqxe': {'RECOMMENDATION': [6, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '464',\n",
       "  'title': 'Learning to Compose Words into Sentences with Reinforcement Learning'},\n",
       " 'SkwSJ99ex': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '587',\n",
       "  'title': 'DeepRebirth: A General Approach for Accelerating Deep Neural Network Execution on Mobile Devices'},\n",
       " 'SkxKPDv5xl': {'APPROPRIATENESS': [4],\n",
       "  'CLARITY': [3],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [9, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '389',\n",
       "  'title': 'SampleRNN: An Unconditional End-to-End Neural Audio Generation Model'},\n",
       " 'SkyQWDcex': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '646',\n",
       "  'title': 'A Context-aware Attention Network for Interactive Question Answering'},\n",
       " 'Sy1rwtKxg': {'RECOMMENDATION': [4, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '745',\n",
       "  'title': 'Parallel Stochastic Gradient Descent with Sound Combiners'},\n",
       " 'Sy4tzwqxe': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '641',\n",
       "  'title': 'Two Methods for Wild Variational Inference'},\n",
       " 'Sy6iJDqlx': {'IMPACT': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '407',\n",
       "  'title': 'Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain'},\n",
       " 'Sy7m72Ogg': {'RECOMMENDATION': [3, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '767',\n",
       "  'title': 'An Actor-critic Algorithm for Learning Rate Learning'},\n",
       " 'SyCSsUDee': {'RECOMMENDATION': [3, 4, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '777',\n",
       "  'title': 'Semantic Noise Modeling for Better Representation Learning'},\n",
       " 'SyEiHNKxx': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '544',\n",
       "  'title': 'A Differentiable Physics Engine for Deep Learning in Robotics'},\n",
       " 'SyJNmVqgg': {'RECOMMENDATION': [6, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '532',\n",
       "  'title': 'Neural Data Filter for Bootstrapping Stochastic Gradient Descent'},\n",
       " 'SyK00v5xx': {'CLARITY': [5, 4],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 3],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '375',\n",
       "  'title': 'A Simple but Tough-to-Beat Baseline for Sentence Embeddings'},\n",
       " 'SyOvg6jxx': {'RECOMMENDATION': [6, 7, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '558',\n",
       "  'title': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning'},\n",
       " 'SyQq185lg': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '430',\n",
       "  'title': 'Latent Sequence Decompositions'},\n",
       " 'SyVVJ85lg': {'RECOMMENDATION': [7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '431',\n",
       "  'title': 'Paleo: A Performance Model for Deep Neural Networks'},\n",
       " 'SyW2QSige': {'RECOMMENDATION': [4, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '573',\n",
       "  'title': 'Towards Information-Seeking Agents'},\n",
       " 'SyWvgP5el': {'CLARITY': [2],\n",
       "  'IMPACT': [1, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [4, 3, 3],\n",
       "  'RECOMMENDATION': [7, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3, 2, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '406',\n",
       "  'title': 'EPOpt: Learning Robust Neural Network Policies Using Model Ensembles'},\n",
       " 'SyZprb5xg': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '536',\n",
       "  'title': 'On Robust Concepts and Small Neural Nets'},\n",
       " 'Syfkm6cgx': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '578',\n",
       "  'title': 'Improving Invariance and Equivariance Properties of Convolutional Neural Networks'},\n",
       " 'SygGlIBcel': {'RECOMMENDATION': [3, 4, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '685',\n",
       "  'title': 'Opening the vocabulary of  neural language models with character-level word representations'},\n",
       " 'SygvTcYee': {'RECOMMENDATION': [6, 6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '740',\n",
       "  'title': 'ParMAC: distributed optimisation of nested functions, with application to binary autoencoders'},\n",
       " 'Syoiqwcxx': {'RECOMMENDATION': [5, 3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '624',\n",
       "  'title': 'Local minima in training of deep networks'},\n",
       " 'SypU81Ole': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '774',\n",
       "  'title': 'Sampling Generative Networks'},\n",
       " 'Sys6GJqxl': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '465',\n",
       "  'title': 'Delving into Transferable Adversarial Examples and Black-box Attacks'},\n",
       " 'Sywh5KYex': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '744',\n",
       "  'title': 'Learning Identity Mappings with Residual Gates'},\n",
       " 'SyxeqhP9ll': {'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4, 4],\n",
       "  'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '380',\n",
       "  'title': 'Calibrating Energy-based Generative Adversarial Networks'},\n",
       " 'r10FA8Kxg': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '476',\n",
       "  'title': 'Do Deep Convolutional Nets Really Need to be Deep and Convolutional?'},\n",
       " 'r17RD2oxe': {'RECOMMENDATION': [4, 4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '561',\n",
       "  'title': 'Deep Neural Networks and the Tree of Life'},\n",
       " 'r1Aab85gg': {'IMPACT': [3, 3],\n",
       "  'ORIGINALITY': [4, 3],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [3, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '426',\n",
       "  'title': 'Offline bilingual word vectors, orthogonal transformations and the inverted softmax'},\n",
       " 'r1BJLw9ex': {'RECOMMENDATION': [6, 5, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '636',\n",
       "  'title': 'Adjusting for Dropout Variance in Batch Normalization and Weight Initialization'},\n",
       " 'r1Bjj8qge': {'RECOMMENDATION': [6, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '658',\n",
       "  'title': 'Encoding and Decoding Representations with Sum- and Max-Product Networks'},\n",
       " 'r1Chut9xl': {'RECOMMENDATION': [5, 5, 6, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '595',\n",
       "  'title': 'Inference and Introspection in Deep Generative Models of Sparse Data'},\n",
       " 'r1G4z8cge': {'CLARITY': [4, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [3, 4],\n",
       "  'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '424',\n",
       "  'title': 'Mollifying Networks'},\n",
       " 'r1GKzP5xx': {'RECOMMENDATION': [4, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '519',\n",
       "  'title': 'Recurrent Normalization Propagation'},\n",
       " 'r1IRctqxg': {'RECOMMENDATION': [7, 3, 2],\n",
       "  'dec': False,\n",
       "  'pr_id': '591',\n",
       "  'title': 'Sample Importance in Training Deep Neural Networks'},\n",
       " 'r1LXit5ee': {'CLARITY': [5],\n",
       "  'IMPACT': [5, 3],\n",
       "  'MEANINGFUL_COMPARISON': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '344',\n",
       "  'title': 'Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement'},\n",
       " 'r1PRvK9el': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '596',\n",
       "  'title': 'Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory'},\n",
       " 'r1S083cgx': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '581',\n",
       "  'title': 'Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks'},\n",
       " 'r1Ue8Hcxg': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [5],\n",
       "  'ORIGINALITY': [4, 2],\n",
       "  'RECOMMENDATION': [9, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '312',\n",
       "  'title': 'Neural Architecture Search with Reinforcement Learning'},\n",
       " 'r1Usiwcex': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '621',\n",
       "  'title': 'Counterpoint by Convolution'},\n",
       " 'r1VGvBcxl': {'RECOMMENDATION': [7, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '437',\n",
       "  'title': 'Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU'},\n",
       " 'r1VdcHcxx': {'RECOMMENDATION': [7, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '434',\n",
       "  'title': 'Recurrent Batch Normalization'},\n",
       " 'r1WUqIceg': {'RECOMMENDATION': [6, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '660',\n",
       "  'title': 'Improving Stochastic Gradient Descent with Feedback'},\n",
       " 'r1X3g2_xl': {'RECOMMENDATION': [6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '488',\n",
       "  'title': 'Adversarial Training Methods for Semi-Supervised Text Classification'},\n",
       " 'r1YNw6sxg': {'APPROPRIATENESS': [3, 2],\n",
       "  'CLARITY': [5, 2],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '320',\n",
       "  'title': 'Learning Visual Servoing with Deep Features and Fitted Q-Iteration'},\n",
       " 'r1aGWUqgg': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '670',\n",
       "  'title': 'Unsupervised Learning of State Representations for Multiple Tasks'},\n",
       " 'r1aPbsFle': {'RECOMMENDATION': [6, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '473',\n",
       "  'title': 'Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling'},\n",
       " 'r1fYuytex': {'RECOMMENDATION': [6, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '487',\n",
       "  'title': 'Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks'},\n",
       " 'r1kGbydxg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '775',\n",
       "  'title': 'Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space Matter?'},\n",
       " 'r1kQkVFgl': {'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '754',\n",
       "  'title': 'Learning Python Code Suggestion with a Sparse Pointer Network'},\n",
       " 'r1nTpv9eg': {'IMPACT': [4],\n",
       "  'RECOMMENDATION': [7, 6, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '377',\n",
       "  'title': 'Learning to Perform Physics Experiments via Deep Reinforcement Learning'},\n",
       " 'r1osyr_xg': {'RECOMMENDATION': [6, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '771',\n",
       "  'title': 'Fuzzy paraphrases in learning word representations with a lexicon'},\n",
       " 'r1rz6U5lg': {'ORIGINALITY': [4, 4],\n",
       "  'RECOMMENDATION': [6, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'dec': True,\n",
       "  'pr_id': '411',\n",
       "  'title': 'Learning to superoptimize programs'},\n",
       " 'r1tHvHKge': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '751',\n",
       "  'title': \"Combating Deep Reinforcement Learning's Sisyphean Curse with Intrinsic Fear\"},\n",
       " 'r1te3Fqel': {'RECOMMENDATION': [6, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '590',\n",
       "  'title': 'End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension'},\n",
       " 'r1w7Jdqxl': {'RECOMMENDATION': [4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '611',\n",
       "  'title': 'Collaborative Deep Embedding via Dual Networks'},\n",
       " 'r1xUYDYgg': {'RECOMMENDATION': [7, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '543',\n",
       "  'title': 'Development of JavaScript-based deep learning platform and application to distributed training'},\n",
       " 'r1y1aawlg': {'RECOMMENDATION': [7, 4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '776',\n",
       "  'title': 'Iterative Refinement for Machine Translation'},\n",
       " 'r1yjkAtxe': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '728',\n",
       "  'title': 'Spatio-Temporal Abstractions in Reinforcement Learning Through Neural Encoding'},\n",
       " 'rJ0-tY5xe': {'APPROPRIATENESS': [2],\n",
       "  'CLARITY': [5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '349',\n",
       "  'title': 'Learning to Query, Reason, and Answer Questions On Ambiguous Texts'},\n",
       " 'rJ0JwFcex': {'APPROPRIATENESS': [1],\n",
       "  'CLARITY': [4],\n",
       "  'IMPACT': [4, 2, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 2],\n",
       "  'ORIGINALITY': [4, 4, 2],\n",
       "  'RECOMMENDATION': [7, 8, 5],\n",
       "  'SUBSTANCE': [2, 1],\n",
       "  'dec': True,\n",
       "  'pr_id': '356',\n",
       "  'title': 'Neuro-Symbolic Program Synthesis'},\n",
       " 'rJ6DhP5xe': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '513',\n",
       "  'title': 'Generalizable Features From Unsupervised Learning'},\n",
       " 'rJ8uNptgl': {'RECOMMENDATION': [7, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '468',\n",
       "  'title': 'Towards the Limit of Network Quantization'},\n",
       " 'rJEgeXFex': {'RECOMMENDATION': [8, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '482',\n",
       "  'title': 'Predicting Medications from Diagnostic Codes with Recurrent Neural Networks'},\n",
       " 'rJJ3YU5ge': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '663',\n",
       "  'title': 'Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce'},\n",
       " 'rJJRDvcex': {'RECOMMENDATION': [7, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '631',\n",
       "  'title': 'Layer Recurrent Neural Networks'},\n",
       " 'rJLS7qKel': {'CLARITY': [4, 5],\n",
       "  'IMPACT': [3],\n",
       "  'MEANINGFUL_COMPARISON': [2],\n",
       "  'ORIGINALITY': [5, 4, 4],\n",
       "  'RECOMMENDATION': [8, 7, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 4],\n",
       "  'SUBSTANCE': [3, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '314',\n",
       "  'title': 'Learning to Act by Predicting the Future'},\n",
       " 'rJM69B5xx': {'RECOMMENDATION': [4, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '678',\n",
       "  'title': 'Finding a Jack-of-All-Trades: An Examination of Semi-supervised Learning in Reading Comprehension'},\n",
       " 'rJPcZ3txx': {'RECOMMENDATION': [6, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '469',\n",
       "  'title': 'Faster CNNs with Direct Sparse Convolutions and Guided Pruning'},\n",
       " 'rJQKYt5ll': {'CLARITY': [3, 3],\n",
       "  'IMPACT': [5],\n",
       "  'MEANINGFUL_COMPARISON': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 8],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '348',\n",
       "  'title': 'Steerable CNNs'},\n",
       " 'rJY0-Kcll': {'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [5, 4, 5],\n",
       "  'RECOMMENDATION': [6, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [3, 3],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '306',\n",
       "  'title': 'Optimization as a Model for Few-Shot Learning'},\n",
       " 'rJY3vK9eg': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '597',\n",
       "  'title': 'Neural Combinatorial Optimization with Reinforcement Learning'},\n",
       " 'rJbPBt9lg': {'RECOMMENDATION': [5, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '603',\n",
       "  'title': 'Neural Code Completion'},\n",
       " 'rJbbOLcex': {'CLARITY': [3, 3],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [8, 6, 7],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '419',\n",
       "  'title': 'TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency'},\n",
       " 'rJe-Pr9le': {'RECOMMENDATION': [2, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '684',\n",
       "  'title': 'Multi-task learning with deep model based reinforcement learning'},\n",
       " 'rJeKjwvclx': {'CLARITY': [5, 5, 5],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '388',\n",
       "  'title': 'Dynamic Coattention Networks For Question Answering'},\n",
       " 'rJfMusFll': {'RECOMMENDATION': [8, 6, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '471',\n",
       "  'title': 'Batch Policy Gradient  Methods for  Improving Neural Conversation Models'},\n",
       " 'rJg_1L5gg': {'RECOMMENDATION': [5, 5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '675',\n",
       "  'title': 'Incremental Sequence Learning'},\n",
       " 'rJiNwv9gg': {'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [5, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'SUBSTANCE': [4],\n",
       "  'dec': True,\n",
       "  'pr_id': '392',\n",
       "  'title': 'Lossy Image Compression with Compressive Autoencoders'},\n",
       " 'rJo9n9Feg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '741',\n",
       "  'title': 'Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe'},\n",
       " 'rJqBEPcxe': {'CLARITY': [5, 2],\n",
       "  'IMPACT': [2, 2, 2],\n",
       "  'MEANINGFUL_COMPARISON': [2, 1],\n",
       "  'ORIGINALITY': [4, 1, 2],\n",
       "  'RECOMMENDATION': [7, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [2, 2, 2],\n",
       "  'dec': True,\n",
       "  'pr_id': '394',\n",
       "  'title': 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations'},\n",
       " 'rJqFGTslg': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [3],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [7, 6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '324',\n",
       "  'title': 'Pruning Filters for Efficient ConvNets'},\n",
       " 'rJq_YBqxx': {'RECOMMENDATION': [6, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '680',\n",
       "  'title': 'Deep Character-Level Neural Machine Translation By Learning Morphology'},\n",
       " 'rJsiFTYex': {'RECOMMENDATION': [5, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '730',\n",
       "  'title': 'A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs'},\n",
       " 'rJxDkvqee': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [2],\n",
       "  'RECOMMENDATION': [6, 5, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'SUBSTANCE': [5, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '408',\n",
       "  'title': 'Multi-view Recurrent Neural Acoustic Word Embeddings'},\n",
       " 'rJxdQ3jeg': {'CLARITY': [5, 3],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [5, 4],\n",
       "  'RECOMMENDATION': [8, 8, 8, 9],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 4],\n",
       "  'dec': True,\n",
       "  'pr_id': '305',\n",
       "  'title': 'End-to-end Optimized Image Compression'},\n",
       " 'rJzaDdYxx': {'RECOMMENDATION': [5, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '747',\n",
       "  'title': 'Gradients of Counterfactuals'},\n",
       " 'rk9eAFcxg': {'APPROPRIATENESS': [3, 1],\n",
       "  'CLARITY': [3],\n",
       "  'IMPACT': [4, 5],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [4],\n",
       "  'RECOMMENDATION': [5, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '342',\n",
       "  'title': 'Variational Recurrent Adversarial Deep Domain Adaptation'},\n",
       " 'rkE8pVcle': {'RECOMMENDATION': [8, 7, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '447',\n",
       "  'title': 'Learning through Dialogue Interactions by Asking Questions'},\n",
       " 'rkEFLFqee': {'CLARITY': [4],\n",
       "  'IMPACT': [4],\n",
       "  'MEANINGFUL_COMPARISON': [3],\n",
       "  'ORIGINALITY': [2, 2],\n",
       "  'RECOMMENDATION': [7, 6, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '357',\n",
       "  'title': 'Decomposing Motion and Content for Natural Video Sequence Prediction'},\n",
       " 'rkFBJv9gg': {'ORIGINALITY': [3],\n",
       "  'RECOMMENDATION': [6, 8, 6],\n",
       "  'SUBSTANCE': [3],\n",
       "  'dec': True,\n",
       "  'pr_id': '409',\n",
       "  'title': 'Learning Features of Music From Scratch'},\n",
       " 'rkFd2P5gl': {'RECOMMENDATION': [5, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '617',\n",
       "  'title': 'Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning'},\n",
       " 'rkGabzZgl': {'RECOMMENDATION': [8, 7, 8],\n",
       "  'dec': True,\n",
       "  'pr_id': '498',\n",
       "  'title': 'Dropout with Expectation-linear Regularization'},\n",
       " 'rkYmiD9lg': {'RECOMMENDATION': [7, 5, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '515',\n",
       "  'title': 'Exponential Machines'},\n",
       " 'rkaRFYcgl': {'RECOMMENDATION': [4, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '594',\n",
       "  'title': 'Low-rank passthrough neural networks'},\n",
       " 'rkjZ2Pcxe': {'RECOMMENDATION': [4, 4, 7],\n",
       "  'dec': False,\n",
       "  'pr_id': '619',\n",
       "  'title': 'Adding Gradient Noise Improves Learning for Very Deep Networks'},\n",
       " 'rkmDI85ge': {'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '523',\n",
       "  'title': 'Efficient Softmax Approximation for GPUs'},\n",
       " 'rkpACe1lx': {'RECOMMENDATION': [7, 8, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '499',\n",
       "  'title': 'HyperNetworks'},\n",
       " 'rkpdnIqlx': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '654',\n",
       "  'title': 'The Variational Walkback Algorithm'},\n",
       " 'rksfwnFxl': {'RECOMMENDATION': [8, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '733',\n",
       "  'title': 'LSTM-Based System-Call Language Modeling and Ensemble Method for Host-Based Intrusion Detection'},\n",
       " 'rkuDV6iex': {'RECOMMENDATION': [4, 6, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '556',\n",
       "  'title': 'An Empirical Analysis of Deep Network Loss Surfaces'},\n",
       " 'rky3QW9le': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '721',\n",
       "  'title': 'Transformational Sparse Coding'},\n",
       " 'ry18Ww5ee': {'CLARITY': [3],\n",
       "  'IMPACT': [4],\n",
       "  'ORIGINALITY': [4, 5],\n",
       "  'RECOMMENDATION': [8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [3],\n",
       "  'SUBSTANCE': [3, 3, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '402',\n",
       "  'title': 'Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization'},\n",
       " 'ry2YOrcge': {'RECOMMENDATION': [7, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '436',\n",
       "  'title': 'Learning a Natural Language Interface with Neural Programmer'},\n",
       " 'ry3iBFqgl': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '601',\n",
       "  'title': 'NEWSQA: A MACHINE COMPREHENSION DATASET'},\n",
       " 'ry4Vrt5gl': {'CLARITY': [5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [7, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '362',\n",
       "  'title': 'Learning to Optimize'},\n",
       " 'ry54RWtxx': {'RECOMMENDATION': [4, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '761',\n",
       "  'title': 'Learning a Static Analyzer: A Case Study on a Toy Language'},\n",
       " 'ryAe2WBee': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '787',\n",
       "  'title': 'Multi-label learning with semantic embeddings'},\n",
       " 'ryCcJaqgl': {'RECOMMENDATION': [5],\n",
       "  'dec': False,\n",
       "  'pr_id': '579',\n",
       "  'title': 'TreNet: Hybrid Neural Networks for Learning the Local Trend in Time Series'},\n",
       " 'ryEGFD9gl': {'RECOMMENDATION': [5, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '628',\n",
       "  'title': 'Submodular Sum-product Networks for Scene Understanding'},\n",
       " 'ryF7rTqgl': {'RECOMMENDATION': [4, 5, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '577',\n",
       "  'title': 'Understanding intermediate layers using linear classifier probes'},\n",
       " 'ryHlUtqge': {'CLARITY': [5, 5],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 7, 6],\n",
       "  'SOUNDNESS_CORRECTNESS': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '360',\n",
       "  'title': 'Generalizing Skills with Semi-Supervised Reinforcement Learning'},\n",
       " 'ryMxXPFex': {'RECOMMENDATION': [8, 8, 9],\n",
       "  'dec': True,\n",
       "  'pr_id': '475',\n",
       "  'title': 'Discrete Variational Autoencoders'},\n",
       " 'ryPx38qge': {'RECOMMENDATION': [7, 7, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '656',\n",
       "  'title': 'A hybrid network: Scattering and Convnet'},\n",
       " 'ryQbbFile': {'RECOMMENDATION': [4, 4, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '570',\n",
       "  'title': 'CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS'},\n",
       " 'ryT4pvqll': {'CLARITY': [4],\n",
       "  'IMPACT': [3],\n",
       "  'RECOMMENDATION': [8, 7, 7],\n",
       "  'SUBSTANCE': [2, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '378',\n",
       "  'title': 'Improving Policy Gradient by Exploring Under-appreciated Rewards'},\n",
       " 'ryT9R3Yxe': {'RECOMMENDATION': [2, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '732',\n",
       "  'title': 'Generative Paragraph Vector'},\n",
       " 'ryTYxh5ll': {'RECOMMENDATION': [3, 3, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '582',\n",
       "  'title': 'CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT IMAGES AND TEXT FOR THE TASK OF PRODUCT RECOMMENDATION'},\n",
       " 'ryUPiRvge': {'RECOMMENDATION': [7, 6, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '546',\n",
       "  'title': 'Extrapolation and learning equations'},\n",
       " 'ryWKREqxx': {'RECOMMENDATION': [6, 5, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '696',\n",
       "  'title': 'Emergent Predication Structure in Vector Representations of Neural Readers'},\n",
       " 'ryXZmzNeg': {'RECOMMENDATION': [3, 3, 3],\n",
       "  'dec': False,\n",
       "  'pr_id': '789',\n",
       "  'title': 'Improving Sampling from Generative Autoencoders with Markov Chains'},\n",
       " 'ryZqPN5xe': {'RECOMMENDATION': [6, 4, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '701',\n",
       "  'title': 'Beyond Fine Tuning: A Modular Approach to Learning on Small Data'},\n",
       " 'ry_4vpixl': {'RECOMMENDATION': [4, 4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '552',\n",
       "  'title': 'Rotation Plane Doubly Orthogonal Recurrent Neural Networks'},\n",
       " 'ry_sjFqgx': {'CLARITY': [5],\n",
       "  'RECOMMENDATION': [5, 8, 8],\n",
       "  'SOUNDNESS_CORRECTNESS': [4, 5],\n",
       "  'SUBSTANCE': [4, 3],\n",
       "  'dec': True,\n",
       "  'pr_id': '343',\n",
       "  'title': 'Program Synthesis for Character Level Language Modeling'},\n",
       " 'ryaFG5ige': {'RECOMMENDATION': [6, 6, 6],\n",
       "  'dec': False,\n",
       "  'pr_id': '566',\n",
       "  'title': 'Introducing Active Learning for CNN under the light of Variational Inference'},\n",
       " 'ryb-q1Olg': {'RECOMMENDATION': [4, 5, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '773',\n",
       "  'title': 'Rectified Factor Networks for Biclustering'},\n",
       " 'ryelgY5eg': {'CLARITY': [4],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [6, 7, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [2],\n",
       "  'SUBSTANCE': [5],\n",
       "  'dec': True,\n",
       "  'pr_id': '367',\n",
       "  'title': 'Optimal Binary Autoencoding with Pairwise Correlations'},\n",
       " 'ryh9pmcee': {'RECOMMENDATION': [7, 8, 7],\n",
       "  'dec': True,\n",
       "  'pr_id': '455',\n",
       "  'title': 'Energy-based Generative Adversarial Networks'},\n",
       " 'ryh_8f9lg': {'RECOMMENDATION': [5, 6, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '719',\n",
       "  'title': 'Classless Association using Neural Networks'},\n",
       " 'ryhqQFKgl': {'RECOMMENDATION': [8, 6, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '474',\n",
       "  'title': 'Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music'},\n",
       " 'ryjp1c9xg': {'RECOMMENDATION': [4, 5],\n",
       "  'dec': False,\n",
       "  'pr_id': '586',\n",
       "  'title': 'Extensions and Limitations of the Neural GPU'},\n",
       " 'ryrGawqex': {'CLARITY': [5, 5],\n",
       "  'IMPACT': [4, 5],\n",
       "  'MEANINGFUL_COMPARISON': [1],\n",
       "  'ORIGINALITY': [5],\n",
       "  'RECOMMENDATION': [8, 8, 7],\n",
       "  'SOUNDNESS_CORRECTNESS': [5, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '379',\n",
       "  'title': 'Deep Learning with Dynamic Computation Graphs'},\n",
       " 'ryuxYmvel': {'RECOMMENDATION': [8, 7, 6],\n",
       "  'dec': True,\n",
       "  'pr_id': '494',\n",
       "  'title': 'HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving'},\n",
       " 'rywUcQogx': {'RECOMMENDATION': [3, 3, 4],\n",
       "  'dec': False,\n",
       "  'pr_id': '575',\n",
       "  'title': 'Differentiable Canonical Correlation Analysis'},\n",
       " 'ryxB0Rtxx': {'RECOMMENDATION': [6, 8, 5],\n",
       "  'dec': True,\n",
       "  'pr_id': '466',\n",
       "  'title': 'Identity Matters in Deep Learning'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLARITY': [5],\n",
       " 'ORIGINALITY': [1],\n",
       " 'RECOMMENDATION': [6, 5],\n",
       " 'SOUNDNESS_CORRECTNESS': [4],\n",
       " 'dec': True,\n",
       " 'pr_id': '341',\n",
       " 'title': 'Third Person Imitation Learning'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_scores[\"B16dGcqlx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RECOMMENDATION': [6, 5], 'CLARITY': [5], 'dec': True, 'title': 'Third Person Imitation Learning', 'pr_id': '341', 'SOUNDNESS_CORRECTNESS': [4], 'ORIGINALITY': [1]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../features/rev_aspects_2017_peerread.pkl\", \"rb\") as f:\n",
    "    review_scores = pickle.load(f)\n",
    "\n",
    "for k in review_scores:\n",
    "#     print(k, review_scores[k])\n",
    "#     break\n",
    "    if k == \"B16dGcqlx\":\n",
    "        print(review_scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../reviewratings_iclr17_peeread.pkl\", \"rb\") as f:\n",
    "    rr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IS_META_REVIEW': True,\n",
       "  'comments': 'The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications.  The main insight is to use adversarial training to learn a policy that is robust to this difference in perspective.  This problem formulation is quite novel compared to the standard imitation learning literature (usually first-order perspective), though has close links to the literature on transfer learning (as explained in Sec.2).\\n\\nThe basic approach is clearly explained, and follows quite readily from recent literature on imitation learning and adversarial training.\\n\\nI would have expected to see comparison to the following methods added to Figure 3:\\n1)  Standard 1st person imitation learning using agent A data, and apply the policy on agent A.  This is an upper-bound on how well you can expect to do, since you have the correct perspective.\\n2)  Standard 1st person imitation learning using agent A data, then apply the policy on agent B.  Here, I expect it might do less well than 3rd person learning, but worth checking to be sure, and showing what is the gap in performance.\\n3)  Reinforcement learning using agent A data, and apply the policy on agent A.  I expect this might do better than 3rd person imitation learning but it might depend on the scenario (e.g. difficulty of imitation vs exploration; how different are the points of view between the agents). I understand this is how the expert data is collected for the demonstrator, but I dont see the performance results from just using this procedure on the learner (to compare to Fig.3 results).\\n\\nIncluding these results would in my view significantly enhance the impact of the paper.'},\n",
       " {'DATE': '06 Feb 2017',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 pcs',\n",
       "  'TITLE': 'ICLR committee final decision',\n",
       "  'comments': 'pros:\\n - new problem\\n - huge number of experimental evaluations, based in part on open-review comments\\n \\n cons:\\n - the main critiques related to not enough experiments being run; this has been addressed in the revised version\\n \\n The current reviewer scores do not yet reflect the many updates provided by the authors.\\n I therefore currently learn in favour of seeing this paper accepted.'},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'RECOMMENDATION': 5,\n",
       "  'REVIEWER_CONFIDENCE': 3,\n",
       "  'SOUNDNESS_CORRECTNESS': 4,\n",
       "  'TITLE': 'Interesting idea but need more experiments',\n",
       "  'comments': 'This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is used to extract a novice-expert (or third-person/first-person) independent feature so that the agent can use to perform the same policy in a different view point.\\n\\nWhile the idea is quite elegant and novel (I enjoy reading it), more experiments are needed to justify the approach. Probably the most important issue is that there is no baseline, e.g., what if we train the model with the image from the same viewpoint? It should be better than the proposed approach but how close are they? How the performance changes when we gradually change the viewpoint from third-person to first-person? Another important question is that maybe the network just blindly remembers the policy, in this case, the extracted feature could be artifacts of the input image that implicitly counts the time tick in some way (and thus domain-agonistic), but can still perform reasonable policy. Since the experiments are conduct in a synthetic environment, this might happen. An easy check is to run the algorithm on multiple viewpoint and/or with blurred/differently rendered images, and/or with random initial conditions.\\n\\nOther ablation analysis is also needed. For example, I am not fully convinced by the gradient flipping trick used in Eqn. 5, and in the experiments there is no ablation analysis for that (GAN/EM style training versus gradient flipping trick). For the experiments, Fig. 4,5,6 does not have error bars and is not very convincing.'},\n",
       " {'DATE': '16 Dec 2016',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer5',\n",
       "  'TITLE': 'Missing',\n",
       "  'comments': ''},\n",
       " {'DATE': '16 Dec 2016 (modified: 20 Jan 2017)',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer5',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Interesting idea for imitation learning. Paper could have been more general. ',\n",
       "  'comments': 'The paper presents an interesting new problem setup for imitation learning: an agent tries to imitate a trajectory demonstrated by an expert but said trajectory is demonstrated in a different state or observation space than the one accessible by the agent (although the dynamics of the underlying MDP are shared). The paper proposes a solution strategy that combines recent work on domain confusion losses with a recent IRL method based on generative adversarial networks.\\n\\nI believe the general problem to be relevant and agree with the authors that it results in a more natural formulation for imitation learning that might be more widely applicable.\\nThere are however a few issues with the paper in its current state that make the paper fall short of being a great exploration of a novel idea. I will list these concerns in the following (in arbitrary order)\\n- The paper feels at times to be a bit hurriedly written (this also mainly manifests itself in the experiments, see comment below) and makes a few fairly strong claims in the introduction that in my opinion are not backed up by their approach. For example: \"Advancements in this class of algorithms would significantly improve the state of robotics, because it will enable anyone to easily teach robots new skills\"; given that the current method to my understanding has the same issues that come with standard GAN training (e.g. instability etc.) and requires a very accurate simulator to work well (since TRPO will require a large number of simulated trajectories in each step) this seems like an overstatement.\\n  There are some sentences that are ungrammatical or switch tense in the middle of the sentence making the paper harder to read than necessary, e.g. Page 2: \"we find that this simple approach has been able to solve the problems\"\\n- The general idea of third person imitation learning is nice, clear and (at least to my understanding) also novel. However, instead of exploring how to generally adapt current IRL algorithms to this setting the authors pick a specific approach that they find promising (using GANs for IRL) and extend it. A significant amount of time is then spent on explaining why current IRL algorithms will fail in the third-person setting. I fail to see why the situation for the GAN based approach is any different than that of any other existing IRL algorithm. To be more clear: I see no reason why e.g. behavioral cloning could not be extended with a domain confusion loss in exactly the same way as the approach presented. To this end it would have been nice to rather discuss which algorithms can be adapted in the same way (and also test them) and which ones cannot. One straightforward approach to apply any IRL algorithm would for example be to train two autoencoders for both domains that share higher layers + a domain confusion loss on the highest layer, should that not result in features that are directly usable? If not, why?\\n- While the general argument that existing IRL algorithms will fail in the proposed setting seems reasonable it is still unfortunate that no attempts have been made to validate this empirically. No comparison is made regarding what happens when one e.g. performs supervised learning (behavioral cloning) using the expert observations and then transfers to the changed domain. How well would this work in practice ? Also, how fast can different IRL algorithms solve the target task in general (assuming a first person perspective) ?\\n- Although I like the idea of presenting the experiments as being directed towards answering a specific set of questions I feel like the posed questions somewhat distract from the main theme of the paper. Question 2 suddenly makes the use of additional velocity information to be a main point of importance and the experiments regarding Question 3 in the end only contain evaluations regarding two hyperparameters (ignoring all other parameters such as the parameters for TRPO, the number of rollouts per iteration, the number of presented expert episodes and  the design choices for the GAN). I understand that not all of these can be evaluated thoroughly in a conference paper but I feel like some more experiments or at least some discussion would have helped here.\\n- The presented experimental evaluation somewhat hides the cost of TRPO training with the obtained reward function. How many roll-outs are necessary in each step?\\n- The experiments lack some details: How are the expert trajectories obtained? The domains for the pendulum experiment seem identical except for coloring of the pole, is that correct (I am surprised this small change seems to have such a detrimental effect)? Figure 3 shows average performance over 5 trials, what about Figure 5 (if this is also average performance, what is the variance here)? Given that GANs are not easy to train, how often does the training fail/were you able to re-use the hyperparameters across all experiments?\\n\\nUPDATE:\\nI updated the score. Please see my response to the rebuttal below.\\n'},\n",
       " {'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 1,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Review',\n",
       "  'comments': 'The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications.  The main insight is to use adversarial training to learn a policy that is robust to this difference in perspective.  This problem formulation is quite novel compared to the standard imitation learning literature (usually first-order perspective), though has close links to the literature on transfer learning (as explained in Sec.2).\\n\\nThe basic approach is clearly explained, and follows quite readily from recent literature on imitation learning and adversarial training.\\n\\nI would have expected to see comparison to the following methods added to Figure 3:\\n1)  Standard 1st person imitation learning using agent A data, and apply the policy on agent A.  This is an upper-bound on how well you can expect to do, since you have the correct perspective.\\n2)  Standard 1st person imitation learning using agent A data, then apply the policy on agent B.  Here, I expect it might do less well than 3rd person learning, but worth checking to be sure, and showing what is the gap in performance.\\n3)  Reinforcement learning using agent A data, and apply the policy on agent A.  I expect this might do better than 3rd person imitation learning but it might depend on the scenario (e.g. difficulty of imitation vs exploration; how different are the points of view between the agents). I understand this is how the expert data is collected for the demonstrator, but I dont see the performance results from just using this procedure on the learner (to compare to Fig.3 results).\\n\\nIncluding these results would in my view significantly enhance the impact of the paper.'},\n",
       " {'DATE': '03 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 1,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'TITLE': 'Questions',\n",
       "  'comments': ''},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '02 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'SOUNDNESS_CORRECTNESS': 4,\n",
       "  'TITLE': 'Some questions.',\n",
       "  'comments': ''},\n",
       " {'IS_META_REVIEW': True,\n",
       "  'comments': 'The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications.  The main insight is to use adversarial training to learn a policy that is robust to this difference in perspective.  This problem formulation is quite novel compared to the standard imitation learning literature (usually first-order perspective), though has close links to the literature on transfer learning (as explained in Sec.2).\\n\\nThe basic approach is clearly explained, and follows quite readily from recent literature on imitation learning and adversarial training.\\n\\nI would have expected to see comparison to the following methods added to Figure 3:\\n1)  Standard 1st person imitation learning using agent A data, and apply the policy on agent A.  This is an upper-bound on how well you can expect to do, since you have the correct perspective.\\n2)  Standard 1st person imitation learning using agent A data, then apply the policy on agent B.  Here, I expect it might do less well than 3rd person learning, but worth checking to be sure, and showing what is the gap in performance.\\n3)  Reinforcement learning using agent A data, and apply the policy on agent A.  I expect this might do better than 3rd person imitation learning but it might depend on the scenario (e.g. difficulty of imitation vs exploration; how different are the points of view between the agents). I understand this is how the expert data is collected for the demonstrator, but I dont see the performance results from just using this procedure on the learner (to compare to Fig.3 results).\\n\\nIncluding these results would in my view significantly enhance the impact of the paper.'},\n",
       " {'DATE': '06 Feb 2017',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 pcs',\n",
       "  'TITLE': 'ICLR committee final decision',\n",
       "  'comments': 'pros:\\n - new problem\\n - huge number of experimental evaluations, based in part on open-review comments\\n \\n cons:\\n - the main critiques related to not enough experiments being run; this has been addressed in the revised version\\n \\n The current reviewer scores do not yet reflect the many updates provided by the authors.\\n I therefore currently learn in favour of seeing this paper accepted.'},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'RECOMMENDATION': 5,\n",
       "  'REVIEWER_CONFIDENCE': 3,\n",
       "  'SOUNDNESS_CORRECTNESS': 4,\n",
       "  'TITLE': 'Interesting idea but need more experiments',\n",
       "  'comments': 'This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is used to extract a novice-expert (or third-person/first-person) independent feature so that the agent can use to perform the same policy in a different view point.\\n\\nWhile the idea is quite elegant and novel (I enjoy reading it), more experiments are needed to justify the approach. Probably the most important issue is that there is no baseline, e.g., what if we train the model with the image from the same viewpoint? It should be better than the proposed approach but how close are they? How the performance changes when we gradually change the viewpoint from third-person to first-person? Another important question is that maybe the network just blindly remembers the policy, in this case, the extracted feature could be artifacts of the input image that implicitly counts the time tick in some way (and thus domain-agonistic), but can still perform reasonable policy. Since the experiments are conduct in a synthetic environment, this might happen. An easy check is to run the algorithm on multiple viewpoint and/or with blurred/differently rendered images, and/or with random initial conditions.\\n\\nOther ablation analysis is also needed. For example, I am not fully convinced by the gradient flipping trick used in Eqn. 5, and in the experiments there is no ablation analysis for that (GAN/EM style training versus gradient flipping trick). For the experiments, Fig. 4,5,6 does not have error bars and is not very convincing.'},\n",
       " {'DATE': '16 Dec 2016',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer5',\n",
       "  'TITLE': 'Missing',\n",
       "  'comments': ''},\n",
       " {'DATE': '16 Dec 2016 (modified: 20 Jan 2017)',\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer5',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Interesting idea for imitation learning. Paper could have been more general. ',\n",
       "  'comments': 'The paper presents an interesting new problem setup for imitation learning: an agent tries to imitate a trajectory demonstrated by an expert but said trajectory is demonstrated in a different state or observation space than the one accessible by the agent (although the dynamics of the underlying MDP are shared). The paper proposes a solution strategy that combines recent work on domain confusion losses with a recent IRL method based on generative adversarial networks.\\n\\nI believe the general problem to be relevant and agree with the authors that it results in a more natural formulation for imitation learning that might be more widely applicable.\\nThere are however a few issues with the paper in its current state that make the paper fall short of being a great exploration of a novel idea. I will list these concerns in the following (in arbitrary order)\\n- The paper feels at times to be a bit hurriedly written (this also mainly manifests itself in the experiments, see comment below) and makes a few fairly strong claims in the introduction that in my opinion are not backed up by their approach. For example: \"Advancements in this class of algorithms would significantly improve the state of robotics, because it will enable anyone to easily teach robots new skills\"; given that the current method to my understanding has the same issues that come with standard GAN training (e.g. instability etc.) and requires a very accurate simulator to work well (since TRPO will require a large number of simulated trajectories in each step) this seems like an overstatement.\\n  There are some sentences that are ungrammatical or switch tense in the middle of the sentence making the paper harder to read than necessary, e.g. Page 2: \"we find that this simple approach has been able to solve the problems\"\\n- The general idea of third person imitation learning is nice, clear and (at least to my understanding) also novel. However, instead of exploring how to generally adapt current IRL algorithms to this setting the authors pick a specific approach that they find promising (using GANs for IRL) and extend it. A significant amount of time is then spent on explaining why current IRL algorithms will fail in the third-person setting. I fail to see why the situation for the GAN based approach is any different than that of any other existing IRL algorithm. To be more clear: I see no reason why e.g. behavioral cloning could not be extended with a domain confusion loss in exactly the same way as the approach presented. To this end it would have been nice to rather discuss which algorithms can be adapted in the same way (and also test them) and which ones cannot. One straightforward approach to apply any IRL algorithm would for example be to train two autoencoders for both domains that share higher layers + a domain confusion loss on the highest layer, should that not result in features that are directly usable? If not, why?\\n- While the general argument that existing IRL algorithms will fail in the proposed setting seems reasonable it is still unfortunate that no attempts have been made to validate this empirically. No comparison is made regarding what happens when one e.g. performs supervised learning (behavioral cloning) using the expert observations and then transfers to the changed domain. How well would this work in practice ? Also, how fast can different IRL algorithms solve the target task in general (assuming a first person perspective) ?\\n- Although I like the idea of presenting the experiments as being directed towards answering a specific set of questions I feel like the posed questions somewhat distract from the main theme of the paper. Question 2 suddenly makes the use of additional velocity information to be a main point of importance and the experiments regarding Question 3 in the end only contain evaluations regarding two hyperparameters (ignoring all other parameters such as the parameters for TRPO, the number of rollouts per iteration, the number of presented expert episodes and  the design choices for the GAN). I understand that not all of these can be evaluated thoroughly in a conference paper but I feel like some more experiments or at least some discussion would have helped here.\\n- The presented experimental evaluation somewhat hides the cost of TRPO training with the obtained reward function. How many roll-outs are necessary in each step?\\n- The experiments lack some details: How are the expert trajectories obtained? The domains for the pendulum experiment seem identical except for coloring of the pole, is that correct (I am surprised this small change seems to have such a detrimental effect)? Figure 3 shows average performance over 5 trials, what about Figure 5 (if this is also average performance, what is the variance here)? Given that GANs are not easy to train, how often does the training fail/were you able to re-use the hyperparameters across all experiments?\\n\\nUPDATE:\\nI updated the score. Please see my response to the rebuttal below.\\n'},\n",
       " {'DATE': '16 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 1,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'RECOMMENDATION': 6,\n",
       "  'REVIEWER_CONFIDENCE': 4,\n",
       "  'TITLE': 'Review',\n",
       "  'comments': 'The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications.  The main insight is to use adversarial training to learn a policy that is robust to this difference in perspective.  This problem formulation is quite novel compared to the standard imitation learning literature (usually first-order perspective), though has close links to the literature on transfer learning (as explained in Sec.2).\\n\\nThe basic approach is clearly explained, and follows quite readily from recent literature on imitation learning and adversarial training.\\n\\nI would have expected to see comparison to the following methods added to Figure 3:\\n1)  Standard 1st person imitation learning using agent A data, and apply the policy on agent A.  This is an upper-bound on how well you can expect to do, since you have the correct perspective.\\n2)  Standard 1st person imitation learning using agent A data, then apply the policy on agent B.  Here, I expect it might do less well than 3rd person learning, but worth checking to be sure, and showing what is the gap in performance.\\n3)  Reinforcement learning using agent A data, and apply the policy on agent A.  I expect this might do better than 3rd person imitation learning but it might depend on the scenario (e.g. difficulty of imitation vs exploration; how different are the points of view between the agents). I understand this is how the expert data is collected for the demonstrator, but I dont see the performance results from just using this procedure on the learner (to compare to Fig.3 results).\\n\\nIncluding these results would in my view significantly enhance the impact of the paper.'},\n",
       " {'DATE': '03 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'ORIGINALITY': 1,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer2',\n",
       "  'TITLE': 'Questions',\n",
       "  'comments': ''},\n",
       " {'CLARITY': 5,\n",
       "  'DATE': '02 Dec 2016',\n",
       "  'IS_ANNOTATED': True,\n",
       "  'IS_META_REVIEW': False,\n",
       "  'OTHER_KEYS': 'ICLR 2017 conference AnonReviewer3',\n",
       "  'SOUNDNESS_CORRECTNESS': 4,\n",
       "  'TITLE': 'Some questions.',\n",
       "  'comments': ''}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr['341'][\"reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
