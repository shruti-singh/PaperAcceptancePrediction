{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Read text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4897, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdate</th>\n",
       "      <th>content</th>\n",
       "      <th>ddate</th>\n",
       "      <th>details</th>\n",
       "      <th>forum</th>\n",
       "      <th>id</th>\n",
       "      <th>invitation</th>\n",
       "      <th>label</th>\n",
       "      <th>nonreaders</th>\n",
       "      <th>number</th>\n",
       "      <th>...</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>writers</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tldr</th>\n",
       "      <th>ref_len</th>\n",
       "      <th>ref_latest</th>\n",
       "      <th>ref_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017_B1-Hhnslg</th>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Prototypical Networks for Few-shot ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'replyCount': 9}</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>2017_B1-Hhnslg</td>\n",
       "      <td>ICLR.cc/2017/conference/-/submission</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[]</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>1481060777491</td>\n",
       "      <td>[]</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>[Jake Snell, Kevin Swersky, Richard Zemel]</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>[Deep learning, Transfer Learning]</td>\n",
       "      <td>We learn a metric space in which few-shot clas...</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "      <td>[2013, 2015, 2013, 2009, 2016, 2004, 2014, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_B1-q5Pqxl</th>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Machine Comprehension Using Match-L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'replyCount': 18}</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>2017_B1-q5Pqxl</td>\n",
       "      <td>ICLR.cc/2017/conference/-/submission</td>\n",
       "      <td>Accept</td>\n",
       "      <td>[]</td>\n",
       "      <td>417</td>\n",
       "      <td>...</td>\n",
       "      <td>1489370977828</td>\n",
       "      <td>[]</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>[Shuohang Wang, Jing Jiang]</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>[Natural language processing, Deep learning]</td>\n",
       "      <td>Using Match-LSTM and Answer Pointer to select ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2016</td>\n",
       "      <td>[2015, 2016, 2016, 2016, 2016, 2015, 2016, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_B16dGcqlx</th>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Third Person Imitation Learning', '...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'replyCount': 14}</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>2017_B16dGcqlx</td>\n",
       "      <td>ICLR.cc/2017/conference/-/submission</td>\n",
       "      <td>Accept</td>\n",
       "      <td>[]</td>\n",
       "      <td>531</td>\n",
       "      <td>...</td>\n",
       "      <td>1488760091458</td>\n",
       "      <td>[]</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>[Bradly C Stadie, Pieter Abbeel, Ilya Sutskever]</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Agent watches another agent at a different cam...</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>[2004, 2010, 2009, 2011, 2005, 2011, 1992, 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cdate                                            content ddate  \\\n",
       "2017_B1-Hhnslg  None  {'title': 'Prototypical Networks for Few-shot ...  None   \n",
       "2017_B1-q5Pqxl  None  {'title': 'Machine Comprehension Using Match-L...  None   \n",
       "2017_B16dGcqlx  None  {'title': 'Third Person Imitation Learning', '...  None   \n",
       "\n",
       "                           details      forum              id  \\\n",
       "2017_B1-Hhnslg   {'replyCount': 9}  B1-Hhnslg  2017_B1-Hhnslg   \n",
       "2017_B1-q5Pqxl  {'replyCount': 18}  B1-q5Pqxl  2017_B1-q5Pqxl   \n",
       "2017_B16dGcqlx  {'replyCount': 14}  B16dGcqlx  2017_B16dGcqlx   \n",
       "\n",
       "                                          invitation   label nonreaders  \\\n",
       "2017_B1-Hhnslg  ICLR.cc/2017/conference/-/submission  Reject         []   \n",
       "2017_B1-q5Pqxl  ICLR.cc/2017/conference/-/submission  Accept         []   \n",
       "2017_B16dGcqlx  ICLR.cc/2017/conference/-/submission  Accept         []   \n",
       "\n",
       "               number  ...         tmdate writers  \\\n",
       "2017_B1-Hhnslg    581  ...  1481060777491      []   \n",
       "2017_B1-q5Pqxl    417  ...  1489370977828      []   \n",
       "2017_B16dGcqlx    531  ...  1488760091458      []   \n",
       "\n",
       "                                                            title  \\\n",
       "2017_B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "2017_B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2017_B16dGcqlx                    Third Person Imitation Learning   \n",
       "\n",
       "                                                         authors  \\\n",
       "2017_B1-Hhnslg        [Jake Snell, Kevin Swersky, Richard Zemel]   \n",
       "2017_B1-q5Pqxl                       [Shuohang Wang, Jing Jiang]   \n",
       "2017_B16dGcqlx  [Bradly C Stadie, Pieter Abbeel, Ilya Sutskever]   \n",
       "\n",
       "                                                         abstract  \\\n",
       "2017_B1-Hhnslg  A recent approach to few-shot classification c...   \n",
       "2017_B1-q5Pqxl  Machine comprehension of text is an important ...   \n",
       "2017_B16dGcqlx  Reinforcement learning (RL) makes it possible ...   \n",
       "\n",
       "                                                    keywords  \\\n",
       "2017_B1-Hhnslg            [Deep learning, Transfer Learning]   \n",
       "2017_B1-q5Pqxl  [Natural language processing, Deep learning]   \n",
       "2017_B16dGcqlx                                            []   \n",
       "\n",
       "                                                             tldr ref_len  \\\n",
       "2017_B1-Hhnslg  We learn a metric space in which few-shot clas...      26   \n",
       "2017_B1-q5Pqxl  Using Match-LSTM and Answer Pointer to select ...      24   \n",
       "2017_B16dGcqlx  Agent watches another agent at a different cam...      50   \n",
       "\n",
       "               ref_latest                                          ref_years  \n",
       "2017_B1-Hhnslg       2016  [2013, 2015, 2013, 2009, 2016, 2004, 2014, 201...  \n",
       "2017_B1-q5Pqxl       2016  [2015, 2016, 2016, 2016, 2016, 2015, 2016, 201...  \n",
       "2017_B16dGcqlx       2016  [2004, 2010, 2009, 2011, 2005, 2011, 1992, 199...  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data  = pd.read_pickle(r'../features/all_data_features_17_20.pkl')\n",
    "print(text_data.shape)\n",
    "text_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Similarity with Call for Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ../../rishi/abstract_jaccardCoef.pickle ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"abstract_jaccardCoef.pickle\", \"rb\") as f:\n",
    "    abs_jc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4897,\n",
       " [('2020_ByeAK1BKPB', 0.024691358024691357),\n",
       "  ('2020_BJe932EYwS', 0.03389830508474576),\n",
       "  ('2017_Sk2iistgg', 0.05405405405405406)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abs_jc), list(abs_jc.items())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text writing clarity features \n",
    "#noun_phrases in abstract and title \\n\n",
    "#nsubj, dobj in abstract\n",
    "#AVERAGE(Non-stop word intersection between consecutive sentences in abstract)\n",
    "#AVERAGE(cosine sim between consecutive sentences in abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clarity_features(title, abst):\n",
    "    \n",
    "    # a. np, nsunj, dobj in abstract\n",
    "    abst = abst.strip(\"\\n\")\n",
    "    abst = abst.strip()\n",
    "    \n",
    "    if not abst:\n",
    "        doc_title = nlp(title)\n",
    "        title_np = 0\n",
    "        for tok in doc_title:\n",
    "            if tok.pos_ == \"NOUN\":\n",
    "                title_np += 1\n",
    "        return [0, 0, 0], title_np, 0\n",
    "    \n",
    "    doc = nlp(abst)\n",
    "    \n",
    "    np_nsubj_dobj = [0, 0, 0]\n",
    "    total_sents = 0\n",
    "    \n",
    "    for s in doc.sents:\n",
    "        total_sents += 1\n",
    "        for tok in s:\n",
    "            if tok.pos_ == \"NOUN\":\n",
    "                np_nsubj_dobj[0] = np_nsubj_dobj[0] + 1\n",
    "            if tok.dep_.startswith(\"nsubj\"):\n",
    "                np_nsubj_dobj[1] = np_nsubj_dobj[1] + 1\n",
    "            if tok.dep_.startswith(\"dobj\"):\n",
    "                np_nsubj_dobj[2] = np_nsubj_dobj[2] + 1\n",
    "    \n",
    "    np_nsubj_dobj = [np_nsubj_dobj[0]/total_sents, np_nsubj_dobj[1]/total_sents, np_nsubj_dobj[2]/total_sents]\n",
    "    \n",
    "    \n",
    "    # b. np in title\n",
    "    doc_title = nlp(title)\n",
    "    title_np = 0\n",
    "    for tok in doc_title:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            title_np += 1\n",
    "    \n",
    "    \n",
    "    # c. AVERAGE(Non-stop word intersection between consecutive sentences in abstract)\n",
    "    intersection_list = []\n",
    "    prev_sent_ent = []\n",
    "    \n",
    "    for s in doc.sents:\n",
    "        curr_sent_ent = []\n",
    "        for tok in s:\n",
    "            if not tok.is_stop and not tok.pos_ == \"PUNCT\":\n",
    "                curr_sent_ent.append(tok.lemma_)\n",
    "        \n",
    "        intersection_list.append(len(set(prev_sent_ent).intersection(set(curr_sent_ent))))\n",
    "        prev_sent_ent = curr_sent_ent\n",
    "    \n",
    "    avg_intersection = np.mean(intersection_list[1:])\n",
    "    \n",
    "    return np_nsubj_dobj, title_np, avg_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for index,row in text_data.iterrows():\n",
    "    np_nsubj_dobj, title_np, avg_intersection = text_clarity_features(row[\"title\"], row[\"abstract\"])\n",
    "    \n",
    "    text_data.loc[index, \"np_count_abs\"] = np_nsubj_dobj[0]\n",
    "    text_data.loc[index, \"nsubj_count_abs\"] = np_nsubj_dobj[1]\n",
    "    text_data.loc[index, \"dobj_count_abs\"] = np_nsubj_dobj[2]\n",
    "    text_data.loc[index, \"np_count_title\"] = title_np\n",
    "    text_data.loc[index, \"cons_inters_abs\"] = avg_intersection\n",
    "    \n",
    "    text_data.loc[index, \"jc_cfp\"] = abs_jc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data[text_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  '"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[text_data[\"id\"]==\"2017_SJUdkecgx\"][\"abstract\"].get_values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cdate', 'content', 'ddate', 'details', 'forum', 'id', 'invitation',\n",
       "       'label', 'nonreaders', 'number', 'original', 'readers', 'referent',\n",
       "       'replyto', 'signatures', 'tcdate', 'tmdate', 'writers', 'title',\n",
       "       'authors', 'abstract', 'keywords', 'tldr', 'ref_len', 'ref_latest',\n",
       "       'ref_years', 'np_count_abs', 'nsubj_count_abs', 'dobj_count_abs',\n",
       "       'np_count_title', 'cons_inters_abs', 'jc_cfp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_consecutive(abst):\n",
    "    \n",
    "    sent_vects = []\n",
    "    \n",
    "    abst = abst.strip(\"\\n\")\n",
    "    abst = abst.strip()\n",
    "    if not abst:\n",
    "        return 0\n",
    "    \n",
    "    doc = nlp(abst)\n",
    "    \n",
    "    for s in doc.sents:\n",
    "        sent_vects.append(s.vector)\n",
    "    \n",
    "    cosine_sim_list = []\n",
    "    \n",
    "    for idx, vec in enumerate(sent_vects[:-1]):\n",
    "        cosine_sim_list.append(1 - spatial.distance.cosine(vec, sent_vects[idx+1]))\n",
    "    \n",
    "    return np.mean(cosine_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6028965943389468"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_consecutive(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in text_data.iterrows():\n",
    "    text_data.loc[index, \"abs_cons_cosine\"] = cosine_sim_consecutive(row[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017_B1-Hhnslg    0.756707\n",
       "2017_B1-q5Pqxl    0.602897\n",
       "2017_B16dGcqlx    0.714312\n",
       "Name: abs_cons_cosine, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[\"abs_cons_cosine\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Leaderboard and Ablation table counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data_features_17_20.pkl\r\n",
      "all_data_features_csv_17_20_new.pkl\r\n",
      "all_data_features_csv_2017_new.pkl\r\n",
      "all_data_features_csv_2017_with_aspect_scores.pkl\r\n",
      "data_csv-2017-20.pkl\r\n",
      "data_features_csv-2017.pkl\r\n",
      "features_csv_17_20.pkl\r\n",
      "GS_augmented_2017_iclr.pickle\r\n",
      "GS_MMM_cit_pub_count_2017.pickle\r\n",
      "iclr_arxiv_map.pkl\r\n",
      "leaderboard_table_refs.pickle\r\n",
      "leaderboard_table_refs.pkl\r\n",
      "mag_features_2017_iclr.pickle\r\n",
      "rev_aspects_2017_peerread.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls ../features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features/leaderboard_table_refs.pkl\", \"rb\") as f:\n",
    "    ldb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../features/leaderboard_table_refs.pickle\", \"rb\") as f:\n",
    "    ldb_other = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 1988)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ldb), len(ldb_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_keys = [0, 0, 0, 0]\n",
    "\n",
    "for k in ldb.keys():\n",
    "    total_keys[0] = total_keys[0] + ldb[k][\"tcount\"][1]\n",
    "    total_keys[1] = total_keys[1] + ldb[k][\"tcount\"][2]\n",
    "    \n",
    "    total_keys[2] = total_keys[2] + ldb_other[k][\"tcount\"][1]\n",
    "    total_keys[3] = total_keys[3] + ldb_other[k][\"tcount\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3330, 3316, 3330, 3316]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in text_data.iterrows():\n",
    "    if index in ldb.keys():\n",
    "        text_data.loc[index, \"ldb_table_count\"] = ldb[index][\"tcount\"][1]\n",
    "        text_data.loc[index, \"abl_table_count\"] = ldb[index][\"tcount\"][2]\n",
    "    else:\n",
    "        text_data.loc[index, \"ldb_table_count\"] = 0\n",
    "        text_data.loc[index, \"abl_table_count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.to_pickle(\"../features/writing_clarity_ldb_abl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017_B1-Hhnslg    2.000000\n",
       "2017_B1-q5Pqxl    0.777778\n",
       "2017_B16dGcqlx    2.666667\n",
       "2017_B184E5qee    2.000000\n",
       "2017_B186cP9gx    1.500000\n",
       "2017_B1E7Pwqgl    1.142857\n",
       "2017_B1ElR4cgg    5.000000\n",
       "2017_B1G9tvcgx    3.200000\n",
       "Name: cons_inters_abs, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[\"cons_inters_abs\"].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
